{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394392b8-2e73-4c0b-884f-add8d444688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files already exist in the output folder. Skipping splitting.\n",
      "Selected CSV file: split-csv\\split_1.csv\n",
      "Cookies added\n",
      "CSV file 'successful_Data\\data-16-05-2024.csv' already exists.\n",
      "CSV file 'failed_Data\\No_Short_Videos_Or_Banned.csv' already exists.\n",
      "CSV file 'failed_Data\\No_Short_Video_in_date-Range-16-05-2024.csv' already exists.\n",
      "16-05-2024\n",
      "Processing link  ##  https://us.youtubers.me//d1b872ae-aff6-43ac-846b-9c54b7d393f3/youtube\n",
      "loading url\n",
      "Subscribers: 138K\n",
      "Channel Name: 숏싹숏싹\n",
      "Found 'Shorts' at XPath: //*[@id='tabsContent']/yt-tab-group-shape/div[1]/yt-tab-shape[2]\n",
      "Shorts\n",
      "48\n",
      "all links saved\n",
      "Loading link: https://www.youtube.com/shorts/QFKDZV-k76I\n",
      "내가 발로 하는 게 낫겠다\n",
      "click\n",
      "clicked\n",
      "\n",
      "19\n",
      "Likes\n",
      "84\n",
      "Views\n",
      "16 May 2024\n",
      "date   ::: May 16 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 16 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '내가 발로 하는 게 낫겠다', 'description': '', 'likes': '19\\n', 'views': '84\\n', 'short_url': 'https://www.youtube.com/shorts/QFKDZV-k76I'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/twRL7ZEif0A\n",
      "진짜 여우짓\n",
      "click\n",
      "clicked\n",
      "\n",
      "163\n",
      "Likes\n",
      "6,763\n",
      "Views\n",
      "16 May 2024\n",
      "date   ::: May 16 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 16 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '진짜 여우짓', 'description': '', 'likes': '163\\n', 'views': '6,763\\n', 'short_url': 'https://www.youtube.com/shorts/twRL7ZEif0A'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/qTGpRlsUrIQ\n",
      "토사물로 공격하는 새\n",
      "click\n",
      "clicked\n",
      "\n",
      "64\n",
      "Likes\n",
      "9,165\n",
      "Views\n",
      "15 May 2024\n",
      "date   ::: May 15 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 15 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '토사물로 공격하는 새', 'description': '', 'likes': '64\\n', 'views': '9,165\\n', 'short_url': 'https://www.youtube.com/shorts/qTGpRlsUrIQ'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/MPS-y3AzvmI\n",
      "개구리마저 먹뱉하는 벌레의 정체\n",
      "click\n",
      "clicked\n",
      "\n",
      "152\n",
      "Likes\n",
      "15,381\n",
      "Views\n",
      "15 May 2024\n",
      "date   ::: May 15 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 15 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '개구리마저 먹뱉하는 벌레의 정체', 'description': '', 'likes': '152\\n', 'views': '15,381\\n', 'short_url': 'https://www.youtube.com/shorts/MPS-y3AzvmI'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/aAqTUKA7O5g\n",
      "존예 간호사 명찰을 보고 환자가 놀란 이유\n",
      "click\n",
      "clicked\n",
      "\n",
      "141\n",
      "Likes\n",
      "19,616\n",
      "Views\n",
      "14 May 2024\n",
      "date   ::: May 14 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 14 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '존예 간호사 명찰을 보고 환자가 놀란 이유', 'description': '', 'likes': '141\\n', 'views': '19,616\\n', 'short_url': 'https://www.youtube.com/shorts/aAqTUKA7O5g'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/2kWaGDC0UZE\n",
      "CG잡아내는 남자\n",
      "click\n",
      "clicked\n",
      "\n",
      "681\n",
      "Likes\n",
      "43,883\n",
      "Views\n",
      "14 May 2024\n",
      "date   ::: May 14 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 14 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': 'CG잡아내는 남자', 'description': '', 'likes': '681\\n', 'views': '43,883\\n', 'short_url': 'https://www.youtube.com/shorts/2kWaGDC0UZE'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/XSYG3wSP6Cs\n",
      "지리는 구글 복지ㄷㄷ\n",
      "click\n",
      "clicked\n",
      "\n",
      "147\n",
      "Likes\n",
      "10,932\n",
      "Views\n",
      "13 May 2024\n",
      "date   ::: May 13 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 13 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '지리는 구글 복지ㄷㄷ', 'description': '', 'likes': '147\\n', 'views': '10,932\\n', 'short_url': 'https://www.youtube.com/shorts/XSYG3wSP6Cs'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/BGHzRLWeTPo\n",
      "공부 못하는 애들 특\n",
      "click\n",
      "clicked\n",
      "\n",
      "2.2K\n",
      "Likes\n",
      "70,471\n",
      "Views\n",
      "13 May 2024\n",
      "date   ::: May 13 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 13 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '공부 못하는 애들 특', 'description': '', 'likes': '2.2K\\n', 'views': '70,471\\n', 'short_url': 'https://www.youtube.com/shorts/BGHzRLWeTPo'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/Lbk7juyVtZs\n",
      "부모님과 살 때 VS 자취할 때\n",
      "click\n",
      "clicked\n",
      "\n",
      "6.6K\n",
      "Likes\n",
      "152,203\n",
      "Views\n",
      "12 May 2024\n",
      "date   ::: May 12 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 12 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '부모님과 살 때 VS 자취할 때', 'description': '', 'likes': '6.6K\\n', 'views': '152,203\\n', 'short_url': 'https://www.youtube.com/shorts/Lbk7juyVtZs'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/Awr3SOXCT14\n",
      "쥐어짜서 쓰는 천연 샴푸\n",
      "click\n",
      "clicked\n",
      "\n",
      "210\n",
      "Likes\n",
      "25,086\n",
      "Views\n",
      "12 May 2024\n",
      "date   ::: May 12 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 12 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '쥐어짜서 쓰는 천연 샴푸', 'description': '', 'likes': '210\\n', 'views': '25,086\\n', 'short_url': 'https://www.youtube.com/shorts/Awr3SOXCT14'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/hwFVUOzMvLY\n",
      "호그와트 편지배달부엉이\n",
      "click\n",
      "clicked\n",
      "\n",
      "168\n",
      "Likes\n",
      "8,753\n",
      "Views\n",
      "11 May 2024\n",
      "date   ::: May 11 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 11 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '호그와트 편지배달부엉이', 'description': '', 'likes': '168\\n', 'views': '8,753\\n', 'short_url': 'https://www.youtube.com/shorts/hwFVUOzMvLY'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/gJfEHgTSvsc\n",
      "뇌를 속이는 실험\n",
      "click\n",
      "clicked\n",
      "\n",
      "1.9K\n",
      "Likes\n",
      "90,045\n",
      "Views\n",
      "11 May 2024\n",
      "date   ::: May 11 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 11 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '뇌를 속이는 실험', 'description': '', 'likes': '1.9K\\n', 'views': '90,045\\n', 'short_url': 'https://www.youtube.com/shorts/gJfEHgTSvsc'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/9pSTayprfRM\n",
      "명장들의 라커룸 대화\n",
      "click\n",
      "clicked\n",
      "\n",
      "279\n",
      "Likes\n",
      "24,889\n",
      "Views\n",
      "10 May 2024\n",
      "date   ::: May 10 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 10 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '명장들의 라커룸 대화', 'description': '', 'likes': '279\\n', 'views': '24,889\\n', 'short_url': 'https://www.youtube.com/shorts/9pSTayprfRM'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/SpX8zMa2HDM\n",
      "끈적하고 투영한 액체를 품은 곰팡이\n",
      "click\n",
      "clicked\n",
      "\n",
      "204\n",
      "Likes\n",
      "21,129\n",
      "Views\n",
      "10 May 2024\n",
      "date   ::: May 10 2024\n",
      "{'chanel_name': '숏싹숏싹', 'yt_url': 'https://www.youtube.com/channel/UCIKPuhVfWDTaCj6gJqcP7aw', 'subscribers': '138K', 'check_date': '16-05-2024', 'released_date': 'May 10 2024', 'is_posted_in_date_range': 'Yes', 'shorts_name': '끈적하고 투영한 액체를 품은 곰팡이', 'description': '', 'likes': '204\\n', 'views': '21,129\\n', 'short_url': 'https://www.youtube.com/shorts/SpX8zMa2HDM'}\n",
      "Trying 4\n",
      "New row appended successfully.\n",
      "data is saved\n",
      "loop is continueing\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "Loading link: https://www.youtube.com/shorts/uwsM7fYOviU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import undetected_chromedriver as uc\n",
    "import os\n",
    "import csv\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "# Import the necessary module\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "# Define the range for the random sleep time in seconds\n",
    "min_sleep_time, max_sleep_time = 1, 3\n",
    "\n",
    "# Generate and use a random sleep time within the defined range\n",
    "random_sleep=time.sleep(random.uniform(min_sleep_time, max_sleep_time))\n",
    "\n",
    "\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.headless = False\n",
    "\n",
    "driver = uc.Chrome(options=options, use_subprocess=True)\n",
    "# Set the browser window size\n",
    "driver.set_window_size(1000, 800)\n",
    "####################################################################\n",
    "\n",
    "def check_folder_empty(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    return not any(filename.endswith('.csv') for filename in os.listdir(folder))\n",
    "\n",
    "def split_csv(input_file, output_folder, max_records=500):\n",
    "    if not check_folder_empty(output_folder):\n",
    "        print(\"CSV files already exist in the output folder. Skipping splitting.\")\n",
    "        return\n",
    "\n",
    "    with open(input_file, 'r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)  # Read the header\n",
    "\n",
    "        count = 0\n",
    "        file_index = 1\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_file = os.path.join(output_folder, f'split_{file_index}.csv')\n",
    "        with open(output_file, 'w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(header)  # Write the header to each split file\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "                count += 1\n",
    "                if count == max_records:\n",
    "                    count = 0\n",
    "                    file_index += 1\n",
    "                    output_file = os.path.join(output_folder, f'split_{file_index}.csv')\n",
    "                    outfile.close()  # Close the current file\n",
    "                    outfile = open(output_file, 'w', newline='')  # Reopen the file\n",
    "                    writer = csv.writer(outfile)\n",
    "                    writer.writerow(header)\n",
    "\n",
    "\n",
    "def crawler(output_folder, csv_file_index):\n",
    "    csv_files = [filename for filename in os.listdir(output_folder) if filename.endswith('.csv')]\n",
    "    if not csv_files:\n",
    "        print(\"No CSV files found in the split folder.\")\n",
    "        return None\n",
    "    else:\n",
    "        if csv_file_index < 1 or csv_file_index > len(csv_files):\n",
    "            print(\"Invalid CSV file index.\")\n",
    "            return None\n",
    "        else:\n",
    "            return os.path.join(output_folder, csv_files[csv_file_index - 1])\n",
    "\n",
    "# Example usage:\n",
    "input_file = 'links.csv'  # Replace 'input.csv' with your CSV file path\n",
    "output_folder = 'split-csv'  # Folder where split CSV files will be saved\n",
    "split_csv(input_file, output_folder, max_records=500)\n",
    "\n",
    "# Select a CSV file from the split folder\n",
    "csv_link_file =  crawler(output_folder, csv_file_index=1)\n",
    "print(\"Selected CSV file:\", csv_link_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "\n",
    "def login(driver, cookies_file_path='cookies.pkl'):\n",
    "    if os.path.exists(cookies_file_path):\n",
    "        # Load cookies if the file exists\n",
    "        with open(cookies_file_path, 'rb') as cookies_file:\n",
    "            cookies = pickle.load(cookies_file)\n",
    "            # Use the loaded cookies for the session\n",
    "            driver.get('https://www.youtube.com')\n",
    "            driver.implicitly_wait(10)\n",
    "            for cookie in cookies:\n",
    "                driver.add_cookie(cookie)\n",
    "            print(\"Cookies added\")\n",
    "            driver.refresh()\n",
    "            driver.implicitly_wait(10)\n",
    "    else:\n",
    "\n",
    "        driver.get('https://www.youtube.com')\n",
    "        driver.implicitly_wait(15)\n",
    "\n",
    "\n",
    "        try:\n",
    "            clk=driver.find_element(By.XPATH,\"(//div[@class='yt-spec-touch-feedback-shape yt-spec-touch-feedback-shape--touch-response-inverse'])[2]\").click()\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "            driver.implicitly_wait(10)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,\"//*[@id='buttons']/ytd-button-renderer/yt-button-shape/a/yt-touch-feedback-shape/div\").click()\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "            driver.implicitly_wait(10)\n",
    "            element=driver.find_element(By.XPATH,\"//*[@id='identifierId']\").click()\n",
    "            print(\"cLICKED\")\n",
    "            # Find and input the email/username\n",
    "            email_field = driver.find_element(By.XPATH, \"//*[@id='identifierId']\")\n",
    "            email_field.send_keys(\"darkjhon449\")  # Replace with your email/username\n",
    "            time.sleep(random.uniform(1, 3))  # Adding a delay to ensure the text is inputted before continuing\n",
    "\n",
    "            # Press Enter to proceed to the password input\n",
    "            email_field.send_keys(Keys.ENTER)\n",
    "            time.sleep(random.uniform(1, 3))  # Adding a delay to ensure the page loads properly\n",
    "            driver.implicitly_wait(10)\n",
    "\n",
    "            email_pass = driver.find_element(By.XPATH, \"//*[@id='password']/div[1]/div/div[1]/input\")\n",
    "            email_pass.send_keys(\"Pakistan@1947\")  # Replace with your email/username\n",
    "            time.sleep(1)  # Adding a delay to ensure the text is inputted before continuing\n",
    "\n",
    "            # Press Enter to proceed to the password input\n",
    "            email_pass.send_keys(Keys.ENTER)\n",
    "            time.sleep(random.uniform(1, 3)) # Adding a delay to ensure the page loads properly\n",
    "            driver.implicitly_wait(10)\n",
    "            input()\n",
    "\n",
    "\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Save cookies for future use\n",
    "        with open(cookies_file_path, 'wb') as cookies_file:\n",
    "            pickle.dump(driver.get_cookies(), cookies_file)\n",
    "        print(\"cookies saved\")\n",
    "\n",
    "login(driver=driver)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_csv_files():\n",
    "    # Create a folder named \"successful_Data\" if it doesn't exist\n",
    "    headers = [\"chanel_name\", \"yt_url\", \"subscribers\", \"check_date\", \"released_date\", \"is_posted_in_date_range\",\n",
    "               \"shorts_name\", \"description\", \"likes\", \"views\", \"short_url\"]\n",
    "    headers2 = [\"yt_url\", \"check_date\", \"is_posted_in_date_range\"]\n",
    "\n",
    "    folder_name = \"successful_Data\"\n",
    "    folder_name2 = \"failed_Data\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(f\"Folder '{folder_name}' created successfully.\")\n",
    "\n",
    "    if not os.path.exists(folder_name2):\n",
    "        os.makedirs(folder_name2)\n",
    "        print(f\"Folder '{folder_name2}' created successfully.\")\n",
    "\n",
    "    # Get the current date in the desired format\n",
    "    current_date = datetime.now().strftime(\"-%d-%m-%Y\")\n",
    "    file_name = os.path.join(folder_name, f\"data{current_date}.csv\")\n",
    "\n",
    "    # Check if a file with the current date exists\n",
    "    if not os.path.exists(file_name):\n",
    "        # If it doesn't exist, create a new CSV file with that name\n",
    "\n",
    "        pd.DataFrame(columns=headers).to_csv(file_name, index=False)\n",
    "        print(f\"CSV file '{file_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"CSV file '{file_name}' already exists.\")\n",
    "\n",
    "    # Create CSV files in \"failed_Data\" folder\n",
    "    failed_folder_name = \"failed_Data\"\n",
    "    Banned_or_no_short_video = os.path.join(failed_folder_name, \"No_Short_Videos_Or_Banned.csv\")\n",
    "    no_video_in_date_range = os.path.join(failed_folder_name, f\"No_Short_Video_in_date-Range{current_date}.csv\")\n",
    "\n",
    "    # Check if the files already exist\n",
    "    if not os.path.exists(Banned_or_no_short_video):\n",
    "        # Create the file only if it doesn't exist\n",
    "        pd.DataFrame(columns=headers2).to_csv(Banned_or_no_short_video, index=False)\n",
    "        print(f\"CSV file '{Banned_or_no_short_video}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"CSV file '{Banned_or_no_short_video}' already exists.\")\n",
    "\n",
    "    if not os.path.exists(no_video_in_date_range):\n",
    "        # Create the file only if it doesn't exist\n",
    "        pd.DataFrame(columns=headers).to_csv(no_video_in_date_range, index=False)\n",
    "        print(f\"CSV file '{no_video_in_date_range}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"CSV file '{no_video_in_date_range}' already exists.\")\n",
    "\n",
    "    return file_name, Banned_or_no_short_video, no_video_in_date_range\n",
    "\n",
    "csv_file, Banned_or_no_short_video1, no_video_in_date_range1 = create_csv_files()\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "headers = [\"chanel_name\", \"yt_url\", \"subscribers\", \"check_date\", \"released_date\", \"is_posted_in_date_range\",\n",
    "           \"shorts_name\", \"description\", \"likes\", \"views\", \"short_url\"]\n",
    "\n",
    "df = pd.DataFrame(columns=headers)\n",
    "check_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "print(check_date)\n",
    "############################################\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "\n",
    "        # Read channel URLs from the CSV file\n",
    "        with open(csv_link_file, \"r\") as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            rows = list(reader)  # Convert the reader object to a list of rows for easier access\n",
    "            for index, row in enumerate(rows):\n",
    "                check_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "                url = row['links']\n",
    "                processed = row['processed']\n",
    "                if not processed:  # Process only if 'processed' column is empty\n",
    "                    # print(url)\n",
    "                    chanel_url = url  # Store the URL in chanel_url variable\n",
    "                    print(f\"Processing link  ##  \" + url)\n",
    "\n",
    "                    print(\"loading url\")\n",
    "                    # Load the channel URL in the browser\n",
    "                    driver.get(url.strip())  # Strip any leading/trailing whitespaces\n",
    "                    driver.implicitly_wait(10)\n",
    "                    fixed_url = driver.current_url\n",
    "\n",
    "                    # Update the processed column for the current URL to 'Yes'\n",
    "                    rows[index]['processed'] = 'Yes'\n",
    "\n",
    "                    # Write back to the CSV file with updated data\n",
    "                    with open(csv_link_file, \"w\", newline='') as csvfile:\n",
    "                        fieldnames = ['links', 'processed']\n",
    "                        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                        writer.writeheader()\n",
    "                        writer.writerows(rows)\n",
    "                     # Break the loop after processing the current URL\n",
    "\n",
    "                    time.sleep(2)\n",
    "\n",
    "                    # Get page source\n",
    "                    page_source = driver.page_source\n",
    "\n",
    "                    # Parse page source using BeautifulSoup\n",
    "                    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                    # Extract all text from the page\n",
    "                    all_text = soup.get_text()\n",
    "                    # print(all_text)\n",
    "\n",
    "                    # Using regular expression to extract subscribers count\n",
    "                    subscribers_pattern = re.search(r'(\\d+(?:\\.\\d+)?[KM]?)(?=\\s*subscribers)', all_text, re.IGNORECASE)\n",
    "                    if subscribers_pattern:\n",
    "                        subscribers = subscribers_pattern.group().strip()\n",
    "                        print(\"Subscribers:\", subscribers)\n",
    "                    else:\n",
    "                        subscribers=\"\"\n",
    "                        print(\"Subscribers not found.\")\n",
    "\n",
    "                    # Using regular expression to extract channel name\n",
    "                    channel_pattern = re.search(r'(.+)(?= - YouTube)', all_text)\n",
    "                    if channel_pattern:\n",
    "                        channel_name = channel_pattern.group().strip()\n",
    "                        print(\"Channel Name:\", channel_name)\n",
    "                    else:\n",
    "                        channel_name=\"\"\n",
    "                        print(\"Channel name not found.\")\n",
    "\n",
    "\n",
    "                    if (\n",
    "                            \" terminated because we received multiple third-party claims of copyright\" in all_text or \"This channel is not available\" in all_text or \"This channel does not exist\" in all_text or \"The page you were looking for doesn't exist\" in all_text or\n",
    "                            \"account has been terminated because it is linked to an account that received multiple third-party claims of copyright infringement\" in all_text) or \"channel was removed because it violated our Community Guidelines\" in all_text:\n",
    "\n",
    "                        print(\"banned account\")\n",
    "                        #saving data\n",
    "                        new_row = {'yt_url': fixed_url,\n",
    "                                   'check_date': check_date,\n",
    "                                   'is_posted_in_date_range': \"Banned\"}\n",
    "\n",
    "                        ##################################################################################################################################\n",
    "                        print(\"Trying 1\")\n",
    "                        ############################################\n",
    "                        fieldnames = ['yt_url', 'check_date', 'is_posted_in_date_range']\n",
    "\n",
    "                        # Check if the file is empty\n",
    "                        with open(Banned_or_no_short_video1, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                            writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "\n",
    "\n",
    "                        print(\"New row appended successfully.\")\n",
    "\n",
    "                        print(\"data is saved\")\n",
    "                        break\n",
    "                    ##############################################\n",
    "                    # Get the page source\n",
    "                    page_source = driver.page_source\n",
    "\n",
    "                    # Parse the page source using BeautifulSoup\n",
    "                    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                    # Find the element matching the XPath\n",
    "                    element = soup.find(\"yt-tab-shape\", {\"tab-title\": \"Shorts\"})\n",
    "\n",
    "                    #######################################\n",
    "                    find_short = None\n",
    "                    short_xpath = \"//*[@id='tabsContent']/yt-tab-group-shape/div[1]/yt-tab-shape[{}]\"\n",
    "\n",
    "                    for i in range(1, 4):  # Try different indexes from 1 to 9\n",
    "                        try:\n",
    "                            short_xpath_formatted = short_xpath.format(i)\n",
    "                            find_short = driver.find_element(By.XPATH, short_xpath_formatted).text\n",
    "                            if \"Shorts\" in find_short:\n",
    "                                print(f\"Found 'Shorts' at XPath: {short_xpath_formatted}\")\n",
    "                                click_short = driver.find_element(By.XPATH, short_xpath_formatted).click()\n",
    "                                break\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    if find_short is None:\n",
    "                        print(\"Text 'Shorts' not found in any of the XPaths.\")\n",
    "                        # saving data\n",
    "                        new_row = {'yt_url': fixed_url,\n",
    "                                   'check_date': check_date,\n",
    "                                   'is_posted_in_date_range': \"No short Videos\"}\n",
    "\n",
    "                        ##################################################################################################################################\n",
    "                        print(\"Trying 2\")\n",
    "                        ############################################\n",
    "                        # Define the header and new row\n",
    "                        fieldnames = ['yt_url', 'check_date',\n",
    "                                      'is_posted_in_date_range']\n",
    "\n",
    "                        # Check if the file is empty\n",
    "\n",
    "                        with open(Banned_or_no_short_video1, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                            writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "                        print(\"New row appended successfully.\")\n",
    "\n",
    "                        print(\"data is saved\")\n",
    "\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        print(find_short)\n",
    "\n",
    "\n",
    "                    shorts = driver.find_elements(By.XPATH,\n",
    "                                                  \"//a[@class='yt-simple-endpoint focus-on-expand style-scope ytd-rich-grid-slim-media']\")\n",
    "                    print(len(shorts))\n",
    "\n",
    "                    if shorts is None or len(shorts) < 1:\n",
    "\n",
    "                        print(\"No Short Videos loop breaked\")\n",
    "                        # saving data\n",
    "                        new_row = {'yt_url': fixed_url,\n",
    "                                   'check_date': check_date,\n",
    "                                   'is_posted_in_date_range': \"No short Videos\"}\n",
    "\n",
    "                        ##################################################################################################################################\n",
    "                        print(\"Trying 3\")\n",
    "                        ############################################\n",
    "                        # Define the header and new row\n",
    "                        fieldnames = ['yt_url', 'check_date',\n",
    "                                      'is_posted_in_date_range']\n",
    "\n",
    "                        # Check if the file is empty\n",
    "                        with open(Banned_or_no_short_video1, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                            writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "\n",
    "\n",
    "                        print(\"New row appended successfully.\")\n",
    "                        print(\"data is saved\")\n",
    "\n",
    "\n",
    "                        print(\n",
    "                            \"33333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\")\n",
    "                        break\n",
    "\n",
    "                    # Store links in a list\n",
    "                    links = []\n",
    "\n",
    "                    for short in shorts:\n",
    "                        link = short.get_attribute(\"href\")\n",
    "                        links.append(link)\n",
    "                        # print(link)\n",
    "\n",
    "                    print(\"all links saved\")\n",
    "                    # Set a flag to keep track of whether the 'if' part of the loop has executed\n",
    "                    if_part_executed = False\n",
    "                    # Iterate over the links and load them one by one\n",
    "                    for link in links:\n",
    "                        print(\"Loading link:\", link)\n",
    "                        driver.get(link)\n",
    "                        driver.implicitly_wait(10)\n",
    "                        try:\n",
    "\n",
    "                            short_name = driver.find_element(By.XPATH,\n",
    "                                                             \"//h2[@class='title style-scope reel-player-header-renderer']\").text\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        print(short_name)\n",
    "\n",
    "                        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "                        print(\"click\")\n",
    "                        clk = driver.find_element(By.XPATH,\n",
    "                                                  \"//*[@id='button-shape']/button/yt-touch-feedback-shape/div/div[2]\").click()\n",
    "                        time.sleep(random.uniform(1, 3))\n",
    "                        clk2 = driver.find_element(By.XPATH,\n",
    "                                                   \"//*[@id='items']/ytd-menu-service-item-renderer/tp-yt-paper-item/yt-formatted-string\").click()\n",
    "                        print(\"clicked\")\n",
    "                        try:\n",
    "                            description = driver.find_element(By.XPATH, \"//div[@id='description']\").text\n",
    "                        except:\n",
    "                            description = \"\"\n",
    "                        print(description)\n",
    "                        try:\n",
    "\n",
    "                            likes1 = driver.find_element(By.XPATH,\n",
    "                                                         \"(//div[@class='YtwFactoidRendererFactoid'])[1]\").text\n",
    "                        except:\n",
    "                            likes1 = \"Likes\"\n",
    "                        print(likes1)\n",
    "                        likes = likes1.replace('Likes', '')\n",
    "                        try:\n",
    "\n",
    "                            veiws1 = driver.find_element(By.XPATH,\n",
    "                                                         \"(//div[@class='YtwFactoidRendererFactoid'])[2]\").text\n",
    "                        except:\n",
    "                            veiws1 = \"Views\"\n",
    "                        print(veiws1)\n",
    "                        veiws = veiws1.replace('Views', '')\n",
    "                        try:\n",
    "\n",
    "                            date = driver.find_element(By.XPATH, \"(//div[@class='YtwFactoidRendererFactoid'])[3]\").text\n",
    "                        except:\n",
    "                            date = \"\\n\"\n",
    "\n",
    "                        date_string = date\n",
    "                        date = date.replace('\\n', ' ')\n",
    "                        print(date)\n",
    "                        # Date string from the webpage\n",
    "                        date_str = date\n",
    "                        # Convert to datetime object\n",
    "                        try:\n",
    "                            # Try parsing the date assuming it's in the format \"Apr 26 2024\"\n",
    "                            date_obj = datetime.strptime(date_str, \"%b %d %Y\")\n",
    "                        except ValueError:\n",
    "                            # If ValueError occurs, try parsing the date assuming it's in the format \"26 Apr 2024\"\n",
    "                            date_obj = datetime.strptime(date_str, \"%d %b %Y\")\n",
    "                            # try:\n",
    "                            #\n",
    "                            #\n",
    "                            # except ValueError:\n",
    "                            #     # If ValueError occurs again, try parsing the date assuming it's in the format \"2022 Dec 19\"\n",
    "                            #     date_obj = datetime.datetime.strptime(date_str, \"%Y %b %d\")\n",
    "\n",
    "                        # Format the date consistently\n",
    "                        date = date_obj.strftime(\"%b %d %Y\")\n",
    "                        print(\"date   :::\" , date)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        # Get the current date\n",
    "                        current_date = datetime.now()\n",
    "\n",
    "                        # Generate a list of date strings for the past 7 days\n",
    "                        date_range = [(current_date - timedelta(days=i)).strftime(\"%b %d %Y\") for i in range(7)]\n",
    "                        # Print the generated date range\n",
    "                        # print(\"Date Range (Past 7 days):\")\n",
    "\n",
    "                        # for dates in date_range:\n",
    "                        #     print(dates)\n",
    "\n",
    "\n",
    "                        # Check if the date falls within the past 7 days\n",
    "                        if (date in date_range) or (\"ago\" in date.lower()):\n",
    "\n",
    "                            if_part_executed = True\n",
    "\n",
    "\n",
    "\n",
    "                            new_row = {'chanel_name': channel_name, 'yt_url': fixed_url,\n",
    "                                       'subscribers': subscribers,\n",
    "                                       'check_date': check_date, 'released_date': date,\n",
    "                                       'is_posted_in_date_range': \"Yes\", 'shorts_name': short_name,\n",
    "                                       'description': description, 'likes': likes, 'views': veiws,\n",
    "                                       'short_url': link}\n",
    "                            print(new_row)\n",
    "                            #time.sleep(5)\n",
    "\n",
    "                            ##################################################################################################################################\n",
    "                            print(\"Trying 4\")\n",
    "                            ############################################\n",
    "\n",
    "                            # Define the header and new row\n",
    "                            fieldnames = ['chanel_name', 'yt_url', 'subscribers', 'check_date', 'released_date',\n",
    "                                          'is_posted_in_date_range', 'shorts_name', 'description', 'likes', 'views',\n",
    "                                          'short_url']\n",
    "\n",
    "                            with open(csv_file, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "\n",
    "\n",
    "                            print(\"New row appended successfully.\")\n",
    "\n",
    "                            print(\"data is saved\")\n",
    "\n",
    "                            print(\"loop is continueing\")\n",
    "\n",
    "\n",
    "                            print(\"%\" * 100)\n",
    "                            print(\n",
    "                                \"4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\")\n",
    "\n",
    "                        else:\n",
    "                            if not if_part_executed:  # If the 'if' part hasn't executed in the first iteration\n",
    "\n",
    "                                check_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "                                new_row = {'chanel_name': channel_name, 'yt_url': fixed_url,\n",
    "                                           'subscribers': subscribers,\n",
    "                                           'check_date': check_date, 'released_date': date,\n",
    "                                           'is_posted_in_date_range': \"No\",\n",
    "                                           'shorts_name': short_name,\n",
    "                                           'description': description,\n",
    "                                           'likes': likes, 'views': veiws, 'short_url': link}\n",
    "                                print(new_row)\n",
    "                                #time.sleep(5)\n",
    "                                print(\"Trying 5\")\n",
    "                                ############################################\n",
    "                                # Define the header and new row\n",
    "                                fieldnames = ['chanel_name', 'yt_url', 'subscribers', 'check_date', 'released_date',\n",
    "                                              'is_posted_in_date_range', 'shorts_name', 'description', 'likes', 'views',\n",
    "                                              'short_url']\n",
    "\n",
    "                                with open(no_video_in_date_range1, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                    writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "                                print(\"New row appended successfully.\")\n",
    "                                print(\"data is saved\")\n",
    "\n",
    "\n",
    "                                print(\"loop breaked\")\n",
    "\n",
    "                                print(\n",
    "                                    \"555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\")\n",
    "\n",
    "                                break\n",
    "                            if (date not in date_range) or (\"ago\"  not in date.lower()):\n",
    "                                print(\"breaking loop after saving data\")\n",
    "                                time.sleep(1)\n",
    "\n",
    "                                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d93d0-7a7b-4bdb-b826-e17aff991393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
