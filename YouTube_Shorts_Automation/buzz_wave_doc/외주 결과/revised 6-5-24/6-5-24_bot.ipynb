{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effb4f2f-4090-4291-9bf7-313e92484142",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'links.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 88\u001b[0m\n\u001b[0;32m     86\u001b[0m input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinks.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace 'input.csv' with your CSV file path\u001b[39;00m\n\u001b[0;32m     87\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit-csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Folder where split CSV files will be saved\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m \u001b[43msplit_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Select a CSV file from the split folder\u001b[39;00m\n\u001b[0;32m     91\u001b[0m csv_link_file \u001b[38;5;241m=\u001b[39m  crawler(output_folder, csv_file_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 48\u001b[0m, in \u001b[0;36msplit_csv\u001b[1;34m(input_file, output_folder, max_records)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV files already exist in the output folder. Skipping splitting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m     49\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(csvfile)\n\u001b[0;32m     50\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(reader)  \u001b[38;5;66;03m# Read the header\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'links.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import undetected_chromedriver as uc\n",
    "import os\n",
    "import csv\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "# Import the necessary module\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "# Define the range for the random sleep time in seconds\n",
    "min_sleep_time, max_sleep_time = 1, 3\n",
    "\n",
    "# Generate and use a random sleep time within the defined range\n",
    "random_sleep=time.sleep(random.uniform(min_sleep_time, max_sleep_time))\n",
    "\n",
    "\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.headless = False\n",
    "\n",
    "driver = uc.Chrome(options=options, use_subprocess=True)\n",
    "# Set the browser window size\n",
    "driver.set_window_size(1000, 800)\n",
    "####################################################################\n",
    "\n",
    "def check_folder_empty(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    return not any(filename.endswith('.csv') for filename in os.listdir(folder))\n",
    "\n",
    "def split_csv(input_file, output_folder, max_records=500):\n",
    "    if not check_folder_empty(output_folder):\n",
    "        print(\"CSV files already exist in the output folder. Skipping splitting.\")\n",
    "        return\n",
    "\n",
    "    with open(input_file, 'r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)  # Read the header\n",
    "\n",
    "        count = 0\n",
    "        file_index = 1\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_file = os.path.join(output_folder, f'split_{file_index}.csv')\n",
    "        with open(output_file, 'w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(header)  # Write the header to each split file\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "                count += 1\n",
    "                if count == max_records:\n",
    "                    count = 0\n",
    "                    file_index += 1\n",
    "                    output_file = os.path.join(output_folder, f'split_{file_index}.csv')\n",
    "                    outfile.close()  # Close the current file\n",
    "                    outfile = open(output_file, 'w', newline='')  # Reopen the file\n",
    "                    writer = csv.writer(outfile)\n",
    "                    writer.writerow(header)\n",
    "\n",
    "import os\n",
    "\n",
    "def crawler(output_folder, csv_file_index):\n",
    "    csv_files = [filename for filename in os.listdir(output_folder) if filename.endswith('.csv')]\n",
    "    if not csv_files:\n",
    "        print(\"No CSV files found in the split folder.\")\n",
    "        return None\n",
    "    else:\n",
    "        if csv_file_index < 1 or csv_file_index > len(csv_files):\n",
    "            print(\"Invalid CSV file index.\")\n",
    "            return None\n",
    "        else:\n",
    "            return os.path.join(output_folder, csv_files[csv_file_index - 1])\n",
    "\n",
    "# Example usage:\n",
    "input_file = 'links.csv'  # Replace 'input.csv' with your CSV file path\n",
    "output_folder = 'split-csv'  # Folder where split CSV files will be saved\n",
    "split_csv(input_file, output_folder, max_records=500)\n",
    "\n",
    "# Select a CSV file from the split folder\n",
    "csv_link_file =  crawler(output_folder, csv_file_index=2)\n",
    "print(\"Selected CSV file:\", csv_link_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "\n",
    "def login(driver, cookies_file_path='cookies.pkl'):\n",
    "    if os.path.exists(cookies_file_path):\n",
    "        # Load cookies if the file exists\n",
    "        with open(cookies_file_path, 'rb') as cookies_file:\n",
    "            cookies = pickle.load(cookies_file)\n",
    "            # Use the loaded cookies for the session\n",
    "            driver.get('https://www.youtube.com')\n",
    "            driver.implicitly_wait(10)\n",
    "            for cookie in cookies:\n",
    "                driver.add_cookie(cookie)\n",
    "            print(\"Cookies added\")\n",
    "            driver.refresh()\n",
    "            driver.implicitly_wait(10)\n",
    "    else:\n",
    "\n",
    "        driver.get('https://www.youtube.com')\n",
    "        driver.implicitly_wait(15)\n",
    "\n",
    "\n",
    "        try:\n",
    "            clk=driver.find_element(By.XPATH,\"(//div[@class='yt-spec-touch-feedback-shape yt-spec-touch-feedback-shape--touch-response-inverse'])[2]\").click()\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "            driver.implicitly_wait(10)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,\"//*[@id='buttons']/ytd-button-renderer/yt-button-shape/a/yt-touch-feedback-shape/div\").click()\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "            driver.implicitly_wait(10)\n",
    "            element=driver.find_element(By.XPATH,\"//*[@id='identifierId']\").click()\n",
    "            print(\"cLICKED\")\n",
    "            # Find and input the email/username\n",
    "            email_field = driver.find_element(By.XPATH, \"//*[@id='identifierId']\")\n",
    "            email_field.send_keys(\"darkjhon449\")  # Replace with your email/username\n",
    "            time.sleep(random.uniform(1, 3))  # Adding a delay to ensure the text is inputted before continuing\n",
    "\n",
    "            # Press Enter to proceed to the password input\n",
    "            email_field.send_keys(Keys.ENTER)\n",
    "            time.sleep(random.uniform(1, 3))  # Adding a delay to ensure the page loads properly\n",
    "            driver.implicitly_wait(10)\n",
    "\n",
    "            email_pass = driver.find_element(By.XPATH, \"//*[@id='password']/div[1]/div/div[1]/input\")\n",
    "            email_pass.send_keys(\"Pakistan@1947\")  # Replace with your email/username\n",
    "            time.sleep(1)  # Adding a delay to ensure the text is inputted before continuing\n",
    "\n",
    "            # Press Enter to proceed to the password input\n",
    "            email_pass.send_keys(Keys.ENTER)\n",
    "            time.sleep(random.uniform(1, 3)) # Adding a delay to ensure the page loads properly\n",
    "            driver.implicitly_wait(10)\n",
    "            input()\n",
    "\n",
    "\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Save cookies for future use\n",
    "        with open(cookies_file_path, 'wb') as cookies_file:\n",
    "            pickle.dump(driver.get_cookies(), cookies_file)\n",
    "        print(\"cookies saved\")\n",
    "\n",
    "login(driver=driver)\n",
    "\n",
    "##################################\n",
    "\n",
    "#################################################\n",
    "\n",
    "\n",
    "def create_csv_files():\n",
    "    # Create a folder named \"successful_Data\" if it doesn't exist\n",
    "    headers = [\"Channel_Name\", \"yt_url\", \"subscribers\", \"Check_Date\", \"Released_Date\", \"is_posted_in_date_range\",\n",
    "               \"Shorts_Name\", \"Description\", \"Likes\", \"Views\", \"short_url\"]\n",
    "    headers2 = [\"yt_url\", \"Check_Date\", \"is_posted_in_date_range\"]\n",
    "\n",
    "    folder_name = \"successful_Data\"\n",
    "    folder_name2 = \"failed_Data\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(f\"Folder '{folder_name}' created successfully.\")\n",
    "\n",
    "    if not os.path.exists(folder_name2):\n",
    "        os.makedirs(folder_name2)\n",
    "        print(f\"Folder '{folder_name2}' created successfully.\")\n",
    "\n",
    "    # Get the current date in the desired format\n",
    "    current_date = datetime.now().strftime(\"-%d-%m-%Y\")\n",
    "    file_name = os.path.join(folder_name, f\"data{current_date}.csv\")\n",
    "\n",
    "    # Check if a file with the current date exists\n",
    "    if not os.path.exists(file_name):\n",
    "        # If it doesn't exist, create a new CSV file with that name\n",
    "\n",
    "        pd.DataFrame(columns=headers).to_csv(file_name, index=False)\n",
    "        print(f\"CSV file '{file_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"CSV file '{file_name}' already exists.\")\n",
    "\n",
    "    # Create CSV files in \"failed_Data\" folder\n",
    "    failed_folder_name = \"failed_Data\"\n",
    "    Banned_or_no_short_video = os.path.join(failed_folder_name, \"No_Short_Videos_Or_Banned.csv\")\n",
    "    no_video_in_date_range = os.path.join(failed_folder_name, f\"No_Short_Video_in_date-Range{current_date}.csv\")\n",
    "\n",
    "    # Check if the files already exist\n",
    "    if not os.path.exists(Banned_or_no_short_video):\n",
    "        # Create the file only if it doesn't exist\n",
    "        pd.DataFrame(columns=headers2).to_csv(Banned_or_no_short_video, index=False)\n",
    "        print(f\"CSV file '{Banned_or_no_short_video}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"CSV file '{Banned_or_no_short_video}' already exists.\")\n",
    "\n",
    "    if not os.path.exists(no_video_in_date_range):\n",
    "        # Create the file only if it doesn't exist\n",
    "        pd.DataFrame(columns=headers).to_csv(no_video_in_date_range, index=False)\n",
    "        print(f\"CSV file '{no_video_in_date_range}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"CSV file '{no_video_in_date_range}' already exists.\")\n",
    "\n",
    "    return file_name, Banned_or_no_short_video, no_video_in_date_range\n",
    "\n",
    "csv_file, Banned_or_no_short_video1, no_video_in_date_range1 = create_csv_files()\n",
    "\n",
    "\n",
    "csv_file, Banned_or_no_short_video1, no_video_in_date_range1 = create_csv_files()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "headers = [\"Channel_Name\", \"yt_url\", \"subscribers\", \"Check_Date\", \"Released_Date\", \"is_posted_in_date_range\",\n",
    "               \"Shorts_Name\", \"Description\", \"Likes\", \"Views\", \"short_url\"]\n",
    "\n",
    "df = pd.DataFrame(columns=headers)\n",
    "check_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "print(check_date)\n",
    "############################################\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(\"loop\")\n",
    "        # Read channel URLs from the CSV file\n",
    "        with open(csv_link_file, \"r\") as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            rows = list(reader)  # Convert the reader object to a list of rows for easier access\n",
    "            for index, row in enumerate(rows):\n",
    "                check_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "                url = row['links']\n",
    "                processed = row['processed']\n",
    "                if not processed:  # Process only if 'processed' column is empty\n",
    "                    # print(url)\n",
    "                    chanel_url = url  # Store the URL in chanel_url variable\n",
    "                    print(f\"Processing link  ##  \" + url)\n",
    "\n",
    "                    print(\"loading url\")\n",
    "                    # Load the channel URL in the browser\n",
    "                    driver.get(url.strip())  # Strip any leading/trailing whitespaces\n",
    "                    driver.implicitly_wait(10)\n",
    "                    fixed_url = driver.current_url\n",
    "                    # Get page source\n",
    "\n",
    "\n",
    "\n",
    "                    # Update the processed column for the current URL to 'Yes'\n",
    "                    rows[index]['processed'] = 'Yes'\n",
    "\n",
    "                    # Write back to the CSV file with updated data\n",
    "                    with open(csv_link_file, \"w\", newline='') as csvfile:\n",
    "                        fieldnames = ['links', 'processed']\n",
    "                        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                        writer.writeheader()\n",
    "                        writer.writerows(rows)\n",
    "                     # Break the loop after processing the current URL\n",
    "\n",
    "                    page_source = driver.page_source\n",
    "\n",
    "                    # Parse page source using BeautifulSoup\n",
    "                    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                    # Extract all text from the page\n",
    "                    all_text = soup.get_text()\n",
    "\n",
    "\n",
    "                    if (\n",
    "                            \" terminated because we received multiple third-party claims of copyright\" in all_text or \"This channel does not exist\" in all_text or \"The page you were looking for doesn't exist\" in all_text or\n",
    "                            \"account has been terminated because it is linked to an account that received multiple third-party claims of copyright infringement\" in all_text) or \"channel was removed because it violated our Community Guidelines\" in all_text:\n",
    "\n",
    "                        print(\"banned account\")\n",
    "                        #saving data\n",
    "                        new_row = {'yt_url': fixed_url,\n",
    "                                   'Check_Date': check_date,\n",
    "                                   'is_posted_in_date_range': \"Banned\"}\n",
    "\n",
    "                        ##################################################################################################################################\n",
    "                        print(\"Trying 1\")\n",
    "                        ############################################\n",
    "                        # Check if the file is empty\n",
    "                        with open(Banned_or_no_short_video1, 'r', encoding='utf-8', newline='') as csvfile:\n",
    "                            reader = csv.reader(csvfile)\n",
    "                            first_row = next(reader, None)\n",
    "                            if first_row is None:  # If the file is empty\n",
    "                                with open(csv_file, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                    writer.writeheader()  # Write the header\n",
    "                                    writer.writerow(new_row)  # Write the new row\n",
    "                            else:\n",
    "                                with open(Banned_or_no_short_video1, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                    writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "                            print(\"New row appended successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print(\"data is saved\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        break\n",
    "                    ##############################################\n",
    "                    # Get the page source\n",
    "                    page_source = driver.page_source\n",
    "\n",
    "                    # Parse the page source using BeautifulSoup\n",
    "                    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "                    # Find the element matching the XPath\n",
    "                    element = soup.find(\"yt-tab-shape\", {\"tab-title\": \"Shorts\"})\n",
    "\n",
    "                    #######################################\n",
    "                    find_short = None\n",
    "                    short_xpath = \"//*[@id='tabsContent']/yt-tab-group-shape/div[1]/yt-tab-shape[{}]\"\n",
    "\n",
    "                    for i in range(1, 4):  # Try different indexes from 1 to 9\n",
    "                        try:\n",
    "                            short_xpath_formatted = short_xpath.format(i)\n",
    "                            find_short = driver.find_element(By.XPATH, short_xpath_formatted).text\n",
    "                            if \"Shorts\" in find_short:\n",
    "                                print(f\"Found 'Shorts' at XPath: {short_xpath_formatted}\")\n",
    "                                click_short = driver.find_element(By.XPATH, short_xpath_formatted).click()\n",
    "                                break\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    if find_short is None:\n",
    "                        print(\"Text 'Shorts' not found in any of the XPaths.\")\n",
    "                        # saving data\n",
    "                        new_row = {'yt_url': fixed_url,\n",
    "                                   'Check_Date': check_date,\n",
    "                                   'is_posted_in_date_range': \"No short Videos\"}\n",
    "\n",
    "                        ##################################################################################################################################\n",
    "                        print(\"Trying 2\")\n",
    "                        ############################################\n",
    "                        # Define the header and new row\n",
    "                        fieldnames = ['yt_url', 'Check_Date',\n",
    "                                      'is_posted_in_date_range']\n",
    "\n",
    "                        # Check if the file is empty\n",
    "                        with open(Banned_or_no_short_video1, 'r', encoding='utf-8', newline='') as csvfile:\n",
    "                            reader = csv.reader(csvfile)\n",
    "                            first_row = next(reader, None)\n",
    "                            if first_row is None:  # If the file is empty\n",
    "                                with open(csv_file, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                    writer.writeheader()  # Write the header\n",
    "                                    writer.writerow(new_row)  # Write the new row\n",
    "                            else:\n",
    "                                with open(Banned_or_no_short_video1, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                    writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "                            print(\"New row appended successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(\"data is saved\")\n",
    "\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        print(find_short)\n",
    "\n",
    "                    # Continue with your code using the found XPath (short_xpath_formatted)\n",
    "\n",
    "                    print(chanel_url)\n",
    "                    try:\n",
    "                        chhanel_name = driver.find_element(By.XPATH,\n",
    "                                                           \"(//*[@id='text'])[1]\").text\n",
    "\n",
    "\n",
    "                        #chhanel_name = driver.find_element(By.XPATH, \"(//div[@class='style-scope ytd-channel-name'])[1]\").text\n",
    "\n",
    "                        print(\"Channel Name:\", chhanel_name)\n",
    "                    except:\n",
    "                        chhanel_name=\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    try:\n",
    "\n",
    "                        subscribers = driver.find_element(By.XPATH, \"//*[@id='subscriber-count']\").text\n",
    "                        print(subscribers)\n",
    "\n",
    "                        #print(chhanel_name)\n",
    "                    except :\n",
    "                        try:\n",
    "                            text1 = driver.find_element(By.XPATH, \"//yt-content-metadata-view-model[@class]\").text\n",
    "                            print(subscribers)\n",
    "\n",
    "                            # Define patterns using regular expressions\n",
    "                            subscribers_pattern = r'(\\d+)K subscribers'\n",
    "\n",
    "\n",
    "                            # Extract subscribers count using regex\n",
    "                            subscribers_match = re.search(subscribers_pattern, text1)\n",
    "                            if subscribers_match:\n",
    "                                subscribers_count = subscribers_match.group(1)\n",
    "                            else:\n",
    "                                subscribers_count = None\n",
    "\n",
    "\n",
    "\n",
    "                            print(\"Subscribers:\", subscribers_count)\n",
    "\n",
    "\n",
    "                            subscribers = subscribers_count\n",
    "\n",
    "                        except:\n",
    "                            subscribers=\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    ############\n",
    "\n",
    "\n",
    "                    shorts = driver.find_elements(By.XPATH,\n",
    "                                                  \"//a[@class='yt-simple-endpoint focus-on-expand style-scope ytd-rich-grid-slim-media']\")\n",
    "                    print(len(shorts))\n",
    "\n",
    "                    if shorts is None or len(shorts) < 1:\n",
    "\n",
    "                        print(\"No Short Videos loop breaked\")\n",
    "                        # saving data\n",
    "                        new_row = {'yt_url': fixed_url,\n",
    "                                   'Check_Date': check_date,\n",
    "                                   'is_posted_in_date_range': \"No short Videos\"}\n",
    "\n",
    "                        ##################################################################################################################################\n",
    "                        print(\"Trying 3\")\n",
    "                        ############################################\n",
    "                        # Define the header and new row\n",
    "                        fieldnames = ['yt_url', 'Check_Date',\n",
    "                                      'is_posted_in_date_range']\n",
    "\n",
    "                        # Check if the file is empty\n",
    "                        with open(Banned_or_no_short_video1, 'r', encoding='utf-8', newline='') as csvfile:\n",
    "                            reader = csv.reader(csvfile)\n",
    "                            first_row = next(reader, None)\n",
    "                            if first_row is None:  # If the file is empty\n",
    "                                with open(csv_file, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                    writer.writeheader()  # Write the header\n",
    "                                    writer.writerow(new_row)  # Write the new row\n",
    "                            else:\n",
    "                                with open(Banned_or_no_short_video1, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                    writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "                        print(\"New row appended successfully.\")\n",
    "                        print(\"data is saved\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        print(\n",
    "                            \"33333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\")\n",
    "                        break\n",
    "\n",
    "                    # Store links in a list\n",
    "                    links = []\n",
    "\n",
    "                    for short in shorts:\n",
    "                        link = short.get_attribute(\"href\")\n",
    "                        links.append(link)\n",
    "                        # print(link)\n",
    "\n",
    "                    print(\"all links saved\")\n",
    "                    # Set a flag to keep track of whether the 'if' part of the loop has executed\n",
    "                    if_part_executed = False\n",
    "                    # Iterate over the links and load them one by one\n",
    "                    for link in links:\n",
    "                        print(\"Loading link:\", link)\n",
    "                        driver.get(link)\n",
    "                        driver.implicitly_wait(10)\n",
    "                        try:\n",
    "\n",
    "                            short_name = driver.find_element(By.XPATH,\n",
    "                                                             \"//h2[@class='title style-scope reel-player-header-renderer']\").text\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        print(short_name)\n",
    "\n",
    "                        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "                        print(\"click\")\n",
    "                        clk = driver.find_element(By.XPATH,\n",
    "                                                  \"//*[@id='button-shape']/button/yt-touch-feedback-shape/div/div[2]\").click()\n",
    "                        time.sleep(random.uniform(1, 3))\n",
    "                        clk2 = driver.find_element(By.XPATH,\n",
    "                                                   \"//*[@id='items']/ytd-menu-service-item-renderer/tp-yt-paper-item/yt-formatted-string\").click()\n",
    "                        print(\"clicked\")\n",
    "                        try:\n",
    "                            description = driver.find_element(By.XPATH, \"//div[@id='description']\").text\n",
    "                        except:\n",
    "                            description = \"\"\n",
    "                        print(description)\n",
    "                        try:\n",
    "\n",
    "                            likes1 = driver.find_element(By.XPATH,\n",
    "                                                         \"(//div[@class='YtwFactoidRendererFactoid'])[1]\").text\n",
    "                        except:\n",
    "                            likes1 = \"Likes\"\n",
    "                        print(likes1)\n",
    "                        likes = likes1.replace('Likes', '')\n",
    "                        try:\n",
    "\n",
    "                            veiws1 = driver.find_element(By.XPATH,\n",
    "                                                         \"(//div[@class='YtwFactoidRendererFactoid'])[2]\").text\n",
    "                        except:\n",
    "                            veiws1 = \"Views\"\n",
    "                        print(veiws1)\n",
    "                        veiws = veiws1.replace('Views', '')\n",
    "                        try:\n",
    "\n",
    "                            date = driver.find_element(By.XPATH, \"(//div[@class='YtwFactoidRendererFactoid'])[3]\").text\n",
    "                        except:\n",
    "                            date = \"\\n\"\n",
    "\n",
    "                        date_string = date\n",
    "                        date = date.replace('\\n', ' ')\n",
    "                        print(date)\n",
    "                        # Date string from the webpage\n",
    "                        date_str = date\n",
    "                        # Convert to datetime object\n",
    "                        try:\n",
    "                            # Try parsing the date assuming it's in the format \"Apr 26 2024\"\n",
    "                            date_obj = datetime.strptime(date_str, \"%b %d %Y\")\n",
    "                        except ValueError:\n",
    "                            # If ValueError occurs, try parsing the date assuming it's in the format \"26 Apr 2024\"\n",
    "                            date_obj = datetime.strptime(date_str, \"%d %b %Y\")\n",
    "\n",
    "                        # Format the date consistently\n",
    "                        date = date_obj.strftime(\"%b %d %Y\")\n",
    "                        print(date)\n",
    "\n",
    "\n",
    "                        # Get the current date\n",
    "                        current_date = datetime.now()\n",
    "\n",
    "                        # Generate a list of date strings for the past 7 days\n",
    "                        date_range = [(current_date - timedelta(days=i)).strftime(\"%b %d %Y\") for i in range(7)]\n",
    "                        # Print the generated date range\n",
    "                        # print(\"Date Range (Past 7 days):\")\n",
    "\n",
    "                        for dates in date_range:\n",
    "                            print(dates)\n",
    "                        #input()\n",
    "\n",
    "                        # Check if the date falls within the past 7 days\n",
    "                        if (date in date_range) or (\"ago\" in date.lower()):\n",
    "\n",
    "                            if_part_executed = True\n",
    "\n",
    "\n",
    "\n",
    "                            new_row = {'Channel_Name': chhanel_name, 'yt_url': fixed_url,\n",
    "                                       'subscribers': subscribers,\n",
    "                                       'Check_Date': check_date, 'Released_Date': date,\n",
    "                                       'is_posted_in_date_range': \"Yes\", 'Shorts_Name': short_name,\n",
    "                                       'Description': description, 'Likes': likes, 'Views': veiws,\n",
    "                                       'short_url': link}\n",
    "\n",
    "                            ##################################################################################################################################\n",
    "                            print(\"Trying 4\")\n",
    "                            ############################################\n",
    "\n",
    "                            # Define the header and new row\n",
    "                            fieldnames = ['Channel_Name', 'yt_url', 'subscribers', 'Check_Date', 'Released_Date',\n",
    "                                          'is_posted_in_date_range', 'Shorts_Name', 'Description', 'Likes', 'Views',\n",
    "                                          'short_url']\n",
    "\n",
    "\n",
    "                            # Check if the file is empty\n",
    "                            with open(csv_file, 'r', encoding='utf-8', newline='') as csvfile:\n",
    "                                reader = csv.reader(csvfile)\n",
    "                                first_row = next(reader, None)\n",
    "                                if first_row is None:  # If the file is empty\n",
    "                                    with open(csv_file, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                        # Write the header\n",
    "                                        writer.writerow(fieldnames)\n",
    "                                    with open(csv_file, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                        # Write the header\n",
    "                                        writer.writerow(new_row)\n",
    "\n",
    "                                            # Write the new row\n",
    "                                else:\n",
    "                                    with open(csv_file, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                        writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "                            print(\"New row appended successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            print(\"data is saved\")\n",
    "\n",
    "                            print(\"loop is continueing\")\n",
    "\n",
    "\n",
    "                            print(\"%\" * 100)\n",
    "                            print(\n",
    "                                \"4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\")\n",
    "\n",
    "                        else:\n",
    "                            if not if_part_executed:  # If the 'if' part hasn't executed in the first iteration\n",
    "\n",
    "                                check_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "                                new_row = {'Channel_Name': chhanel_name, 'yt_url': fixed_url,\n",
    "                                           'subscribers': subscribers,\n",
    "                                           'Check_Date': check_date, 'Released_Date': date,\n",
    "                                           'is_posted_in_date_range': \"No\",\n",
    "                                           'Shorts_Name': short_name,\n",
    "                                           'Description': description,\n",
    "                                           'Likes': likes, 'Views': veiws, 'short_url': link}\n",
    "\n",
    "                                print(\"Trying 5\")\n",
    "                                ############################################\n",
    "                                # Define the header and new row\n",
    "                                fieldnames = ['Channel_Name', 'yt_url', 'subscribers', 'Check_Date', 'Released_Date',\n",
    "                                              'is_posted_in_date_range', 'Shorts_Name', 'Description', 'Likes', 'Views',\n",
    "                                              'short_url']\n",
    "\n",
    "                                # Check if the file is empty\n",
    "                                with open(no_video_in_date_range1, 'r', encoding='utf-8', newline='') as csvfile:\n",
    "                                    reader = csv.reader(csvfile)\n",
    "                                    first_row = next(reader, None)\n",
    "                                    if first_row is None:  # If the file is empty\n",
    "                                        with open(csv_file, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                            writer.writeheader()  # Write the header\n",
    "                                            writer.writerow(new_row)  # Write the new row\n",
    "                                    else:\n",
    "                                        with open(no_video_in_date_range1, 'a', encoding='utf-8', newline='') as csvfile:\n",
    "                                            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                                            writer.writerow(new_row)  # Append the new row\n",
    "\n",
    "                                print(\"New row appended successfully.\")\n",
    "                                print(\"data is saved\")\n",
    "\n",
    "\n",
    "                                print(\"loop breaked\")\n",
    "\n",
    "                                print(\n",
    "                                    \"555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\")\n",
    "\n",
    "                                break\n",
    "                            if (date not in date_range) or (\"ago\"  not in date.lower()):\n",
    "                                print(\"breaking loop after saving data\")\n",
    "\n",
    "                                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd270e-29d2-44c4-a732-faa736dc003a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8fb804-c63c-4e5e-b691-4066ddec9e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58c590-9396-4bf5-b2a4-6035b3d05c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
