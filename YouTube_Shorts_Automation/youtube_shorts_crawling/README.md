# YouTube Shorts Crawling

This folder contains scripts and resources used for collecting YouTube Shorts data as part of the D'NOVA project. It includes both in-house and outsourced (freelancer) code, as well as reference documents and working materials.

## üìå Purpose

- Automate the collection of YouTube Shorts metadata (e.g., title, description, likes, comments).
- Maintain structured records of externally developed components (freelancer deliveries).
- Organize working files for cold outreach and internal planning.

## üìÅ Directory Structure

| Folder/File | Description |
|-------------|-------------|
| `Archive/` | Older scripts or results that are no longer actively used. |
| `change_fixed_url/` | Scripts related to fixed URL crawlers or hardcoded channel/video lists. |
| `scraperAPI/` | API-based crawling logic (e.g., using services like ScraperAPI or proxies). |
| `top_yt_shorts_crawling/` | Core scripts for extracting top YouTube Shorts by views, likes, or recency. |
| `README.md` | This file. |
| Other `.ppt`, `.docx`, `.pdf` files | Company-related documents such as:<br>‚Äì Service introduction decks<br>‚Äì Cold email copywriting<br>‚Äì Lists of target companies<br>‚Äì Marketing study materials<br>Most documents are managed primarily via Google Docs. |
| Fiverr code | Crawling code and outputs developed by freelancers. |

## üõ†Ô∏è Notes

- This folder includes contributions from external freelancers (e.g., via Fiverr).
- Some materials serve planning or outreach purposes and are not part of the executable pipeline.
- For current crawling pipelines, refer to `top_yt_shorts_crawling/`.

---

*For crawling updates or integration needs, contact the internal data team or check Google Docs for linked workflows.*
