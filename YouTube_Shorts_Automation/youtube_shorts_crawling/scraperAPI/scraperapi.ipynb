{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8d19d6",
   "metadata": {},
   "source": [
    "# Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2dca984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae8b7d",
   "metadata": {},
   "source": [
    "### Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97634441",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# short extraction parameters\n",
    "num_adtn_collect = 3\n",
    "collect_freq = 7\n",
    "# Seclare today time to fix the time range\n",
    "today = datetime.today()\n",
    "# Declare API Key\n",
    "API_KEY = '3397e8a6a37e89b03b08750a27575df8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99612920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국, 미국 데이터 9507개\n",
    "channel_df = pd.read_csv('us_korea_channels.csv')\n",
    "# channel_df = ch_df[81:]\n",
    "channel_df = channel_df.drop_duplicates(subset=['channel_name', 'yt_fixed_url'], keep='last')\n",
    "\n",
    "loaded_df = pd.read_csv(\"loaded_db.csv\")\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "try:\n",
    "    loaded_df['check_date'] = loaded_df['check_date'].dt.date\n",
    "    filter_dates = [today - timedelta(days=7), today - timedelta(days=14), today - timedelta(days=21)]\n",
    "    # Filter the dataframe based on check_date\n",
    "    loaded_df = loaded_df[loaded_df['check_date'].isin(filter_dates)]\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf5bd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>youtuberme_url</th>\n",
       "      <th>category</th>\n",
       "      <th>country</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>total_video_views</th>\n",
       "      <th>total_video_count</th>\n",
       "      <th>started</th>\n",
       "      <th>yt_url</th>\n",
       "      <th>yt_fixed_url</th>\n",
       "      <th>data_yn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://us.youtubers.me//robert-breaker/youtuber-stats</td>\n",
       "      <td>education</td>\n",
       "      <td>United States</td>\n",
       "      <td>Robert Breaker</td>\n",
       "      <td>702000.0</td>\n",
       "      <td>99929372.0</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>https://us.youtubers.me//robert-breaker/youtube</td>\n",
       "      <td>https://www.youtube.com/channel/UCPkTFG8FeBL6iR8YemTaMYQ/shorts</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://us.youtubers.me//nick-jones-00fc3f40-721a-488f-b594-a78beed97744/youtuber-stats</td>\n",
       "      <td>education</td>\n",
       "      <td>United States</td>\n",
       "      <td>Nick Jones</td>\n",
       "      <td>760000.0</td>\n",
       "      <td>99644730.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>https://us.youtubers.me//nick-jones-00fc3f40-721a-488f-b594-a78beed97744/youtube</td>\n",
       "      <td>https://www.youtube.com/channel/UCwfeFpvbkp8cgmJWaMO9K0g/shorts</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://us.youtubers.me//tactical-toolbox/youtuber-stats</td>\n",
       "      <td>education</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tactical Toolbox</td>\n",
       "      <td>957000.0</td>\n",
       "      <td>99603977.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>https://us.youtubers.me//tactical-toolbox/youtube</td>\n",
       "      <td>https://www.youtube.com/channel/UCM9IxdhUn4Sm8ITdod8Tm2Q/shorts</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://us.youtubers.me//steve-ram/youtuber-stats</td>\n",
       "      <td>education</td>\n",
       "      <td>United States</td>\n",
       "      <td>Steve Ram</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99339604.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>https://us.youtubers.me//steve-ram/youtube</td>\n",
       "      <td>https://www.youtube.com/channel/UC_9iG1I_ic5jUOyzR9vTMBg/shorts</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://us.youtubers.me//awesome-toys-tv/youtuber-stats</td>\n",
       "      <td>education</td>\n",
       "      <td>United States</td>\n",
       "      <td>So Sweet ASMR</td>\n",
       "      <td>907000.0</td>\n",
       "      <td>99023999.0</td>\n",
       "      <td>2619.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>https://us.youtubers.me//awesome-toys-tv/youtube</td>\n",
       "      <td>https://www.youtube.com/channel/UCrZfx6rscDd5qOdi5ni8rtg/shorts</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            youtuberme_url  \\\n",
       "0                                   https://us.youtubers.me//robert-breaker/youtuber-stats   \n",
       "1  https://us.youtubers.me//nick-jones-00fc3f40-721a-488f-b594-a78beed97744/youtuber-stats   \n",
       "2                                 https://us.youtubers.me//tactical-toolbox/youtuber-stats   \n",
       "3                                        https://us.youtubers.me//steve-ram/youtuber-stats   \n",
       "4                                  https://us.youtubers.me//awesome-toys-tv/youtuber-stats   \n",
       "\n",
       "    category        country      channel_name  subscribers  total_video_views  \\\n",
       "0  education  United States    Robert Breaker     702000.0         99929372.0   \n",
       "1  education  United States        Nick Jones     760000.0         99644730.0   \n",
       "2  education  United States  Tactical Toolbox     957000.0         99603977.0   \n",
       "3  education  United States         Steve Ram     500000.0         99339604.0   \n",
       "4  education  United States     So Sweet ASMR     907000.0         99023999.0   \n",
       "\n",
       "   total_video_count  started  \\\n",
       "0             1879.0   2009.0   \n",
       "1              485.0   2018.0   \n",
       "2              431.0   2006.0   \n",
       "3             2202.0   2016.0   \n",
       "4             2619.0   2014.0   \n",
       "\n",
       "                                                                             yt_url  \\\n",
       "0                                   https://us.youtubers.me//robert-breaker/youtube   \n",
       "1  https://us.youtubers.me//nick-jones-00fc3f40-721a-488f-b594-a78beed97744/youtube   \n",
       "2                                 https://us.youtubers.me//tactical-toolbox/youtube   \n",
       "3                                        https://us.youtubers.me//steve-ram/youtube   \n",
       "4                                  https://us.youtubers.me//awesome-toys-tv/youtube   \n",
       "\n",
       "                                                      yt_fixed_url data_yn  \n",
       "0  https://www.youtube.com/channel/UCPkTFG8FeBL6iR8YemTaMYQ/shorts       y  \n",
       "1  https://www.youtube.com/channel/UCwfeFpvbkp8cgmJWaMO9K0g/shorts       y  \n",
       "2  https://www.youtube.com/channel/UCM9IxdhUn4Sm8ITdod8Tm2Q/shorts       y  \n",
       "3  https://www.youtube.com/channel/UC_9iG1I_ic5jUOyzR9vTMBg/shorts       y  \n",
       "4  https://www.youtube.com/channel/UCrZfx6rscDd5qOdi5ni8rtg/shorts       y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb6275f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>shorts_url</th>\n",
       "      <th>shorts_title</th>\n",
       "      <th>shorts_description</th>\n",
       "      <th>shorts_thumbnail</th>\n",
       "      <th>shorts_view</th>\n",
       "      <th>shorts_likes</th>\n",
       "      <th>shorts_comments_num</th>\n",
       "      <th>shorts_comments_time</th>\n",
       "      <th>shorts_published_date</th>\n",
       "      <th>check_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert Breaker</td>\n",
       "      <td>https://www.youtube.com/watch?v=qc0iqmlAR38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube</td>\n",
       "      <td>6,422</td>\n",
       "      <td>264.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nick Jones</td>\n",
       "      <td>https://www.youtube.com/watch?v=fa_sSaHxTZ4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube</td>\n",
       "      <td>91,113</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steve Ram</td>\n",
       "      <td>https://www.youtube.com/watch?v=SqU7aeAPkrY</td>\n",
       "      <td>Will You Comply? New Coming Mandates in 2023</td>\n",
       "      <td>FULL VIDEO    • TRUMP BLASTS Bringing Back COVID Mand...  \\n\\nJoin this channel to get access to perks:\\n   / @steveram</td>\n",
       "      <td>https://rr4---sn-a5mlrnlz.googlevideo.com/videoplayback?expire=1730136361\\u0026ei=yXQfZ66mII7p9fwP5buhyAk\\u0026ip=88.80.138.153\\u0026id=o-ADGRnyRXXWs0ey6VgIAwD6jjYgDnlAPCHxJTkzJkl3op\\u0026itag=18\\u0026source=youtube\\u0026requiressl=yes\\u0026xpc=EgVo2aDSNQ%3D%3D\\u0026met=1730114761%2C\\u0026mh=aJ\\u0026mm=31%2C26\\u0026mn=sn-a5mlrnlz%2Csn-aigl6ned\\u0026ms=au%2Conr\\u0026mv=u\\u0026mvi=4\\u0026pl=24\\u0026rms=au%2Cau\\u0026bui=AQn3pFRkfuQgpTNQtV6Rx0EbF5Yc4uKr6aUfAnutSsW00_W-aS2OQMOFaE7gsVnw3NP65JrCNa4-KGwt\\u0026spc=qtApAeYZ-ZHwiV-OQpLGoJu6pxBfbDgbCbfueRn9EF3Kj1O_YEXP-RXwuN3Q9Ko\\u0026vprv=1\\u0026svpuc=1\\u0026mime=video%2Fmp4\\u0026ns=O-70yoh2uoVVRBz9uXYov70Q\\u0026rqh=1\\u0026cnr=14\\u0026ratebypass=yes\\u0026dur=27.028\\u0026lmt=1699161979496252\\u0026mt=1730113623\\u0026fvip=5\\u0026fexp=51312688%2C51326931\\u0026c=WEB\\u0026sefc=1\\u0026txp=6300224\\u0026n=6ETZCBPEcrdbd7kj\\u0026sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Ccnr%2Cratebypass%2Cdur%2Clmt\\u0026sig=AJfQdSswRAIgHhpJ1qfecSaSqCus0fZqWNcrOzdyPRqlySu9RmchW08CIDjeqaCim2fsX1d2kyDcMjiaMzHJ5PMQVuYu9TmqqzhL\\u0026lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms\\u0026lsig=ACJ0pHgwRgIhAONANxNBbu_SWBgC4wdGutJ5fFsXLMotTeJYmKk1wMJbAiEA98hcmjhkxEUyrMgrsEEBK2QLCYvssCkbuRNtM-x0rr0%3D</td>\n",
       "      <td>56,703</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-04 15</td>\n",
       "      <td>2024-10-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So Sweet ASMR</td>\n",
       "      <td>https://www.youtube.com/watch?v=k27UsRRjC5g</td>\n",
       "      <td>ASMR Marble run #marblerun #asmr</td>\n",
       "      <td>ASMR Marble run #marblerun #asmr</td>\n",
       "      <td>https://rr1---sn-vgqsknez.googlevideo.com/videoplayback?expire=1730136367\\u0026ei=z3QfZ8qpLaveybgP4OWv8A8\\u0026ip=71.4.186.115\\u0026id=o-AGLlhTYSO80LtXyVwaPBGbJYxUwygCN8TM1d-DXioC0f\\u0026itag=18\\u0026source=youtube\\u0026requiressl=yes\\u0026xpc=EgVo2aDSNQ%3D%3D\\u0026met=1730114767%2C\\u0026mh=lN\\u0026mm=31%2C26\\u0026mn=sn-vgqsknez%2Csn-p5qddn7r\\u0026ms=au%2Conr\\u0026mv=u\\u0026mvi=1\\u0026pl=21\\u0026rms=au%2Cau\\u0026bui=AQn3pFS3Hz6UofnuTnhzhIHgQ2I4S2cXpFEYnxTsghTaDqOHyGlPyEFUXzQWm-gnWGYn0yfh-3jQ8NFh\\u0026spc=qtApAY2nxRS4poXQExTgxfNVGGVxdhlokeTGd5KfjP5h48RoEKRk4QgGrRqqEGA\\u0026vprv=1\\u0026svpuc=1\\u0026mime=video%2Fmp4\\u0026ns=VOstOVf9Rc6ykhAlGFFx9oAQ\\u0026rqh=1\\u0026gir=yes\\u0026clen=537287\\u0026ratebypass=yes\\u0026dur=15.168\\u0026lmt=1720022156668305\\u0026mt=1730113623\\u0026fvip=4\\u0026fexp=51264009%2C51312688%2C51326931\\u0026c=WEB\\u0026sefc=1\\u0026txp=6300224\\u0026n=WJ2bpJvqGE_qtbq2\\u0026sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt\\u0026sig=AJfQdSswRQIhAM6_54omB-ct_OuFjld8bTeU3YM9Sr9zV5A7dVNglygKAiBIoGr0ccLa9ggeBDU7yByufNgLXpuADZum_H9yGuUmeA%3D%3D\\u0026lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms\\u0026lsig=ACJ0pHgwRQIgZ7Os0lyhs_TXGgXsrEL9HKC-C7RlqvFUSHvRXge_TBcCIQCnjWVIdtaoKHs2V9opF3dVuns2pwCD6qF6V2Srt9l08w%3D%3D</td>\n",
       "      <td>12,582</td>\n",
       "      <td>236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-03 08</td>\n",
       "      <td>2024-10-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English with Jennifer</td>\n",
       "      <td>https://www.youtube.com/watch?v=7L3CTSU7MqU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-28 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            channel_name                                   shorts_url  \\\n",
       "0         Robert Breaker  https://www.youtube.com/watch?v=qc0iqmlAR38   \n",
       "1             Nick Jones  https://www.youtube.com/watch?v=fa_sSaHxTZ4   \n",
       "2              Steve Ram  https://www.youtube.com/watch?v=SqU7aeAPkrY   \n",
       "3          So Sweet ASMR  https://www.youtube.com/watch?v=k27UsRRjC5g   \n",
       "4  English with Jennifer  https://www.youtube.com/watch?v=7L3CTSU7MqU   \n",
       "\n",
       "                                   shorts_title  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2  Will You Comply? New Coming Mandates in 2023   \n",
       "3              ASMR Marble run #marblerun #asmr   \n",
       "4                                           NaN   \n",
       "\n",
       "                                                                                                          shorts_description  \\\n",
       "0                                                                                                                        NaN   \n",
       "1                                                                                                                        NaN   \n",
       "2  FULL VIDEO    • TRUMP BLASTS Bringing Back COVID Mand...  \\n\\nJoin this channel to get access to perks:\\n   / @steveram     \n",
       "3                                                                                           ASMR Marble run #marblerun #asmr   \n",
       "4                                                                                                                        NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 shorts_thumbnail  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube   \n",
       "2                                               https://rr4---sn-a5mlrnlz.googlevideo.com/videoplayback?expire=1730136361\\u0026ei=yXQfZ66mII7p9fwP5buhyAk\\u0026ip=88.80.138.153\\u0026id=o-ADGRnyRXXWs0ey6VgIAwD6jjYgDnlAPCHxJTkzJkl3op\\u0026itag=18\\u0026source=youtube\\u0026requiressl=yes\\u0026xpc=EgVo2aDSNQ%3D%3D\\u0026met=1730114761%2C\\u0026mh=aJ\\u0026mm=31%2C26\\u0026mn=sn-a5mlrnlz%2Csn-aigl6ned\\u0026ms=au%2Conr\\u0026mv=u\\u0026mvi=4\\u0026pl=24\\u0026rms=au%2Cau\\u0026bui=AQn3pFRkfuQgpTNQtV6Rx0EbF5Yc4uKr6aUfAnutSsW00_W-aS2OQMOFaE7gsVnw3NP65JrCNa4-KGwt\\u0026spc=qtApAeYZ-ZHwiV-OQpLGoJu6pxBfbDgbCbfueRn9EF3Kj1O_YEXP-RXwuN3Q9Ko\\u0026vprv=1\\u0026svpuc=1\\u0026mime=video%2Fmp4\\u0026ns=O-70yoh2uoVVRBz9uXYov70Q\\u0026rqh=1\\u0026cnr=14\\u0026ratebypass=yes\\u0026dur=27.028\\u0026lmt=1699161979496252\\u0026mt=1730113623\\u0026fvip=5\\u0026fexp=51312688%2C51326931\\u0026c=WEB\\u0026sefc=1\\u0026txp=6300224\\u0026n=6ETZCBPEcrdbd7kj\\u0026sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Ccnr%2Cratebypass%2Cdur%2Clmt\\u0026sig=AJfQdSswRAIgHhpJ1qfecSaSqCus0fZqWNcrOzdyPRqlySu9RmchW08CIDjeqaCim2fsX1d2kyDcMjiaMzHJ5PMQVuYu9TmqqzhL\\u0026lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms\\u0026lsig=ACJ0pHgwRgIhAONANxNBbu_SWBgC4wdGutJ5fFsXLMotTeJYmKk1wMJbAiEA98hcmjhkxEUyrMgrsEEBK2QLCYvssCkbuRNtM-x0rr0%3D   \n",
       "3  https://rr1---sn-vgqsknez.googlevideo.com/videoplayback?expire=1730136367\\u0026ei=z3QfZ8qpLaveybgP4OWv8A8\\u0026ip=71.4.186.115\\u0026id=o-AGLlhTYSO80LtXyVwaPBGbJYxUwygCN8TM1d-DXioC0f\\u0026itag=18\\u0026source=youtube\\u0026requiressl=yes\\u0026xpc=EgVo2aDSNQ%3D%3D\\u0026met=1730114767%2C\\u0026mh=lN\\u0026mm=31%2C26\\u0026mn=sn-vgqsknez%2Csn-p5qddn7r\\u0026ms=au%2Conr\\u0026mv=u\\u0026mvi=1\\u0026pl=21\\u0026rms=au%2Cau\\u0026bui=AQn3pFS3Hz6UofnuTnhzhIHgQ2I4S2cXpFEYnxTsghTaDqOHyGlPyEFUXzQWm-gnWGYn0yfh-3jQ8NFh\\u0026spc=qtApAY2nxRS4poXQExTgxfNVGGVxdhlokeTGd5KfjP5h48RoEKRk4QgGrRqqEGA\\u0026vprv=1\\u0026svpuc=1\\u0026mime=video%2Fmp4\\u0026ns=VOstOVf9Rc6ykhAlGFFx9oAQ\\u0026rqh=1\\u0026gir=yes\\u0026clen=537287\\u0026ratebypass=yes\\u0026dur=15.168\\u0026lmt=1720022156668305\\u0026mt=1730113623\\u0026fvip=4\\u0026fexp=51264009%2C51312688%2C51326931\\u0026c=WEB\\u0026sefc=1\\u0026txp=6300224\\u0026n=WJ2bpJvqGE_qtbq2\\u0026sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt\\u0026sig=AJfQdSswRQIhAM6_54omB-ct_OuFjld8bTeU3YM9Sr9zV5A7dVNglygKAiBIoGr0ccLa9ggeBDU7yByufNgLXpuADZum_H9yGuUmeA%3D%3D\\u0026lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms\\u0026lsig=ACJ0pHgwRQIgZ7Os0lyhs_TXGgXsrEL9HKC-C7RlqvFUSHvRXge_TBcCIQCnjWVIdtaoKHs2V9opF3dVuns2pwCD6qF6V2Srt9l08w%3D%3D   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             NaN   \n",
       "\n",
       "  shorts_view  shorts_likes  shorts_comments_num  shorts_comments_time  \\\n",
       "0       6,422         264.0                 16.0                   NaN   \n",
       "1      91,113       17000.0                553.0                   NaN   \n",
       "2      56,703        3200.0                504.0                   NaN   \n",
       "3      12,582         236.0                  3.0                   NaN   \n",
       "4         NaN           NaN                  NaN                   NaN   \n",
       "\n",
       "  shorts_published_date           check_date  \n",
       "0                   NaN  2024-10-28 00:00:00  \n",
       "1                   NaN  2024-10-28 00:00:00  \n",
       "2         2023-09-04 15  2024-10-28 00:00:00  \n",
       "3         2024-07-03 08  2024-10-28 00:00:00  \n",
       "4                   NaN  2024-10-28 00:00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7199c966",
   "metadata": {},
   "source": [
    "# 2.Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cd1fc",
   "metadata": {},
   "source": [
    "### 2_1. PreProcess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4203d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE: Parse to string date \n",
    "def to_strdata(date):\n",
    "    if isinstance(date, datetime):\n",
    "        date = date.strftime('%Y-%m-%d')\n",
    "    return date\n",
    "\n",
    "\n",
    "# Updated function to include the <link rel=\"image_src\" ...> part in the thumbnail extraction\n",
    "def basic_shorts_info(text):\n",
    "    # Shorts title\n",
    "    match_title = re.search(r'<title>(.*?) - YouTube</title>', text)\n",
    "    extracted_title = match_title.group(1) if match_title else np.nan\n",
    "\n",
    "    # Shorts description\n",
    "    description_pattern = r'attributedDescription\":{\"content\":\"(.*?)\"'\n",
    "    description_match = re.search(description_pattern, text)\n",
    "    extracted_description = description_match.group(1) if description_match else None\n",
    "    \n",
    "    # Shorts total view (date and time)\n",
    "    date_time_pattern = r'datePublished\" content=\"(\\d{4}-\\d{2}-\\d{2})T(\\d{2}):'\n",
    "    match_date = re.search(date_time_pattern, text)\n",
    "    extracted_published = f\"{match_date.group(1)} {match_date.group(2)}\" if match_date else np.nan\n",
    "\n",
    "    # Thumbnail (updated pattern to include <link rel=\"image_src\" ...)\n",
    "    thumbnail_pattern = r'<link rel=\"image_src\" href=\"(https?://i\\.ytimg\\.com/vi/[^/]+/maxres2\\.jpg\\?[^\"]+)\"'\n",
    "    thumbnail_match = re.search(thumbnail_pattern, text)\n",
    "    yt_shorts_thumbnail = thumbnail_match.group(1) if thumbnail_match else np.nan\n",
    "\n",
    "    # Total view\n",
    "    view_pattern = r'\"viewCountEntityKey\":\"[^\"]+\",\"factoid\":\\{\"factoidRenderer\":\\{\"value\":\\{\"simpleText\":\"([\\d,]+)\"'\n",
    "    view_match = re.search(view_pattern, text)\n",
    "    extracted_view = view_match.group(1) if view_match else np.nan\n",
    "\n",
    "    # Total likes\n",
    "    like_pattern = r'\"iconName\":\"LIKE\",\"title\":\"([\\d.]+)([KM]?)\"'\n",
    "    like_match = re.search(like_pattern, text)\n",
    "    if like_match:\n",
    "        extracted_likes = float(like_match.group(1))\n",
    "        suffix = like_match.group(2)\n",
    "        if suffix == 'K':\n",
    "            extracted_likes *= 1000\n",
    "        elif suffix == 'M':\n",
    "            extracted_likes *= 1000000\n",
    "    else:\n",
    "        extracted_likes = np.nan\n",
    "\n",
    "    # Total comments    \n",
    "    comment_num_pattern = r'\"text\":\"Comments\"}\\]},\"contextualInfo\":\\{\"runs\":\\[\\{\"text\":\"([\\d.]+)([KM]?)\"'\n",
    "    comment_num_match = re.search(comment_num_pattern, text)\n",
    "    if comment_num_match:\n",
    "        extracted_comments_number = float(comment_num_match.group(1))\n",
    "        suffix = comment_num_match.group(2)\n",
    "        if suffix == 'K':\n",
    "            extracted_comments_number *= 1000\n",
    "        elif suffix == 'M':\n",
    "            extracted_comments_number *= 1000000\n",
    "    else:\n",
    "        extracted_comments_number = np.nan\n",
    "\n",
    "    # YT shorts comment results and comment creation time\n",
    "    comments_time_text_pattern = r'<span[^>]*id=\"published-time-text\"[^>]*>\\s*<a[^>]*>\\s*(.*?)\\s*<\\/a>.*?<yt-attributed-string[^>]*>\\s*<span[^>]*class=\"yt-core-attributed-string yt-core-attributed-string--white-space-pre-wrap\"[^>]*>\\s*(.*?)\\s*<\\/span>'\n",
    "    \n",
    "    comments_time_matches = re.findall(comments_time_text_pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Process and clean comments\n",
    "    extracted_comments_time_matches = []\n",
    "    if comments_time_matches:\n",
    "        for time, comment in comments_time_matches:\n",
    "            soup = BeautifulSoup(comment, 'html.parser')\n",
    "            cleaned_comment = soup.get_text()\n",
    "            extracted_comments_time_matches.append((time.strip(), cleaned_comment.strip()))\n",
    "    else:\n",
    "        extracted_comments_time_matches = np.nan\n",
    "\n",
    "    return (extracted_title, extracted_description, extracted_published, yt_shorts_thumbnail, \n",
    "            extracted_view, extracted_likes, extracted_comments_number, extracted_comments_time_matches)\n",
    "\n",
    "\n",
    "def convert_subscribers(subscriber_text):\n",
    "    \"\"\"Convert subscriber text to a numeric value.\"\"\"\n",
    "    if 'K' in subscriber_text:\n",
    "        return int(float(subscriber_text.replace('K', '').strip()) * 1000)\n",
    "    elif 'M' in subscriber_text:\n",
    "        return int(float(subscriber_text.replace('M', '').strip()) * 1000000)\n",
    "    return int(subscriber_text.strip())\n",
    "\n",
    "def extract_total_video_count(video_text):\n",
    "    \"\"\"Extract total video count as an integer from the input text.\"\"\"\n",
    "    # Check for formats like '3.1K' and convert accordingly\n",
    "    if 'K' in video_text:\n",
    "        return int(float(video_text.replace('K', '').strip()) * 1000)\n",
    "    elif 'M' in video_text:\n",
    "        return int(float(video_text.replace('M', '').strip()) * 1000000)\n",
    "    number_pattern = r'(\\d+) videos'\n",
    "    match = re.search(number_pattern, video_text)\n",
    "    return int(match.group(1)) if match else None  # Return the number part if found\n",
    "\n",
    "def extract_description(description_text):\n",
    "    \"\"\"Extract description from the HTML content.\"\"\"\n",
    "    lines = description_text.splitlines()\n",
    "    first_line = lines[0].strip() if len(lines) > 0 else None\n",
    "    second_line = lines[1].strip() if len(lines) > 1 else None\n",
    "    return first_line, second_line  # Get the first two lines\n",
    "#################################################################3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c76cf7",
   "metadata": {},
   "source": [
    "### 2_2. Scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2616da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Scraping code #################################\n",
    "\n",
    "# 페이지 스크래핑 함수\n",
    "def scrape_page(url):\n",
    "    scraper_api_url = 'https://api.scraperapi.com'\n",
    "    params = {\n",
    "        'api_key': API_KEY,\n",
    "        'url': url,\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(scraper_api_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Successfully scraped: {url}\")\n",
    "            return {\"url\": url, \"status\": \"success\", \"content\": response.text}\n",
    "        else:\n",
    "            print(f\"Failed to scrape {url}: Status {response.status_code}\")\n",
    "            return {\"url\": url, \"status\": \"failed\", \"status_code\": response.status_code}\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return {\"url\": url, \"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "# 배치 스크래핑 함수\n",
    "def scrape_batch(urls, requests_per_second):\n",
    "    # list to save data\n",
    "    results = []\n",
    "    # perform concurrent calls\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=requests_per_second) as executor:\n",
    "        futures = []\n",
    "        for url in urls:\n",
    "            futures.append(executor.submit(scrape_page, url))\n",
    "            time.sleep(1 / requests_per_second)  # 초당 요청 제한\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            results.append(future.result())\n",
    "    return results\n",
    "\n",
    "# 전체 URL을 배치로 나누고 스크래핑 실행\n",
    "    # url_data : list of url\n",
    "    \n",
    "def scrape_all_urls(url_data, batch_size, requests_per_second):\n",
    "    # 전체 URL 수\n",
    "    total_urls_len = len(url_data)\n",
    "    print(f'Total url length: {total_urls_len}')\n",
    "    \n",
    "    # number of batches for 101 urls, 50 batchs -> 3 \n",
    "    num_batches = ceil(total_urls_len / batch_size)\n",
    "    \n",
    "    # save all results\n",
    "    all_results = []\n",
    "    \n",
    "    # start batch for each iternation\n",
    "    for batch_num in range(num_batches):\n",
    "        \n",
    "        # batch start index 0, 50, 100...\n",
    "        start_idx = batch_num * batch_size\n",
    "        \n",
    "        # end index \n",
    "        # 50, 100 \n",
    "        end_idx = min((batch_num + 1) * batch_size, total_urls_len)\n",
    "        \n",
    "        # get urls form the url data\n",
    "        #batch_urls = url_data['youtuberme_url'].iloc[start_idx:end_idx].tolist()\n",
    "        batch_urls = url_data[start_idx:end_idx].tolist()\n",
    "        \n",
    "        print(f\"Scraping batch {batch_num + 1}/{num_batches}, URLs {start_idx + 1}-{end_idx}\")\n",
    "        \n",
    "        # get batch results\n",
    "        batch_results = scrape_batch(batch_urls, requests_per_second)\n",
    "        all_results.extend(batch_results)\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "######################## End of scraping code #################################\n",
    "\n",
    "\n",
    "def scanning_yt_shorts_page(api_key, channel_db, loaded_db):\n",
    "    # List to store new shorts results in the format (channel_name, new_shorts_url)\n",
    "    new_shorts_urls = []\n",
    "    # List to store channels with no shorts_urls\n",
    "    no_shorts_list = []\n",
    "    \n",
    "    # Initialize a list for the additional DataFrame\n",
    "    additional_data = []\n",
    "\n",
    "    # Iterate over each row in channel_db\n",
    "    for index, row in channel_db.iterrows():\n",
    "        # Only proceed if data_yn is \"y\"\n",
    "        if row['data_yn'] != 'y':\n",
    "            continue  # Skip the row if data_yn is not \"y\"\n",
    "        \n",
    "        channel_name = row['channel_name']\n",
    "        yt_fixed_url = row['yt_fixed_url']\n",
    "        print(channel_name)\n",
    "        # Filter loaded_db where channel_name matches\n",
    "        matching_rows = loaded_db[loaded_db['channel_name'] == channel_name]\n",
    "        \n",
    "        if not matching_rows.empty:\n",
    "            # Sort by check_date to get the most recent row\n",
    "            latest_row = matching_rows.sort_values(by='check_date', ascending=False).iloc[0]\n",
    "            latest_url = latest_row['shorts_url']\n",
    "        else:\n",
    "            # If no match found in loaded_db, set latest_url to None to ensure data collection proceeds\n",
    "            latest_url = None\n",
    "        \n",
    "        # Prepare the payload for ScraperAPI request, using yt_fixed_url\n",
    "        payload = {\n",
    "            'api_key': api_key,\n",
    "            'url': yt_fixed_url\n",
    "        }\n",
    "        \n",
    "        # Send the request to ScraperAPI\n",
    "        r = requests.get('https://api.scraperapi.com/', params=payload, verify=False)\n",
    "        \n",
    "        # Define the regex pattern to extract Shorts URLs\n",
    "        shorts_url_pattern = r'webCommandMetadata\":{\"url\":\"(/shorts/\\w+)\"'\n",
    "        # Find all matching Shorts URLs\n",
    "        shorts_urls = re.findall(shorts_url_pattern, r.text)\n",
    "        shorts_urls = ['https://www.youtube.com' + url.replace('/shorts/', '/watch?v=') for url in shorts_urls]\n",
    "\n",
    "        print(f\"shorts_urls for {channel_name}: \", shorts_urls)\n",
    "\n",
    "        # Extract subscribers\n",
    "        subscribers_pattern = r'(\\d+K|\\d+M|\\d+) subscribers'\n",
    "        subscribers_match = re.search(subscribers_pattern, r.text)\n",
    "        last_subscribers = convert_subscribers(subscribers_match.group(1)) if subscribers_match else None\n",
    "        \n",
    "        # Extract total video count with the required prefix\n",
    "        total_video_count_pattern = r'{\"text\":{\"content\":\"([\\d.]+[K|M]?) videos\"'\n",
    "        total_video_count_match = re.search(total_video_count_pattern, r.text)\n",
    "        last_total_videos = extract_total_video_count(total_video_count_match.group(1)) if total_video_count_match else None\n",
    "        \n",
    "        # Extract description\n",
    "        description_pattern = r'itemprop=\"description\" content=\"(.*?)\"'\n",
    "        description_match = re.search(description_pattern, r.text, re.DOTALL)\n",
    "        last_description = extract_description(description_match.group(1)) if description_match else (None, None)\n",
    "\n",
    "        # Store the data for the DataFrame\n",
    "        additional_data.append({\n",
    "            'channel_name': channel_name,\n",
    "            'yt_fixed_url': yt_fixed_url,\n",
    "            'subscribers': last_subscribers,\n",
    "            'total_video_count': last_total_videos,\n",
    "            'description': last_description[0]  # Assuming we want the first line of the description\n",
    "        })\n",
    "\n",
    "        # Proceed based on shorts_urls availability\n",
    "        if shorts_urls:\n",
    "            if latest_url and latest_url in shorts_urls:\n",
    "                # If there's a match, get all URLs before the latest one\n",
    "                matching_index = shorts_urls.index(latest_url)\n",
    "                for shorts_url in shorts_urls[:matching_index]:\n",
    "                    new_shorts_urls.append((channel_name, shorts_url))\n",
    "            else:\n",
    "                # If no latest URL or no match in loaded_db, collect the first URL\n",
    "                new_shorts_urls.append((channel_name, shorts_urls[0]))\n",
    "        else:\n",
    "            # If shorts_urls is empty, add the channel_name and yt_fixed_url to the no_shorts_list\n",
    "            no_shorts_list.append((channel_name, yt_fixed_url))\n",
    "    \n",
    "    # Convert the no_shorts_list to a DataFrame\n",
    "    no_shorts_df = pd.DataFrame(no_shorts_list, columns=['channel_name', 'yt_fixed_url'])\n",
    "    \n",
    "    # Create a DataFrame from the additional data\n",
    "    df = pd.DataFrame(additional_data)\n",
    "\n",
    "    return new_shorts_urls, no_shorts_df, df  # Return both the list, no_shorts DataFrame, and additional DataFrame\n",
    "\n",
    "\n",
    "def update_channel_df_with_new_data(ch_df, new_data):\n",
    "    \"\"\"\n",
    "    Update the channel DataFrame with new data based on matching channel names.\n",
    "    \n",
    "    Parameters:\n",
    "    ch_df (pd.DataFrame): The original channel DataFrame to be updated.\n",
    "    new_data (pd.DataFrame): The new data DataFrame containing updated information.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The updated channel DataFrame.\n",
    "    \"\"\"\n",
    "    for index, new_row in new_data.iterrows():\n",
    "        channel_name = new_row['channel_name']\n",
    "\n",
    "        # Find matching channel in channel_df\n",
    "        matching_row = ch_df[ch_df['channel_name'] == channel_name]\n",
    "\n",
    "        if not matching_row.empty:\n",
    "            # Update values if they're NaN or if the new value is not NaN\n",
    "            ch_df.loc[ch_df['channel_name'] == channel_name, 'subscribers'] = (\n",
    "                new_row['subscribers'] if pd.notna(new_row['subscribers']) else ch_df.loc[ch_df['channel_name'] == channel_name, 'subscribers']\n",
    "            )\n",
    "            \n",
    "            ch_df.loc[ch_df['channel_name'] == channel_name, 'total_video_count'] = (\n",
    "                new_row['total_video_count'] if pd.notna(new_row['total_video_count']) else ch_df.loc[ch_df['channel_name'] == channel_name, 'total_video_count']\n",
    "            )\n",
    "    \n",
    "    return ch_df\n",
    "\n",
    "def update_channel_df_with_new_shorts(df, new_shorts_urls_df):\n",
    "    # Iterate over each row in new_shorts_urls_df to match with channel_df\n",
    "    for index, row in new_shorts_urls_df.iterrows():\n",
    "        target_channel_name = row['channel_name']\n",
    "        \n",
    "        # Update 'data_yn' in channel_df where 'channel_name' matches\n",
    "        df.loc[df['channel_name'] == target_channel_name, 'data_yn'] = 'n'\n",
    "\n",
    "    # Return the updated channel_df with all rows\n",
    "    return df\n",
    "\n",
    "# url 여러개 진행\n",
    "def add_new_shorts_data(api_key, urls):\n",
    "    data_list = []\n",
    "    check_date = today\n",
    "    # Separate channel names and shorts URLs\n",
    "    channel_names = [item[0] for item in urls]\n",
    "    shorts_urls = [item[1] for item in urls]\n",
    "    \n",
    "    for channel_name, url in zip(channel_names, shorts_urls):\n",
    "        print(channel_name, url)\n",
    "        shorts_url = url\n",
    "        # Prepare payload and headers for the request\n",
    "        payload = {\n",
    "            'api_key': api_key,\n",
    "            'url': url\n",
    "            # ,'render': 'true'\n",
    "        }\n",
    "        # Make the GET request\n",
    "        r = requests.get('https://api.scraperapi.com/', params=payload,  verify=False)\n",
    "        # Extract the necessary data\n",
    "        shorts_title, shorts_description, shorts_published, shorts_thumbnail, shorts_view, shorts_likes, shorts_comments_num, shorts_comments_time = basic_shorts_info(r.text)\n",
    "        \n",
    "        # Print the extracted information for debugging\n",
    "        # print(\"title: \", channel_name)\n",
    "        # print(\"shorts_title: \", shorts_title)\n",
    "        # print(\"shorts_description: \", shorts_description)\n",
    "        # print(\"shorts_published: \", shorts_published)\n",
    "        # print(\"shorts_thumbnalil: \", shorts_thumbnail)\n",
    "        # print(\"view: \", shorts_view)\n",
    "        # print(\"likes: \", shorts_likes)\n",
    "        # print(\"comments: \", shorts_comments_num)\n",
    "        # print(\"shorts_comments_time: \", shorts_comments_time)\n",
    "\n",
    "        # Append as a tuple to the data_list\n",
    "        data_list.append((\n",
    "            channel_name,\n",
    "            shorts_url, \n",
    "            shorts_title,  \n",
    "            shorts_description, \n",
    "            shorts_thumbnail, \n",
    "            shorts_view, \n",
    "            shorts_likes, \n",
    "            shorts_comments_num, \n",
    "            shorts_comments_time,\n",
    "            shorts_published, \n",
    "            check_date\n",
    "\n",
    "        ))\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "# 추가된 데이터 dataframe으로 loaed_db에 추가\n",
    "def add_new_data_to_loaded_db(data_list, loaded_db):\n",
    "    # Define the columns for the DataFrame\n",
    "    columns = [\n",
    "        'channel_name', 'shorts_url', 'shorts_title', 'shorts_description', \n",
    "        'shorts_thumbnail', 'shorts_view', 'shorts_likes', \n",
    "        'shorts_comments_num', 'shorts_comments_time', \n",
    "        'shorts_published_date', 'check_date'\n",
    "    ]\n",
    "    \n",
    "    # Map the data_list to the correct columns and create a new DataFrame\n",
    "    new_data_df = pd.DataFrame(data_list, columns=columns)\n",
    "    \n",
    "    # Append the new data to the loaded_db DataFrame\n",
    "    updated_loaded_db = pd.concat([loaded_db, new_data_df], ignore_index=True)\n",
    "    \n",
    "    return updated_loaded_db\n",
    "\n",
    "\n",
    "\n",
    "def collecting_past_shorts(api_key, loaded_df):    \n",
    "    # Convert 'today' to a datetime object from the 'yyyy-mm-dd' format\n",
    "    today_date = datetime.strptime(today, \"%Y-%m-%d\")\n",
    "    #today_date = today.strftime(\"%Y-%m-%d\")\n",
    "    # Iterate over each row in loaded_df, checking check_date and shorts_url\n",
    "    for idx, (check_dt, shorts_url) in enumerate(zip(loaded_df['check_date'], loaded_df['shorts_url'])):\n",
    "        # Convert check_dt to datetime format for comparison\n",
    "        check_dt_date = datetime.strptime(check_dt, \"%Y-%m-%d\") if isinstance(check_dt, str) else check_dt\n",
    "        \n",
    "        # Check if check_dt matches any of the past intervals (7, 14, or 21 days ago)\n",
    "        if check_dt_date in [today_date - timedelta(days=days) for days in [7, 14, 21]]:\n",
    "            payload = {\n",
    "                'api_key': api_key,\n",
    "                'url': shorts_url\n",
    "            }\n",
    "            \n",
    "            # Send the request\n",
    "            r = requests.get('https://api.scraperapi.com/', params=payload, verify=False)\n",
    "\n",
    "            # Extract relevant information from the response\n",
    "            yt_title, yt_shorts_description, yt_shorts_published, yt_shorts_thumbnail, yt_shorts_view, yt_shorts_likes, yt_shorts_comments_num, yt_shorts_comments_time = basic_shorts_info(r.text)\n",
    "            \n",
    "            # Prepare new row with updated values (keeping the same channel name and other values from loaded_df)\n",
    "            new_row = {\n",
    "                'channel_name': loaded_df.loc[idx, 'channel_name'], \n",
    "                'shorts_url': shorts_url, \n",
    "                'shorts_title': yt_title,\n",
    "                'shorts_description': yt_shorts_description,\n",
    "                'shorts_thumbnail': yt_shorts_thumbnail,\n",
    "                'shorts_view': yt_shorts_view,\n",
    "                'shorts_likes': yt_shorts_likes,\n",
    "                'shorts_comments': yt_shorts_comments_num,\n",
    "                'shorts_comments_time': yt_shorts_comments_time,\n",
    "                'shorts_published_date': yt_shorts_published,\n",
    "                'check_date': today  # Use today's date for the new check_date\n",
    "            }\n",
    "            \n",
    "            # Append the new row to the DataFrame\n",
    "            loaded_df = loaded_df.append(new_row, ignore_index=True)\n",
    "        else:\n",
    "            print(\"no data\")\n",
    "            pass\n",
    "\n",
    "    return loaded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaf44e5",
   "metadata": {},
   "source": [
    "### Collect new shorts urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f533636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total url length: 112\n",
      "Scraping batch 1/3, URLs 1-50\n",
      "Successfully scraped: https://www.youtube.com/channel/UCWTFGPpNQ0Ms6afXhaWDiRw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCFIRm1Fv1VC4DZxmYyvNOTQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCWhKFUSIbtGK1CANZjwTgsA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCrtd2wePvAl6RN_D-9jWVQQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCwfeFpvbkp8cgmJWaMO9K0g/shortsSuccessfully scraped: https://www.youtube.com/channel/UCaapxaQKJFJ6XC56CHgeTzw/shorts\n",
      "\n",
      "Successfully scraped: https://www.youtube.com/channel/UCL5Hf6_JIzb3HpiJQGqs8cQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCB3jUEyCLRbCw7QED0vnXYg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UChPVoBpjfJngjoKjxrwGSTw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCrZfx6rscDd5qOdi5ni8rtg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC08Ti1qPyHfHSjUnOHNlEaw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCKJOEv8ymPEmTE-zWAsBimw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC-TfjGnWhxI79Nw6GxwfOpA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCQsYAEW0n3tGsRfMVfIRzRw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCG1uayRlzz3ahT8ISRdyw7Q/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCI0wUrfRUN2F-5G_AgTpR-w/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC_NHdxyV_HzFkLgFvyYIP4Q/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCEKXieT70wByfvZwP1CxdPQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCoeJKtPJLoIBqWq4o8TDLpA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC7xiEjMTy-8EvujnY4K6Mvw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCGxNgUiosK3KImnLoOQTtkg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCc11676iKpKrJMYqNYHqNig/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCl-J-ovSJhA3or73Q2uVpow/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC_9iG1I_ic5jUOyzR9vTMBg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCM9IxdhUn4Sm8ITdod8Tm2Q/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC1LpsuAUaKoMzzJSEt5WImw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCHfY_EOzB1i57hYLSw_rYMg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCPkTFG8FeBL6iR8YemTaMYQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCzMvqwt21xqm7Fg5Uo3lsRQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC8XjmAEDVZSCQjI150cb4QA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCJLMboBYME_CLEfwsduI0wQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCct9aR7HC79Cv2g-9oDOTLw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCdvO5cIFPdFDhXDzs1WrbZw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC3KD-V1QgBMmlOOZaINfuGg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC0p8yCPxPjlPwJ81dGxCHoA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCikzJG7RbnNZhKLqqaXRM6A/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC9Pbt3q-ihROg1lmmmQdU2w/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCLKZ20yD2tNMBOkSDZo4FeQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCcuGKGOhMfwlkrYxpc_r-mw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UClvwNCja3aXxqiFrsKC1DPQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCUxQWmWk1_Hk9iDRKvhH29Q/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCV0OPCa5_LS8SWp118FRHIA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCS0N5baNlQWJCUrhCEo8WlA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCKtu_JtQCY0yryIy6zK4ZCg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC8FnQA_ZSeHwxAX9igzyeCg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCWfujqUxO6s5mLKkqvGeGyQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCyBZhSDikA9WsUyC_CqO7nQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCTOoRgpHTjAQPk6Ak70u-pA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCkgElsjGDR4Pw7vAd1baQ5g/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCxdMiqKX7PQuwN53qM0kRZQ/shorts\n",
      "Scraping batch 2/3, URLs 51-100\n",
      "Successfully scraped: https://www.youtube.com/channel/UCIhjNQgYHjxT2XW28frlGsg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCoZa2ULJBElSDQCHUMyXj4w/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCy6Lo9T1wmY26leaLJ6MBWA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCJ_LA5iTmFyAQMXA5ekWpXA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC5bp5_6h-ZxkBz6S_33ZUVg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC0JB7TSe49lg56u6qH8y_MQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC_oqZXtcxfJTaw1j2M1H1XQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCHF88ovEEPETzNtEUbgGBuw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCgntwWFdMDPq0eNhaQ0LHIQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCsOeo1CtwMwF95aBr-RawyA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCXSVZTsqJn5JjN0h5q5_B_Q/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC556b-Cl0Fp02iMc96yoJbg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCX-sMuCMrAKevkaZIIfvgrA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCVeW9qkBjo3zosnqUbG7CFw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCxmEEGYXJkgJJO12nJhXl5g/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCOaof-3dr6b7dFIxNP_1Wlw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCmsAwNJKAGI2ibq--B-unKw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC0fS2kF3-cMT9ukX9MB9G1Q/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCw00qFF3snXN_QbBYNIWkpw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCBmW_ESeD4mnODFYpzVcPpQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCLobgyWcuKEbaqDImqUk9XA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC9CswYtb5rL31CHwyVoyJvQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC_SLthyNX_ivd-dmsFgmJVg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCOVfjynWebmzBCxrJVeHXqw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCHRwi1a-WFadE9w3JakBeUA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCmzxXgnzO7cwSEiMFWiNOWw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCIPMZMDMGv8vWT-vWnUGA_g/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCYp1p4KZdNQVaA5MKbQhCpg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCyjTtXnpBEI45ssSmt_VKrA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCsvUzBAxu2t5e_qOEr6iczQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCnidVRZng96xx-OVc6dK6fQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCir8ZEhgIOLY__2tN1Pi0ig/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCdp4_l1vPmpN-gDbUwhaRUQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCwd_qoS94df5orGoPLPnsxQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCs7nPQIEba0T3tGOWWsZpJQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCZYqWTQJzJaMW7jFG16p8ug/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC-98P1HknuXGxDYNwlxsKwQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCUQTqWAaSzhAKRanOpes1nA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCoes3Go2hjk-D7wQs5AznqA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC5_Y-BKzq1uW_2rexWkUzlA/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCW6TXMZ5Pq6yL6_k5NZ2e0Q/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCtEWTaMjqOH8J1Gy06Ey0Yg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC0Cyf-sOPE0AGY41I6andkQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCd6Za0CXVldhY8fK8eYoIuw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCoBapgfK_m6G7airg1rdn8w/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCASM0cgfkJxQ1ICmRilfHLw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCFjqauxWluNME8L1R4TVVRg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCbYmF43dpGHz8gi2ugiXr0Q/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCkO8yHEMmbvuw9Dgmuvwhsw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCglkkIyNzYBOFOR5gp5Yt3Q/shorts\n",
      "Scraping batch 3/3, URLs 101-112\n",
      "Successfully scraped: https://www.youtube.com/channel/UC6VAIqNQBc7ggiqvsOHOBqw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCk8GzjMOrta8yxDcKfylJYw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCcartHVtvAUzfajflyeT_Gg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCMsPm8-25ygqRrRe9_s1WFw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCb06IKdt8yeJDhqUct0z-gQ/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCCOnWIXYq9qQtfVxfvEgr0g/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCvthuVsurPaVz2a7_4LepGg/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UClZAOlfhJQJRym39WoAPxdw/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCNBTflmnht6ZMRNCDNilw9g/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCvoh9uWVTzo8u3e5eX4lO5A/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UCovtFObhY9NypXcyHxAS7-Q/shorts\n",
      "Successfully scraped: https://www.youtube.com/channel/UC7Lta_EuGv5BXoLTpUutvBA/shorts\n"
     ]
    }
   ],
   "source": [
    "def shorts_page_preprocessor(result):\n",
    "            \n",
    "    # Define the regex pattern to extract Shorts URLs\n",
    "    shorts_url_pattern = r'webCommandMetadata\":{\"url\":\"(/shorts/\\w+)\"'\n",
    "    # Find all matching Shorts URLs\n",
    "    shorts_urls = re.findall(shorts_url_pattern, result)\n",
    "    shorts_urls = ['https://www.youtube.com' + url.replace('/shorts/', '/watch?v=') for url in shorts_urls]\n",
    "\n",
    "\n",
    "    # Extract subscribers\n",
    "    subscribers_pattern = r'(\\d+K|\\d+M|\\d+) subscribers'\n",
    "    subscribers_match = re.search(subscribers_pattern, result)\n",
    "    last_subscribers = convert_subscribers(subscribers_match.group(1)) if subscribers_match else None\n",
    "            \n",
    "    # Extract total video count with the required prefix\n",
    "    total_video_count_pattern = r'{\"text\":{\"content\":\"([\\d.]+[K|M]?) videos\"'\n",
    "    total_video_count_match = re.search(total_video_count_pattern, result)\n",
    "    last_total_videos = extract_total_video_count(total_video_count_match.group(1)) if total_video_count_match else None\n",
    "            \n",
    "    # Extract description\n",
    "    description_pattern = r'itemprop=\"description\" content=\"(.*?)\"'\n",
    "    description_match = re.search(description_pattern, result, re.DOTALL)\n",
    "    last_description = extract_description(description_match.group(1)) if description_match else (None, None)\n",
    "    \n",
    "    return last_subscribers, last_total_videos, last_description, shorts_urls\n",
    "        \n",
    "\n",
    "def scanning_yt_shorts_page_cct(channel_df, loaded_df, batch_size, requests_per_second):\n",
    "    # List to store new shorts results in the format (channel_name, new_shorts_url)\n",
    "    new_shorts_urls = []\n",
    "    # List to store channels with no shorts_urls\n",
    "    no_shorts_list = []    \n",
    "    # Initialize a list for the additional DataFrame\n",
    "    additional_data = []\n",
    "    \n",
    "    target_df = channel_df[channel_df['data_yn'] == 'y']\n",
    "    channel_names = target_df['channel_name']\n",
    "    yt_fixed_urls = target_df['yt_fixed_url']\n",
    "    latest_urls = []\n",
    "    \n",
    "    # Filter loaded_db where channel_name matches\n",
    "    matching_df = loaded_df[loaded_df['channel_name'].isin(channel_names)]\n",
    "    \n",
    "    for channel_name in channel_names:\n",
    "        matching_rows = matching_df[matching_df['channel_name'] == channel_name]\n",
    "                \n",
    "        if not matching_rows.empty:\n",
    "            # Sort by check_date to get the most recent row\n",
    "            latest_row = matching_rows.sort_values(by='check_date', ascending=False).iloc[0]\n",
    "            latest_url = latest_row['shorts_url']\n",
    "        else:\n",
    "            # If no match found in loaded_db, set latest_url to None to ensure data collection proceeds\n",
    "            latest_url = None\n",
    "            \n",
    "        latest_urls.append(latest_url)\n",
    "\n",
    "    scrapped_data = scrape_all_urls(yt_fixed_urls, batch_size, requests_per_second)\n",
    "    scrapped_contents = scrapped_data['content']\n",
    "    \n",
    "    last_subscribers_list = []\n",
    "    last_total_videos_list = []\n",
    "    last_description_list = []\n",
    "    shorts_urls_list = []\n",
    "    for scrapped_content in scrapped_contents:\n",
    "        last_subscribers, last_total_videos, last_description, shorts_urls = shorts_page_preprocessor(scrapped_content)\n",
    "        last_subscribers_list.append(last_subscribers)\n",
    "        last_total_videos_list.append(last_total_videos)\n",
    "        last_description_list.append(last_description[0])\n",
    "        shorts_urls_list.append(shorts_urls)\n",
    "\n",
    "    for shorts_urls, latest_url, yt_fixed_url, channel_name in zip(shorts_urls_list,latest_urls, yt_fixed_urls, channel_names):\n",
    "        # Proceed based on shorts_urls availability\n",
    "        if shorts_urls:\n",
    "            if latest_url and latest_url in shorts_urls:\n",
    "                # If there's a match, get all URLs before the latest one\n",
    "                matching_index = shorts_urls.index(latest_url)\n",
    "                for shorts_url in shorts_urls[:matching_index]:\n",
    "                    new_shorts_urls.append((channel_name, shorts_url))\n",
    "            else:\n",
    "                # If no latest URL or no match in loaded_db, collect the first URL\n",
    "                new_shorts_urls.append((channel_name, shorts_urls[0]))\n",
    "        else:\n",
    "            # If shorts_urls is empty, add the channel_name and yt_fixed_url to the no_shorts_list\n",
    "            no_shorts_list.append((channel_name, yt_fixed_url))\n",
    "    \n",
    "    additional_data = {\n",
    "        'channel_name': channel_names,\n",
    "        'yt_fixed_url': yt_fixed_urls,\n",
    "        'subscribers': last_subscribers_list,\n",
    "        'total_video_count': last_total_videos_list,\n",
    "        'description': last_description_list  # As\n",
    "    }\n",
    "    no_shorts_df = pd.DataFrame(no_shorts_list, columns=['channel_name', 'yt_fixed_url'])\n",
    "    df = pd.DataFrame(additional_data)\n",
    "    \n",
    "    return new_shorts_urls, no_shorts_df, df  # Return both the list, no_shorts DataFrame, and additional DataFrame\n",
    "\n",
    "\n",
    "# CHANGE: 50 concurrent call\n",
    "new_shorts_urls, no_shorts_df, df = scanning_yt_shorts_page_cct(channel_df[:121], loaded_df, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26dcc129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Robert Breaker', 'https://www.youtube.com/watch?v=g6lcT4EhNzM'),\n",
       " ('Nick Jones', 'https://www.youtube.com/watch?v=ZmaF4ezj1aY'),\n",
       " ('Steve Ram', 'https://www.youtube.com/watch?v=iIR4NFDDEeg'),\n",
       " ('So Sweet ASMR', 'https://www.youtube.com/watch?v=LqGq8OLIX1Y'),\n",
       " ('English with Jennifer', 'https://www.youtube.com/watch?v=fa_sSaHxTZ4')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_shorts_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0e5a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>yt_fixed_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tactical Toolbox</td>\n",
       "      <td>https://www.youtube.com/channel/UCM9IxdhUn4Sm8ITdod8Tm2Q/shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinkedIn Learning</td>\n",
       "      <td>https://www.youtube.com/channel/UCikzJG7RbnNZhKLqqaXRM6A/shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matt Granger</td>\n",
       "      <td>https://www.youtube.com/channel/UCL5Hf6_JIzb3HpiJQGqs8cQ/shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ben Eater</td>\n",
       "      <td>https://www.youtube.com/channel/UCS0N5baNlQWJCUrhCEo8WlA/shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiritual Secrets</td>\n",
       "      <td>https://www.youtube.com/channel/UC0p8yCPxPjlPwJ81dGxCHoA/shorts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        channel_name  \\\n",
       "0   Tactical Toolbox   \n",
       "1  LinkedIn Learning   \n",
       "2       Matt Granger   \n",
       "3          Ben Eater   \n",
       "4  Spiritual Secrets   \n",
       "\n",
       "                                                      yt_fixed_url  \n",
       "0  https://www.youtube.com/channel/UCM9IxdhUn4Sm8ITdod8Tm2Q/shorts  \n",
       "1  https://www.youtube.com/channel/UCikzJG7RbnNZhKLqqaXRM6A/shorts  \n",
       "2  https://www.youtube.com/channel/UCL5Hf6_JIzb3HpiJQGqs8cQ/shorts  \n",
       "3  https://www.youtube.com/channel/UCS0N5baNlQWJCUrhCEo8WlA/shorts  \n",
       "4  https://www.youtube.com/channel/UC0p8yCPxPjlPwJ81dGxCHoA/shorts  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_shorts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d67e20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>yt_fixed_url</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>total_video_count</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert Breaker</td>\n",
       "      <td>https://www.youtube.com/channel/UCPkTFG8FeBL6iR8YemTaMYQ/shorts</td>\n",
       "      <td>961000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Now You See It is a media analysis channel that searches for meaning in unexpected places.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nick Jones</td>\n",
       "      <td>https://www.youtube.com/channel/UCwfeFpvbkp8cgmJWaMO9K0g/shorts</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Helping you make better videos and tell interesting stories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tactical Toolbox</td>\n",
       "      <td>https://www.youtube.com/channel/UCM9IxdhUn4Sm8ITdod8Tm2Q/shorts</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bringing you into the paracord world has been my objective since 2012.  I enjoy tying knots and bracelets.  Even more, I enjoy sharing my passion with others and I want to do it in a way that pleases all.  My hope is that you take my instruction and create amazing paracord items and learn useful skills along the way.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steve Ram</td>\n",
       "      <td>https://www.youtube.com/channel/UC_9iG1I_ic5jUOyzR9vTMBg/shorts</td>\n",
       "      <td>649000.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>World&amp;#39;s best and free medical lectures to prepare you for medical exams.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So Sweet ASMR</td>\n",
       "      <td>https://www.youtube.com/channel/UCrZfx6rscDd5qOdi5ni8rtg/shorts</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Channel by Leonardo Pereznieto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel_name  \\\n",
       "0    Robert Breaker   \n",
       "1        Nick Jones   \n",
       "2  Tactical Toolbox   \n",
       "3         Steve Ram   \n",
       "4     So Sweet ASMR   \n",
       "\n",
       "                                                      yt_fixed_url  \\\n",
       "0  https://www.youtube.com/channel/UCPkTFG8FeBL6iR8YemTaMYQ/shorts   \n",
       "1  https://www.youtube.com/channel/UCwfeFpvbkp8cgmJWaMO9K0g/shorts   \n",
       "2  https://www.youtube.com/channel/UCM9IxdhUn4Sm8ITdod8Tm2Q/shorts   \n",
       "3  https://www.youtube.com/channel/UC_9iG1I_ic5jUOyzR9vTMBg/shorts   \n",
       "4  https://www.youtube.com/channel/UCrZfx6rscDd5qOdi5ni8rtg/shorts   \n",
       "\n",
       "   subscribers  total_video_count  \\\n",
       "0     961000.0                NaN   \n",
       "1    8000000.0                NaN   \n",
       "2     780000.0                NaN   \n",
       "3     649000.0             1600.0   \n",
       "4    9000000.0                NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                      description  \n",
       "0                                                                                                                                                                                                                                      Now You See It is a media analysis channel that searches for meaning in unexpected places.  \n",
       "1                                                                                                                                                                                                                                                                    Helping you make better videos and tell interesting stories.  \n",
       "2  Bringing you into the paracord world has been my objective since 2012.  I enjoy tying knots and bracelets.  Even more, I enjoy sharing my passion with others and I want to do it in a way that pleases all.  My hope is that you take my instruction and create amazing paracord items and learn useful skills along the way.  \n",
       "3                                                                                                                                                                                                                                                    World&#39;s best and free medical lectures to prepare you for medical exams.  \n",
       "4                                                                                                                                                                                                                                                                                                  Channel by Leonardo Pereznieto  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ab61e",
   "metadata": {},
   "source": [
    "### Collect additional channel information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9346eaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m updated_channel_df \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_channel_df_with_new_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shorts_urls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 180\u001b[0m, in \u001b[0;36mupdate_channel_df_with_new_data\u001b[0;34m(ch_df, new_data)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_channel_df_with_new_data\u001b[39m(ch_df, new_data):\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    Update the channel DataFrame with new data based on matching channel names.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    pd.DataFrame: The updated channel DataFrame.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, new_row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnew_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m():\n\u001b[1;32m    181\u001b[0m         channel_name \u001b[38;5;241m=\u001b[39m new_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;66;03m# Find matching channel in channel_df\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "updated_channel_df = update_channel_df_with_new_data(channel_df, new_shorts_urls[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba2d7eb",
   "metadata": {},
   "source": [
    "### Update Channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1cbb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_channel_df = update_channel_df_with_new_shorts(channel_df, new_shorts_urls[1])\n",
    "channel_df.update(updated_channel_df)\n",
    "channel_df.to_excel(\"us_korea.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197e3c1",
   "metadata": {},
   "source": [
    "### Collect new shorts data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e73fbec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Breaker https://www.youtube.com/watch?v=rQBQ0LhYi9w\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nick Jones https://www.youtube.com/watch?v=fa_sSaHxTZ4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Ram https://www.youtube.com/watch?v=SqU7aeAPkrY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So Sweet ASMR https://www.youtube.com/watch?v=k27UsRRjC5g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English with Jennifer https://www.youtube.com/watch?v=FyVlw7QkBE8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Inglés https://www.youtube.com/watch?v=iOPYuI2dLc0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALIF FUN TIME https://www.youtube.com/watch?v=XgCToLOdEgM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetically Modified Skeptic https://www.youtube.com/watch?v=IzQDQrpPZ38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinkedIn Learning https://www.youtube.com/watch?v=tcyb9Qs3638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exam Preparation https://www.youtube.com/watch?v=es4rnY2rFis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matt Granger https://www.youtube.com/watch?v=CWtfHDx2FiY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Art-Tips https://www.youtube.com/watch?v=LqGq8OLIX1Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Torito https://www.youtube.com/watch?v=XyVxii6Z6us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drum Beats Online https://www.youtube.com/watch?v=5EQArCVZJEc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 10 https://www.youtube.com/watch?v=giybdhzJdHg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunjaecho/Git/dnova_code/env/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_list = add_new_shorts_data(API_KEY, new_shorts_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8ad24f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qg/b8v1nh_d69760npt2k4xd1jc0000gn/T/ipykernel_7613/3802664893.py:303: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  updated_loaded_db = pd.concat([loaded_db, new_data_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "loaded_df = add_new_data_to_loaded_db(data_list, loaded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e208a",
   "metadata": {},
   "source": [
    "### Collect past shorts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da8fbfd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strptime() argument 1 must be str, not datetime.datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m today_past_shorts \u001b[38;5;241m=\u001b[39m \u001b[43mcollecting_past_shorts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m loaded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([loaded_df, today_past_shorts], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m loaded_df \u001b[38;5;241m=\u001b[39m loaded_df\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
      "Cell \u001b[0;32mIn[75], line 311\u001b[0m, in \u001b[0;36mcollecting_past_shorts\u001b[0;34m(api_key, loaded_df)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollecting_past_shorts\u001b[39m(api_key, loaded_df):    \n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# Convert 'today' to a datetime object from the 'yyyy-mm-dd' format\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     today_date \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoday\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m#today_date = today.strftime(\"%Y-%m-%d\")\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# Iterate over each row in loaded_df, checking check_date and shorts_url\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (check_dt, shorts_url) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(loaded_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_date\u001b[39m\u001b[38;5;124m'\u001b[39m], loaded_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshorts_url\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# Convert check_dt to datetime format for comparison\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: strptime() argument 1 must be str, not datetime.datetime"
     ]
    }
   ],
   "source": [
    "today_past_shorts = collecting_past_shorts(API_KEY, loaded_df)\n",
    "loaded_df = pd.concat([loaded_df, today_past_shorts], ignore_index=True)\n",
    "loaded_df = loaded_df.drop_duplicates()\n",
    "loaded_df.to_excel(\"loaded_db.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97a29976",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24927072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-11-14'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
