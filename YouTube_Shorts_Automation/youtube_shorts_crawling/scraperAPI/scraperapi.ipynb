{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727b5030",
   "metadata": {},
   "source": [
    "## D'NOVA YouTube Shorts Scraping Flow\n",
    "-  Test code: 테스트 코드\n",
    "- Daily Shorts check: 수집 데이터 loading\n",
    "#### Code Flow\n",
    "1. 기존 수집했던 쇼츠 재수집 -7d, -14d, -21d\n",
    "2. channel shorts url input으로 들어갈시 채널 url 필터링(daily)\n",
    "3. 수집한 channel list 수집 후 loaded_db에 적재 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de18ecdc",
   "metadata": {},
   "source": [
    "### Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1430ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4efc4d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 26\u001b[0m\n\u001b[0;32m     19\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx-sapi-render\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx-sapi-instruction_set\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscroll\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdirection\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: 3}]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# , {\"type\": \"click\", \"selector\": {\"type\": \"text\",\"value\": \"Show transcript\"}}\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# ,{\"type\":\"scroll\",\"direction\":\"y\",\"value\":\"bottom\"}, {\"type\": \"wait\", \"value\": 2} \u001b[39;00m\n\u001b[0;32m     24\u001b[0m }\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Make the GET request\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m r_full \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://api.scraperapi.com/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# headers=headers,\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Save the response text to a file\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_channel_test.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\T14Gen1\\Documents\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the payload and headers for the request\n",
    "# shorts channel1: https://www.youtube.com/watch?v=xEuH_5Ik92U\n",
    "# shorts channel2: https://www.youtube.com/watch?v=fa_sSaHxTZ4\n",
    "# yt_shorts page: https://www.youtube.com/@%EC%95%84%EC%9D%B4%EB%8F%8C/shorts\n",
    "API_KEY = '3397e8a6a37e89b03b08750a27575df8'\n",
    "payload = {\n",
    "    'api_key': API_KEY,\n",
    "    'url': 'https://www.youtube.com/watch?v=fa_sSaHxTZ4'\n",
    "    ,'render': 'true'\n",
    "}\n",
    "# payload = { 'api_key': '3397e8a6a37e89b03b08750a27575df8', 'url': 'https://www.youtube.com/watch?v=xEuH_5Ik92U' }\n",
    "# r = requests.get('https://api.scraperapi.com/', params=payload, verify=False)\n",
    "# print(r.text)\n",
    "headers = {\n",
    "    'x-sapi-render': 'true',\n",
    "    'x-sapi-instruction_set': '[{\"type\":\"scroll\",\"direction\":\"y\",\"value\":\"bottom\"}, {\"type\": \"wait\", \"value\": 3}]'\n",
    "    # , {\"type\": \"click\", \"selector\": {\"type\": \"text\",\"value\": \"Show transcript\"}}\n",
    "    # ,{\"type\":\"scroll\",\"direction\":\"y\",\"value\":\"bottom\"}, {\"type\": \"wait\", \"value\": 2} \n",
    "}\n",
    "# Make the GET request\n",
    "r_full = requests.get('https://api.scraperapi.com/', params=payload, headers=headers, verify=False) # headers=headers,\n",
    "\n",
    "# Save the response text to a file\n",
    "with open('response_channel_test.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(r_full.text)\n",
    "\n",
    "print(\"Response saved to response_output.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "84991370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response saved to response_output.txt\n"
     ]
    }
   ],
   "source": [
    "# url 한개만 추출 -> comments (x)\n",
    "import requests\n",
    "\n",
    "payload = { 'api_key': '3397e8a6a37e89b03b08750a27575df8', 'url': 'https://www.youtube.com/watch?v=PUs_h8-PDeg'}\n",
    "r_normal = requests.get('https://api.scraperapi.com/', params=payload, verify=False)\n",
    "# Save the response text to a file\n",
    "with open('response_channel_test_예와_Rovert.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(r_normal.text)\n",
    "\n",
    "print(\"Response saved to response_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "25e67cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for https://www.youtube.com/watch?v=xEuH_5Ik92U saved to response_1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for https://www.youtube.com/watch?v=CPsCEfs3m8I saved to response_2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for https://www.youtube.com/watch?v=jXUHFbNo5Vg saved to response_3.txt\n"
     ]
    }
   ],
   "source": [
    "# url 여러개 진행\n",
    "import requests\n",
    "API_KEY = '3397e8a6a37e89b03b08750a27575df8'\n",
    "# List of URLs to test\n",
    "urls = [\n",
    "    'https://www.youtube.com/watch?v=xEuH_5Ik92U',\n",
    "    'https://www.youtube.com/watch?v=CPsCEfs3m8I',\n",
    "    'https://www.youtube.com/watch?v=jXUHFbNo5Vg'\n",
    "]\n",
    "\n",
    "# API key and headers\n",
    "headers = {\n",
    "    'x-sapi-render': 'true',\n",
    "    # 'x-sapi-instruction_set': '[{\"type\":\"scroll\",\"direction\":\"y\",\"value\":\"bottom\"}, {\"type\": \"wait\", \"value\": 2}]'\n",
    "    'x-sapi-instruction_set': '[{\"type\":\"loop\",\"for\":' + str(len(urls))+',\"instructions\":[{\"type\":\"scroll\",\"direction\":\"y\",\"value\":\"bottom\"}, {\"type\": \"wait\", \"value\": 2}]}]'\n",
    "}\n",
    "\n",
    "# Loop through each URL, send request, and save response to a file\n",
    "for i, url in enumerate(urls):\n",
    "    payload = {\n",
    "        'api_key': API_KEY,\n",
    "        'url': url,\n",
    "        'render': 'true'\n",
    "    }\n",
    "    \n",
    "    # Send the request\n",
    "    r = requests.get('https://api.scraperapi.com/', params=payload, headers=headers, verify=False)\n",
    "    \n",
    "    # Save the response to a file, naming it based on the URL index\n",
    "    filename = f'response_{i + 1}.txt'\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(r.text)\n",
    "    \n",
    "    print(f'Response for {url} saved to {filename}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0decd",
   "metadata": {},
   "source": [
    "### Daily Shorts Check\n",
    "- 95000 채널 매일 확인 KST 23:30 진행 -> request 95000 기본\n",
    "- channel_df: YT 채널 데이터\n",
    "- loaded_df: 적제 쇼츠 데이터\n",
    "- basic_shorts_info: 기본적인 Shorts 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90ce72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [channel_name, shorts_url, shorts_title, shorts_description, shorts_thumbnail, shorts_view, shorts_likes, shorts_comments_num, shorts_comments_time, shorts_published_date, check_date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 기존 channel list와 적재 데이터 loaded\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "API_KEY = '3397e8a6a37e89b03b08750a27575df8'\n",
    "# 한국, 미국 데이터 9507개\n",
    "channel_df = pd.read_excel('us_korea_test.xlsx')[30:40]\n",
    "# 적재 DB: # -7d, -14d, -21d 만 필터링\n",
    "loaded_df = pd.read_excel(\"loaded_db.xlsx\")\n",
    "today = datetime.today()\n",
    "try:\n",
    "    loaded_df['check_date'] = loaded_df['check_date'].dt.date\n",
    "    filter_dates = [today.date() - timedelta(days=7), today.date() - timedelta(days=14), today.date() - timedelta(days=21)]\n",
    "    # Filter the dataframe based on check_date\n",
    "    loaded_df = loaded_df[loaded_df['check_date'].isin(filter_dates)]\n",
    "    # channel_df 와 loaded_df 교집합 데이터\n",
    "    merged_df = pd.merge(loaded_df, channel_df, on='channel_name', how='inner')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(loaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c24239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 용\n",
    "# r_full: render 조건 True, request: 10, 쇼츠 데이터\n",
    "# r_normal: render 조건 False, request: 1, 쇼츠데이터\n",
    "# r_page: 채널 쇼츠 페이지, reqeust: 1\n",
    "\n",
    "# scraperAPI result filter with NaN values for missing data\n",
    "def basic_shorts_info(text):\n",
    "    # shorts title\n",
    "    match_title = re.search(r'<title>(.*?) - YouTube</title>', text)\n",
    "    extracted_title = match_title.group(1) if match_title else np.nan\n",
    "\n",
    "    # shorts description\n",
    "    description_pattern = r'attributedDescription\":{\"content\":\"(.*?)\"'\n",
    "    # Find the match\n",
    "    description_match = re.search(description_pattern, text)\n",
    "    # Extract the content if found\n",
    "    extracted_description = description_match.group(1) if description_match else None\n",
    "    \n",
    "    # shorts total view (date and time)\n",
    "    date_time_pattern = r'datePublished\" content=\"(\\d{4}-\\d{2}-\\d{2})T(\\d{2}):'\n",
    "    match_date = re.search(date_time_pattern, text)\n",
    "    extracted_published = f\"{match_date.group(1)} {match_date.group(2)}\" if match_date else np.nan\n",
    "\n",
    "    # Thumbnail\n",
    "    thumbnail_pattern = r'\"url\":\"(https?://[^\\s\"]+)\"'\n",
    "    thumbnail_match = re.search(thumbnail_pattern, text)\n",
    "    yt_shorts_thumbnail = thumbnail_match.group(1) if thumbnail_match else np.nan\n",
    "\n",
    "    # Total view\n",
    "    view_pattern = r'\"viewCountEntityKey\":\"[^\"]+\",\"factoid\":\\{\"factoidRenderer\":\\{\"value\":\\{\"simpleText\":\"([\\d,]+)\"'\n",
    "    view_match = re.search(view_pattern, text)\n",
    "    extracted_view = view_match.group(1) if view_match else np.nan\n",
    "\n",
    "    # Total likes\n",
    "    like_pattern = r'\"iconName\":\"LIKE\",\"title\":\"([\\d.]+)([KM]?)\"'\n",
    "    like_match = re.search(like_pattern, text)\n",
    "    if like_match:\n",
    "        extracted_likes = float(like_match.group(1))\n",
    "        suffix = like_match.group(2)\n",
    "        if suffix == 'K':\n",
    "            extracted_likes *= 1000\n",
    "        elif suffix == 'M':\n",
    "            extracted_likes *= 1000000\n",
    "    else:\n",
    "        extracted_likes = np.nan\n",
    "\n",
    "    # Total comments    \n",
    "    comment_num_pattern = r'\"text\":\"Comments\"}\\]},\"contextualInfo\":\\{\"runs\":\\[\\{\"text\":\"([\\d.]+)([KM]?)\"'\n",
    "    comment_num_match = re.search(comment_num_pattern, text)\n",
    "    if comment_num_match:\n",
    "        extracted_comments_number = float(comment_num_match.group(1))\n",
    "        suffix = comment_num_match.group(2)\n",
    "        if suffix == 'K':\n",
    "            extracted_comments_number *= 1000\n",
    "        elif suffix == 'M':\n",
    "            extracted_comments_number *= 1000000\n",
    "    else:\n",
    "        extracted_comments_number = np.nan\n",
    "\n",
    "    # yt shorts comment 결과 및 comment 작성 시간\n",
    "    comments_time_text_pattern = r'<span[^>]*id=\"published-time-text\"[^>]*>\\s*<a[^>]*>\\s*(.*?)\\s*<\\/a>.*?<yt-attributed-string[^>]*>\\s*<span[^>]*class=\"yt-core-attributed-string yt-core-attributed-string--white-space-pre-wrap\"[^>]*>\\s*(.*?)\\s*<\\/span>'\n",
    "    \n",
    "    # Find all matches for time and comments\n",
    "    comments_time_matches = re.findall(comments_time_text_pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Process and clean comments\n",
    "    extracted_comments_time_matches = []\n",
    "    if comments_time_matches:\n",
    "        for time, comment in comments_time_matches:\n",
    "            # Clean the comment to remove unwanted tags using BeautifulSoup\n",
    "            soup = BeautifulSoup(comment, 'html.parser')\n",
    "            cleaned_comment = soup.get_text()\n",
    "            extracted_comments_time_matches.append((time.strip(), cleaned_comment.strip()))\n",
    "    else:\n",
    "        extracted_comments_time_matches = np.nan\n",
    "\n",
    "    return (extracted_title, extracted_description, extracted_published, yt_shorts_thumbnail, \n",
    "            extracted_view, extracted_likes, extracted_comments_number, extracted_comments_time_matches)\n",
    "# yt_shorts_title, yt_shorts_description, yt_shorts_published, yt_shorts_thumbnail, yt_shorts_view, yt_shorts_likes, yt_shorts_comments_num, yt_shorts_comments_time = basic_shorts_info(r_normal.text)\n",
    "# print(\"yt_shorts_title: \", yt_shorts_title)\n",
    "# print(\"yt_shorts_description: \", yt_shorts_description)\n",
    "# print(\"yt_shorts_published: \", yt_shorts_published)\n",
    "# print(\"yt_shorts_thumbnalil: \", yt_shorts_thumbnail)\n",
    "# print(\"yt_view: \", yt_shorts_view)\n",
    "# print(\"yt_likes: \", yt_shorts_likes)\n",
    "# print(\"yt_comments: \", yt_shorts_comments_num)\n",
    "# print(\"yt_shorts_comments_time: \", yt_shorts_comments_time)\n",
    "# print(len(yt_shorts_comments_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ec5be",
   "metadata": {},
   "source": [
    "##### 1. 기존 수집했던 쇼츠 재수집 -7d, -14d, -21d\n",
    "- loaded_db에서 날짜 필터링해서 데이터 수집 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62c08ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [channel_name, shorts_url, shorts_title, shorts_description, shorts_thumbnail, shorts_view, shorts_likes, shorts_comments_num, shorts_comments_time, shorts_published_date, check_date]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>shorts_url</th>\n",
       "      <th>shorts_title</th>\n",
       "      <th>shorts_description</th>\n",
       "      <th>shorts_thumbnail</th>\n",
       "      <th>shorts_view</th>\n",
       "      <th>shorts_likes</th>\n",
       "      <th>shorts_comments_num</th>\n",
       "      <th>shorts_comments_time</th>\n",
       "      <th>shorts_published_date</th>\n",
       "      <th>check_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [channel_name, shorts_url, shorts_title, shorts_description, shorts_thumbnail, shorts_view, shorts_likes, shorts_comments_num, shorts_comments_time, shorts_published_date, check_date]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def collecting_past_shorts(api_key, loaded_df):\n",
    "    today = datetime.today()\n",
    "    print(loaded_df)\n",
    "    # Iterate over each row in loaded_df, checking check_date and shorts_url\n",
    "    for idx, (check_dt, shorts_url) in enumerate(zip(loaded_df['check_date'], loaded_df['shorts_url'])):\n",
    "        if check_dt == (today.date() - timedelta(days=14)) or check_dt == (today.date() - timedelta(days=21)):\n",
    "            payload = {\n",
    "                'api_key': api_key,\n",
    "                'url': shorts_url\n",
    "            }\n",
    "            \n",
    "            # Send the request\n",
    "            r = requests.get('https://api.scraperapi.com/', params=payload, verify=False)\n",
    "\n",
    "            # Extract relevant information from the response\n",
    "            yt_title, yt_shorts_description, yt_shorts_published, yt_shorts_thumbnail, yt_shorts_view, yt_shorts_likes, yt_shorts_comments_num, yt_shorts_comments_time = basic_shorts_info(r.text)\n",
    "            # Prepare new row with updated values (keeping the same channel name and other values from loaded_df)\n",
    "            new_row = {\n",
    "                'channel_nm': loaded_df.loc[idx, 'channel_nm'], \n",
    "                'shorts_url': shorts_url, \n",
    "                'shorts_title': yt_title,\n",
    "                'shorts_description': yt_shorts_description,\n",
    "                'shorts_thumbnalil': yt_shorts_thumbnail,\n",
    "                'shorts_view': yt_shorts_view,\n",
    "                'shorts_likes': yt_shorts_likes,\n",
    "                'shorts_comments': yt_shorts_comments_num,\n",
    "                'shorts_comments_time': yt_shorts_comments_time,\n",
    "                'shorts_published_date': yt_shorts_published,\n",
    "                'check_date': today.date()  # Use today's date for the new check_date\n",
    "            }\n",
    "            \n",
    "            # Append the new row to the DataFrame\n",
    "            loaded_df = loaded_df.append(new_row, ignore_index=True)\n",
    "\n",
    "        # -7d에는 comments 추가 수집\n",
    "        elif check_dt==(today.date() - timedelta(days=7)): \n",
    "            payload = {\n",
    "                'api_key': API_KEY,\n",
    "                'url': 'https://www.youtube.com/watch?v=xEuH_5Ik92U',\n",
    "                'render': 'true'\n",
    "            }\n",
    "\n",
    "            headers = {\n",
    "                'x-sapi-render': 'true',\n",
    "                'x-sapi-instruction_set': '[{\"type\":\"scroll\",\"direction\":\"y\",\"value\":\"bottom\"}, {\"type\": \"wait\", \"value\": 2}]'\n",
    "                # , {\"type\": \"click\", \"selector\": {\"type\": \"text\",\"value\": \"Show transcript\"}}\n",
    "                # ,{\"type\":\"scroll\",\"direction\":\"y\",\"value\":\"bottom\"}, {\"type\": \"wait\", \"value\": 2} \n",
    "            }\n",
    "            r = requests.get('https://api.scraperapi.com/', params=payload, headers=headers, verify=False)\n",
    "            yt_title, yt_shorts_description, yt_shorts_published, yt_shorts_thumbnail, yt_shorts_view, yt_shorts_likes, yt_shorts_comments_num, yt_shorts_comments_time = basic_shorts_info(r.text)\n",
    "\n",
    "            # Prepare new row with updated values (keeping the same channel name and other values from loaded_df)\n",
    "            new_row = {\n",
    "                'channel_nm': loaded_df.loc[idx, 'channel_nm'], \n",
    "                'shorts_url': shorts_url, \n",
    "                'shorts_title': yt_title,\n",
    "                'shorts_description': yt_shorts_description,\n",
    "                'shorts_thumbnalil': yt_shorts_thumbnail,\n",
    "                'shorts_view': yt_shorts_view,\n",
    "                'shorts_likes': yt_shorts_likes,\n",
    "                'shorts_comments': yt_shorts_comments_num,\n",
    "                'shorts_comments_time': yt_shorts_comments_time,\n",
    "                'shorts_published_date': yt_shorts_published,\n",
    "                'check_date': today.date()  # Use today's date for the new check_date\n",
    "            }\n",
    "\n",
    "            loaded_df = loaded_df.append(new_row, ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            print(\"no data\")\n",
    "            pass\n",
    "\n",
    "    return loaded_df\n",
    "\n",
    "collecting_past_shorts(API_KEY, loaded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaf44e5",
   "metadata": {},
   "source": [
    "##### 2. channel shorts url input으로 들어갈시 채널 url 필터링(daily)\n",
    "- 최신 기준으로 맵핑이 되지 않는 경우 최근 1개 url수집 \n",
    "- 기존 말고 신규 shorts url 확인시 list 추가\n",
    "- 마지막에 다 확인후 추가된 list 쇼츠 데이터 수집 진행 -> 10 request로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b517bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매일 전체 채널 필터링\n",
    "# - 신규 쇼츠 데이터 발견시 list에 추가해서 comments까지 확인\n",
    "# - 과거 데이터가 없을 수 있으니 만약 하나도 매칭이 안되면 3개 수집, 있다면 그거 앞에꺼를 추가수집\n",
    "import pandas as pd\n",
    "\n",
    "def scanning_yt_shorts_page(api_key, channel_db, loaded_db):\n",
    "    # List to store new shorts results in the format (channel_name, new_shorts_url)\n",
    "    new_shorts_urls = []\n",
    "    # List to store channels with no shorts_urls\n",
    "    no_shorts_list = []\n",
    "\n",
    "    # Iterate over each row in channel_db\n",
    "    for index, row in channel_db.iterrows():\n",
    "        channel_name = row['channel_name']\n",
    "        yt_fixed_url = row['yt_fixed_url']\n",
    "        \n",
    "        # Filter loaded_db where channel_name matches\n",
    "        matching_rows = loaded_db[loaded_db['channel_name'] == channel_name]\n",
    "        \n",
    "        if not matching_rows.empty:\n",
    "            # Sort by check_date to get the most recent row\n",
    "            latest_row = matching_rows.sort_values(by='check_date', ascending=False).iloc[0]\n",
    "        \n",
    "        # Prepare the payload for ScraperAPI request, using yt_fixed_url\n",
    "        payload = {\n",
    "            'api_key': api_key,\n",
    "            'url': yt_fixed_url\n",
    "        }\n",
    "        \n",
    "        # Send the request to ScraperAPI\n",
    "        r = requests.get('https://api.scraperapi.com/', params=payload, verify=False)\n",
    "        \n",
    "        # Define the regex pattern to extract Shorts URLs\n",
    "        shorts_url_pattern = r'webCommandMetadata\":{\"url\":\"(/shorts/\\w+)\"'\n",
    "        # Find all matching Shorts URLs\n",
    "        shorts_urls = re.findall(shorts_url_pattern, r.text)\n",
    "        shorts_urls =  ['https://www.youtube.com' + url.replace('/shorts/', '/watch?v=') for url in shorts_urls]\n",
    "\n",
    "        print(f\"shorts_urls for {channel_name}: \", shorts_urls)\n",
    "\n",
    "        # Check if there are any new shorts URLs before the latest one\n",
    "        if not matching_rows.empty:\n",
    "            latest_url = latest_row['shorts_url']\n",
    "            # If the latest URL exists in the list of Shorts URLs, find the ones before it\n",
    "            if latest_url in shorts_urls:\n",
    "                matching_index = shorts_urls.index(latest_url)\n",
    "                # Collect all URLs before the match with channel_name\n",
    "                for shorts_url in shorts_urls[:matching_index]:\n",
    "                    new_shorts_urls.append((channel_name, shorts_url))\n",
    "        else:\n",
    "            # If no match in loaded_db, return the first shorts URL with channel_name\n",
    "            if shorts_urls:\n",
    "                new_shorts_urls.append((channel_name, shorts_urls[0]))\n",
    "        \n",
    "        # If shorts_urls is empty, add the channel_name and yt_fixed_url to the no_shorts_list\n",
    "        if not shorts_urls:\n",
    "            no_shorts_list.append((channel_name, yt_fixed_url))\n",
    "    \n",
    "    # Convert the no_shorts_list to a DataFrame\n",
    "    no_shorts_df = pd.DataFrame(no_shorts_list, columns=['channel_name', 'yt_fixed_url'])\n",
    "\n",
    "    return new_shorts_urls, no_shorts_df  # Return both the list and DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f533636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for Marc Brunet:  ['https://www.youtube.com/watch?v=Qc6NO19u3MM', 'https://www.youtube.com/watch?v=qSfXMQQRNY0', 'https://www.youtube.com/watch?v=QcnpGUdGFmg', 'https://www.youtube.com/watch?v=wMXHYET8xP8', 'https://www.youtube.com/watch?v=SRzUqX9pza8', 'https://www.youtube.com/watch?v=UituSM5LlZc', 'https://www.youtube.com/watch?v=8sORtqjvClM', 'https://www.youtube.com/watch?v=t51uvIVlkwg', 'https://www.youtube.com/watch?v=kOyXKhVChTo', 'https://www.youtube.com/watch?v=TTU6VNh07aM', 'https://www.youtube.com/watch?v=11rLjEFozYY', 'https://www.youtube.com/watch?v=ryGJf_v4WHE', 'https://www.youtube.com/watch?v=PNIL5KP51N4', 'https://www.youtube.com/watch?v=83CEXyazHcc', 'https://www.youtube.com/watch?v=G4PoTrGsEOg', 'https://www.youtube.com/watch?v=IaOPd8Q9_MI', 'https://www.youtube.com/watch?v=_cpmZJ2CqHQ', 'https://www.youtube.com/watch?v=1dQW5oshfTM', 'https://www.youtube.com/watch?v=aI3mrZo4Hxc', 'https://www.youtube.com/watch?v=6j9GT29xHOI', 'https://www.youtube.com/watch?v=wvCKZ3OG8us', 'https://www.youtube.com/watch?v=t61knwIo_CY', 'https://www.youtube.com/watch?v=KcLuvnp7Zfo', 'https://www.youtube.com/watch?v=vNT5ozaAt9Y', 'https://www.youtube.com/watch?v=g62JjvsdY5k', 'https://www.youtube.com/watch?v=axxdYIpXnfE', 'https://www.youtube.com/watch?v=_0ZM8q4k5x8', 'https://www.youtube.com/watch?v=sqltfkMIdcw', 'https://www.youtube.com/watch?v=LVISy7Rm9H4', 'https://www.youtube.com/watch?v=qwf22VeesYA', 'https://www.youtube.com/watch?v=RtAInZVW79g', 'https://www.youtube.com/watch?v=bCkDjbilsBg', 'https://www.youtube.com/watch?v=K1oqcHTrTkY', 'https://www.youtube.com/watch?v=kAhnPgYRuSI', 'https://www.youtube.com/watch?v=p0NYuaJz0nw', 'https://www.youtube.com/watch?v=88RfsiJoPlA', 'https://www.youtube.com/watch?v=MwuBuzQDnl0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for Jen_ny69:  ['https://www.youtube.com/watch?v=ixq_pOK7jk0', 'https://www.youtube.com/watch?v=2iRkPzWEwoM', 'https://www.youtube.com/watch?v=12cAOIfgpN8', 'https://www.youtube.com/watch?v=olKeodW3OgI', 'https://www.youtube.com/watch?v=bdWLh27gMCg', 'https://www.youtube.com/watch?v=u2JvUYlHcvw', 'https://www.youtube.com/watch?v=ubl0lfLL1BA', 'https://www.youtube.com/watch?v=DNd49qvBXa8', 'https://www.youtube.com/watch?v=pxKm4bgE1A8', 'https://www.youtube.com/watch?v=0Vhy78hFn0M', 'https://www.youtube.com/watch?v=ul0n6QL9CDg', 'https://www.youtube.com/watch?v=iEFgA507ubY', 'https://www.youtube.com/watch?v=dFlGiETcf_w', 'https://www.youtube.com/watch?v=LmP9AwSqgPk', 'https://www.youtube.com/watch?v=omejymfxZ8w', 'https://www.youtube.com/watch?v=QEAALeEsMVI', 'https://www.youtube.com/watch?v=lSUKtugjzUY', 'https://www.youtube.com/watch?v=zW8EYv6UUeU', 'https://www.youtube.com/watch?v=3xX7yJf9Ii4', 'https://www.youtube.com/watch?v=N2YWU5bPf98', 'https://www.youtube.com/watch?v=NBXHMt_CLGo', 'https://www.youtube.com/watch?v=CCf8hTgMddI', 'https://www.youtube.com/watch?v=jfkCWq9HoMI', 'https://www.youtube.com/watch?v=THAXskEidg0', 'https://www.youtube.com/watch?v=Yo0LQlLsB3E', 'https://www.youtube.com/watch?v=D0BU33UItVA', 'https://www.youtube.com/watch?v=B5NT6JdB5KY', 'https://www.youtube.com/watch?v=F51fGCbWfOo', 'https://www.youtube.com/watch?v=GTVfW6c_n8Y', 'https://www.youtube.com/watch?v=jYgLynwhBtk', 'https://www.youtube.com/watch?v=2eSOy0KlNk8', 'https://www.youtube.com/watch?v=cQlEFgry0Yo', 'https://www.youtube.com/watch?v=8RqEkfiF7eI', 'https://www.youtube.com/watch?v=xCSicVNFhoA', 'https://www.youtube.com/watch?v=at5O0Q7VkOU', 'https://www.youtube.com/watch?v=Pi0OOnM0N7U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for DawateIslami:  ['https://www.youtube.com/watch?v=JhocFEigq3k', 'https://www.youtube.com/watch?v=FAlUsZJt0yo', 'https://www.youtube.com/watch?v=cp0Ezo8SGK0', 'https://www.youtube.com/watch?v=NeQKyVvbync', 'https://www.youtube.com/watch?v=EyQpR_ksap8', 'https://www.youtube.com/watch?v=TOHAHH8zqkM', 'https://www.youtube.com/watch?v=rpm6ktQgqmw', 'https://www.youtube.com/watch?v=ARB36uMrsV4', 'https://www.youtube.com/watch?v=aGPhQxeoMy0', 'https://www.youtube.com/watch?v=Kq_zs1cuB64', 'https://www.youtube.com/watch?v=mhLfsLJeS8c', 'https://www.youtube.com/watch?v=pAiEU6jnEVU', 'https://www.youtube.com/watch?v=eTMo5WCL1Rw', 'https://www.youtube.com/watch?v=_8s5z45Tc_U', 'https://www.youtube.com/watch?v=gBWfraV21h0', 'https://www.youtube.com/watch?v=Ys0qLD1YsS0', 'https://www.youtube.com/watch?v=mDL0kl7EshA', 'https://www.youtube.com/watch?v=cFtLinHyTT8', 'https://www.youtube.com/watch?v=dwHQcgwNfMk', 'https://www.youtube.com/watch?v=R0xWGnljWzk', 'https://www.youtube.com/watch?v=AGxgYplCvSc', 'https://www.youtube.com/watch?v=8AU3nnWgCJM', 'https://www.youtube.com/watch?v=bDgsotCTZRM', 'https://www.youtube.com/watch?v=bX3omxdmGqA', 'https://www.youtube.com/watch?v=YmvmlSLkQVg', 'https://www.youtube.com/watch?v=VDSb6gTUfF4', 'https://www.youtube.com/watch?v=YhFKo2Fr3nM', 'https://www.youtube.com/watch?v=n_UCJ8YdJYM', 'https://www.youtube.com/watch?v=TP6_fScU1Xw', 'https://www.youtube.com/watch?v=iLx2Y_qvHnM', 'https://www.youtube.com/watch?v=B2xXy77sayo', 'https://www.youtube.com/watch?v=jFa0f3a_HsI', 'https://www.youtube.com/watch?v=HmeO6a7t7c4', 'https://www.youtube.com/watch?v=L6p0UksO7bU', 'https://www.youtube.com/watch?v=2q8Qy8Osj0g', 'https://www.youtube.com/watch?v=1zhmZFeoEN4', 'https://www.youtube.com/watch?v=lAXd7zACQM4', 'https://www.youtube.com/watch?v=WV4jG1OgneA', 'https://www.youtube.com/watch?v=JN53PWk8Doc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for Go Natural English with Gabby Wallace:  ['https://www.youtube.com/watch?v=v9dcf7OF1Wg', 'https://www.youtube.com/watch?v=lNlQBVr5T1Q', 'https://www.youtube.com/watch?v=FyH27MVcAMs', 'https://www.youtube.com/watch?v=WKYJOilrc6g', 'https://www.youtube.com/watch?v=e0_VW_kWHTM', 'https://www.youtube.com/watch?v=BXE0IJsZdY8', 'https://www.youtube.com/watch?v=PPUYPoNv7ws', 'https://www.youtube.com/watch?v=nZ9RcuybSiY', 'https://www.youtube.com/watch?v=xsYZcX3zBo0', 'https://www.youtube.com/watch?v=SojCx1cyHl8', 'https://www.youtube.com/watch?v=1Ch0m7z1IrM', 'https://www.youtube.com/watch?v=GeUEs6fBgXU', 'https://www.youtube.com/watch?v=V_d_qNjkRQ0', 'https://www.youtube.com/watch?v=X0GrGiHe9DU', 'https://www.youtube.com/watch?v=S1bjZJ_5Pc0', 'https://www.youtube.com/watch?v=nneOpUp6sM8', 'https://www.youtube.com/watch?v=23T4gLlbt1c', 'https://www.youtube.com/watch?v=ABkRecJU_xY', 'https://www.youtube.com/watch?v=wc9gCqXE2BA', 'https://www.youtube.com/watch?v=RVCHaOOdr1k', 'https://www.youtube.com/watch?v=kaTs8Yr6LjQ', 'https://www.youtube.com/watch?v=kkeO2KprRuE', 'https://www.youtube.com/watch?v=kiHMAlNSOUs', 'https://www.youtube.com/watch?v=jsx22srDBFo', 'https://www.youtube.com/watch?v=D1HFbeSY8ro', 'https://www.youtube.com/watch?v=9vlzmYp7FtU', 'https://www.youtube.com/watch?v=vzpG_sl8e68', 'https://www.youtube.com/watch?v=OweZxkUTHVo', 'https://www.youtube.com/watch?v=wJs0eU71Dmk', 'https://www.youtube.com/watch?v=weiOCa8I6PU', 'https://www.youtube.com/watch?v=C4Mqy2I9aec', 'https://www.youtube.com/watch?v=2mq_UUIrPl0', 'https://www.youtube.com/watch?v=e3YNnbMkSxE', 'https://www.youtube.com/watch?v=DC6JjgbaEv8', 'https://www.youtube.com/watch?v=pQ8VvXI8rfk', 'https://www.youtube.com/watch?v=0wmpXCyKn5Q', 'https://www.youtube.com/watch?v=edLCLSM_zRQ', 'https://www.youtube.com/watch?v=2Y9aYdF62Jk', 'https://www.youtube.com/watch?v=KqFT8vTUmoM', 'https://www.youtube.com/watch?v=ZoKOG5Ot5gw']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for ReligionForBreakfast:  ['https://www.youtube.com/watch?v=WZn6dF9C1NQ', 'https://www.youtube.com/watch?v=mDXgX3WPLfI', 'https://www.youtube.com/watch?v=Nse3_pm7GFQ', 'https://www.youtube.com/watch?v=GgwAwhxZr1o', 'https://www.youtube.com/watch?v=Q5E6MxwPTek', 'https://www.youtube.com/watch?v=2dUDOt1zkQI', 'https://www.youtube.com/watch?v=gtCtWWGh7wY', 'https://www.youtube.com/watch?v=ryTjb8MxIZk', 'https://www.youtube.com/watch?v=TV4dBEF5K4w', 'https://www.youtube.com/watch?v=vVTiEEwEt7o', 'https://www.youtube.com/watch?v=18wg8CZ5C8U', 'https://www.youtube.com/watch?v=1V8lCp2JaBI', 'https://www.youtube.com/watch?v=vlrIijJ7bsk']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for Medicosis Perfectionalis:  ['https://www.youtube.com/watch?v=wFVlzZUWFcw', 'https://www.youtube.com/watch?v=pBv5ZWw72zQ', 'https://www.youtube.com/watch?v=ahEIRmZ3s8w', 'https://www.youtube.com/watch?v=7reyEtSDMTQ', 'https://www.youtube.com/watch?v=P2_QyGlz8V4', 'https://www.youtube.com/watch?v=rSnK1pZuMKY', 'https://www.youtube.com/watch?v=ctyvxOdIisU', 'https://www.youtube.com/watch?v=xsJJBAHTXG0', 'https://www.youtube.com/watch?v=HxALevClFjs', 'https://www.youtube.com/watch?v=5rQaPWgoS3s', 'https://www.youtube.com/watch?v=pCq3p1yZyWk', 'https://www.youtube.com/watch?v=wyRCFq05aBE', 'https://www.youtube.com/watch?v=JtJBn9wiIWc', 'https://www.youtube.com/watch?v=OxKG_3e6e6E', 'https://www.youtube.com/watch?v=nmqdbij2bo4', 'https://www.youtube.com/watch?v=WEapu7ZfCH0', 'https://www.youtube.com/watch?v=KH5az9RFlSc', 'https://www.youtube.com/watch?v=p6R1Cdegz3U', 'https://www.youtube.com/watch?v=DWO0mIOcDKU', 'https://www.youtube.com/watch?v=HbLlgfKVLsU', 'https://www.youtube.com/watch?v=UVBmTnHFdC0', 'https://www.youtube.com/watch?v=J95q_9RcrqE', 'https://www.youtube.com/watch?v=M7zr7oKO57Y', 'https://www.youtube.com/watch?v=ubMeuQxmNOU', 'https://www.youtube.com/watch?v=1taK69_Hhnw', 'https://www.youtube.com/watch?v=80bU_usP0WM', 'https://www.youtube.com/watch?v=zgNCD5PRDQQ', 'https://www.youtube.com/watch?v=NhEKtuqQi7Y', 'https://www.youtube.com/watch?v=F5MO0Fy8NHA', 'https://www.youtube.com/watch?v=yLSeaNLQI2o', 'https://www.youtube.com/watch?v=i5OYcAiqD4I', 'https://www.youtube.com/watch?v=8OGdtlnpLSM', 'https://www.youtube.com/watch?v=PtS2QXrfO7c', 'https://www.youtube.com/watch?v=tjw9wHTY2C8', 'https://www.youtube.com/watch?v=t4_FYiXd55Q', 'https://www.youtube.com/watch?v=byy_3XoNnlE', 'https://www.youtube.com/watch?v=y2Kyp7Las0I', 'https://www.youtube.com/watch?v=wpDVqpyL5KI', 'https://www.youtube.com/watch?v=VgepQ94Chko', 'https://www.youtube.com/watch?v=4T2iAJMRsho', 'https://www.youtube.com/watch?v=H7Vkdy4Sw10', 'https://www.youtube.com/watch?v=Q9GU8AjN_H8', 'https://www.youtube.com/watch?v=xmFaiqtghBU', 'https://www.youtube.com/watch?v=h3HWtTWN3OQ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for 理科太太 Li Ke Tai Tai:  ['https://www.youtube.com/watch?v=E1789fuBkkU', 'https://www.youtube.com/watch?v=C_MjJlcIRHs', 'https://www.youtube.com/watch?v=Q1o1ohed5sA', 'https://www.youtube.com/watch?v=YlL0Nz6m_Yg', 'https://www.youtube.com/watch?v=YI4LimFWx1I', 'https://www.youtube.com/watch?v=UwQX8DjzP3Y', 'https://www.youtube.com/watch?v=SCCo9AkyKoE', 'https://www.youtube.com/watch?v=SC8dA_5QL2w', 'https://www.youtube.com/watch?v=xZ_zZeEC08w', 'https://www.youtube.com/watch?v=3sXJrssmrXM', 'https://www.youtube.com/watch?v=M5ef2rl4wpw', 'https://www.youtube.com/watch?v=dFlbsMqRoyk', 'https://www.youtube.com/watch?v=QiPdDssMbq4', 'https://www.youtube.com/watch?v=vmLqMkSYQXM', 'https://www.youtube.com/watch?v=_TEwTU2mpPM', 'https://www.youtube.com/watch?v=VGSh0L8YYSM', 'https://www.youtube.com/watch?v=SmOnwBJM3Cw', 'https://www.youtube.com/watch?v=lfYkNweVbUw', 'https://www.youtube.com/watch?v=n3OzmfBWuDQ', 'https://www.youtube.com/watch?v=NBgmKrgeYgI', 'https://www.youtube.com/watch?v=vCIbLNaWhc0', 'https://www.youtube.com/watch?v=Az2ahEn5R4U', 'https://www.youtube.com/watch?v=hvaH2wjwZeE', 'https://www.youtube.com/watch?v=72jHqoBBJWI', 'https://www.youtube.com/watch?v=oabGLoBE4Yw', 'https://www.youtube.com/watch?v=N3fT1MMVPjw', 'https://www.youtube.com/watch?v=ZoyhoH0VCyc', 'https://www.youtube.com/watch?v=evXc3oVEeEE', 'https://www.youtube.com/watch?v=OYLv8lEqXLQ', 'https://www.youtube.com/watch?v=AkZizynShf8', 'https://www.youtube.com/watch?v=6aXpsxa0Z7g', 'https://www.youtube.com/watch?v=4ICdv8XMhWQ', 'https://www.youtube.com/watch?v=9uKfqfv7Kp4', 'https://www.youtube.com/watch?v=FM5b7j3X628', 'https://www.youtube.com/watch?v=2iWj5FEblJY', 'https://www.youtube.com/watch?v=6kABICjCRWg', 'https://www.youtube.com/watch?v=XI9P1DQBrtk', 'https://www.youtube.com/watch?v=2MeI22SAz9c']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for Brian Tracy:  ['https://www.youtube.com/watch?v=C6HaBSkA6xU', 'https://www.youtube.com/watch?v=WM1KN4J05FM', 'https://www.youtube.com/watch?v=pkDnvxaPJtU', 'https://www.youtube.com/watch?v=L61s3UPCDQA', 'https://www.youtube.com/watch?v=B_VTA8X9y3U', 'https://www.youtube.com/watch?v=Ve7q421iE2w', 'https://www.youtube.com/watch?v=7oFeHZQ3n4M', 'https://www.youtube.com/watch?v=S1SfRCRbaf0', 'https://www.youtube.com/watch?v=OH2V71GWgUA', 'https://www.youtube.com/watch?v=aaMcWg_XEVU', 'https://www.youtube.com/watch?v=kjRDvACn6Ls', 'https://www.youtube.com/watch?v=ZBvv6ciCVFk', 'https://www.youtube.com/watch?v=ASqkHoHfDMI', 'https://www.youtube.com/watch?v=7oKpedyMLJw', 'https://www.youtube.com/watch?v=9JzJDMt7eXE', 'https://www.youtube.com/watch?v=niI8RlDiLW0', 'https://www.youtube.com/watch?v=crZG3xDWA_A', 'https://www.youtube.com/watch?v=bz9wtjo0DVQ', 'https://www.youtube.com/watch?v=pSZLAXPhPXc', 'https://www.youtube.com/watch?v=YBhM2nWb0wA', 'https://www.youtube.com/watch?v=vfPw0eHREBs', 'https://www.youtube.com/watch?v=zvt1MEjVxcw', 'https://www.youtube.com/watch?v=zHNMfLFW3Pk', 'https://www.youtube.com/watch?v=qm2ebTABtPY', 'https://www.youtube.com/watch?v=Lp__fx4dSNk', 'https://www.youtube.com/watch?v=8bYpQdqRbx8', 'https://www.youtube.com/watch?v=PAdzClfuYNo', 'https://www.youtube.com/watch?v=UXcQLthjjPQ', 'https://www.youtube.com/watch?v=G8CRjYRCEXU', 'https://www.youtube.com/watch?v=pGedlaxHDjI', 'https://www.youtube.com/watch?v=ffr47PNkt_Q', 'https://www.youtube.com/watch?v=mfeFxUedjWw', 'https://www.youtube.com/watch?v=tj3Upy5Z0yw', 'https://www.youtube.com/watch?v=CVAzhASMSBQ', 'https://www.youtube.com/watch?v=VF_k38tOprU', 'https://www.youtube.com/watch?v=Edmw7ZwC96c', 'https://www.youtube.com/watch?v=8VQ2rujlBYQ', 'https://www.youtube.com/watch?v=ctDdaenTT7k', 'https://www.youtube.com/watch?v=ByPFllqr3PA', 'https://www.youtube.com/watch?v=7IjpP7nYf0g']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for Now You See It:  ['https://www.youtube.com/watch?v=g6lcT4EhNzM']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shorts_urls for Fitness Guru:  []\n",
      "([('Marc Brunet', 'https://www.youtube.com/watch?v=Qc6NO19u3MM'), ('Jen_ny69', 'https://www.youtube.com/watch?v=ixq_pOK7jk0'), ('DawateIslami', 'https://www.youtube.com/watch?v=JhocFEigq3k'), ('Go Natural English with Gabby Wallace', 'https://www.youtube.com/watch?v=v9dcf7OF1Wg'), ('ReligionForBreakfast', 'https://www.youtube.com/watch?v=WZn6dF9C1NQ'), ('Medicosis Perfectionalis', 'https://www.youtube.com/watch?v=wFVlzZUWFcw'), ('理科太太 Li Ke Tai Tai', 'https://www.youtube.com/watch?v=E1789fuBkkU'), ('Brian Tracy', 'https://www.youtube.com/watch?v=C6HaBSkA6xU'), ('Now You See It', 'https://www.youtube.com/watch?v=g6lcT4EhNzM')],    channel_name                                       yt_fixed_url\n",
      "0  Fitness Guru  https://www.youtube.com/channel/UCKJOEv8ymPEmT...)\n"
     ]
    }
   ],
   "source": [
    "new_shorts_urls = scanning_yt_shorts_page('3397e8a6a37e89b03b08750a27575df8', channel_df, loaded_df)\n",
    "print(new_shorts_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba2d7eb",
   "metadata": {},
   "source": [
    "#### YouTube 채널 및 shorts를 업로드 하지 않는 경우\n",
    "- data_yn에서 y를 n으로 변경 (y가 default)\n",
    "- 필터링 중 n이였던 건이 y가 되는 경우도 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1cbb7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       youtuberme_url   category  \\\n",
      "30  https://us.youtubers.me//brushboost/youtuber-s...  education   \n",
      "31   https://us.youtubers.me//jen_ny69/youtuber-stats  education   \n",
      "32  https://us.youtubers.me//dawateislami/youtuber...  education   \n",
      "33  https://us.youtubers.me//go-natural-english-by...  education   \n",
      "34  https://us.youtubers.me//religionforbreakfast/...  education   \n",
      "35  https://us.youtubers.me//medicosis-perfectiona...  education   \n",
      "36  https://us.youtubers.me//tai-tai-li-ke/youtube...  education   \n",
      "37  https://us.youtubers.me//brian-tracy/youtuber-...  education   \n",
      "38  https://us.youtubers.me//now-you-see-it/youtub...  education   \n",
      "39  https://us.youtubers.me//fitness-guru/youtuber...  education   \n",
      "\n",
      "          country                           channel_name  subscribers  \\\n",
      "30  United States                            Marc Brunet      1570000   \n",
      "31  United States                               Jen_ny69      1020000   \n",
      "32  United States                           DawateIslami       955000   \n",
      "33  United States  Go Natural English with Gabby Wallace      2280000   \n",
      "34  United States                   ReligionForBreakfast       805000   \n",
      "35  United States               Medicosis Perfectionalis      1140000   \n",
      "36  United States                     理科太太 Li Ke Tai Tai      1130000   \n",
      "37  United States                            Brian Tracy      1570000   \n",
      "38  United States                         Now You See It       964000   \n",
      "39  United States                           Fitness Guru       659000   \n",
      "\n",
      "    total_video_views  total_video_count  started  \\\n",
      "30           84742744                261     2008   \n",
      "31           84321071                300     2012   \n",
      "32           83737949               1319     2015   \n",
      "33           83468179                804     2011   \n",
      "34           83361295                247     2013   \n",
      "35           80240316               2334     2017   \n",
      "36           80095772                238     2018   \n",
      "37           80001315                904     2007   \n",
      "38           79125245                 96     2015   \n",
      "39           78023000                737     2016   \n",
      "\n",
      "                                               yt_url  \\\n",
      "30        https://us.youtubers.me//brushboost/youtube   \n",
      "31          https://us.youtubers.me//jen_ny69/youtube   \n",
      "32      https://us.youtubers.me//dawateislami/youtube   \n",
      "33  https://us.youtubers.me//go-natural-english-by...   \n",
      "34  https://us.youtubers.me//religionforbreakfast/...   \n",
      "35  https://us.youtubers.me//medicosis-perfectiona...   \n",
      "36     https://us.youtubers.me//tai-tai-li-ke/youtube   \n",
      "37       https://us.youtubers.me//brian-tracy/youtube   \n",
      "38    https://us.youtubers.me//now-you-see-it/youtube   \n",
      "39      https://us.youtubers.me//fitness-guru/youtube   \n",
      "\n",
      "                                         yt_fixed_url data_yn  \n",
      "30  https://www.youtube.com/channel/UCKtu_JtQCY0yr...       Y  \n",
      "31  https://www.youtube.com/channel/UC3KD-V1QgBMml...       Y  \n",
      "32  https://www.youtube.com/channel/UC7xiEjMTy-8Ev...       Y  \n",
      "33  https://www.youtube.com/channel/UC9Pbt3q-ihROg...       Y  \n",
      "34  https://www.youtube.com/channel/UCct9aR7HC79Cv...       Y  \n",
      "35  https://www.youtube.com/channel/UCl-J-ovSJhA3o...       Y  \n",
      "36  https://www.youtube.com/channel/UCHfY_EOzB1i57...       Y  \n",
      "37  https://www.youtube.com/channel/UCc11676iKpKrJ...       Y  \n",
      "38  https://www.youtube.com/channel/UCWTFGPpNQ0Ms6...       Y  \n",
      "39  https://www.youtube.com/channel/UCKJOEv8ymPEmT...       n  \n"
     ]
    }
   ],
   "source": [
    "def update_channel_df_with_new_shorts(channel_df, new_shorts_urls_df):\n",
    "    # Iterate over each row in new_shorts_urls_df to match with channel_df\n",
    "    for index, row in new_shorts_urls_df.iterrows():\n",
    "        target_channel_name = row['channel_name']\n",
    "        \n",
    "        # Update 'data_yn' in channel_df where 'channel_name' matches\n",
    "        channel_df.loc[channel_df['channel_name'] == target_channel_name, 'data_yn'] = 'n'\n",
    "\n",
    "    # Return the updated channel_df with all rows\n",
    "    return channel_df\n",
    "\n",
    "updated_channel_df = update_channel_df_with_new_shorts(channel_df, new_shorts_urls[1])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(updated_channel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cb90094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>yt_fixed_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fitness Guru</td>\n",
       "      <td>https://www.youtube.com/channel/UCKJOEv8ymPEmT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   channel_name                                       yt_fixed_url\n",
       "0  Fitness Guru  https://www.youtube.com/channel/UCKJOEv8ymPEmT..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_shorts_urls[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553e0ec",
   "metadata": {},
   "source": [
    "##### 3. 수집한 channel list 수집 후 loaded_db에 적재\n",
    "- new_shorts_urls 기준으로 rendered=True로 수집\n",
    "- 수집 데이터 loaded_db에 적재 후 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e73fbec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marc Brunet https://www.youtube.com/watch?v=Qc6NO19u3MM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  Marc Brunet\n",
      "shorts_title:  \n",
      "shorts_description:  👨‍🎨 Serious about your art? Check out my ART School program here! ➡️ cgart.school (or link in bio)\n",
      "shorts_published:  nan\n",
      "shorts_thumbnalil:  https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube\n",
      "view:  121,372\n",
      "likes:  17000.0\n",
      "comments:  94.0\n",
      "shorts_comments_time:  nan\n",
      "Jen_ny69 https://www.youtube.com/watch?v=ixq_pOK7jk0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  Jen_ny69\n",
      "shorts_title:  \n",
      "shorts_description:  Watch full video on ‪@adayinthelifeofa69‬\n",
      "shorts_published:  nan\n",
      "shorts_thumbnalil:  https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube\n",
      "view:  6,270\n",
      "likes:  328.0\n",
      "comments:  13.0\n",
      "shorts_comments_time:  nan\n",
      "DawateIslami https://www.youtube.com/watch?v=JhocFEigq3k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  DawateIslami\n",
      "shorts_title:  \n",
      "shorts_description:  Kabhi Ye Bhi Try Karen | #dawateislami #whatsappstatus #telethon #islamiccharity #bayanstatus \\n\\nJoin the Cause! Your Generosity Can Make a Difference – Donate Today at Our Telethon!\\nUAN # 021 111 113 473\\nWhatsApp # 03 111 111 226\\nDonate Now:\\nhttps://www.dawateislami.net/onlinedo...\\n#Telethon3Nov\\n#DawateislamiTelethon\\n\\nCOPYRIGHTS RESERVED BY Dawat-e-Islami\\n\\nFollow us on Social Media: \\n\\n► Join Us On Facebook:\\n  / dawateislami.net  \\n\\n► Subscribe Dawat-e-Islami's Official YouTube Channel:\\n   / @dawateislami  \\n\\n► Follow us on Twitter:\\nhttps://x.com/MADANIinfo\\n\\n► Follow on Instagram:\\n  / dawateislam  \n",
      "shorts_published:  nan\n",
      "shorts_thumbnalil:  https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube\n",
      "view:  926\n",
      "likes:  229.0\n",
      "comments:  3.0\n",
      "shorts_comments_time:  nan\n",
      "Go Natural English with Gabby Wallace https://www.youtube.com/watch?v=v9dcf7OF1Wg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  Go Natural English with Gabby Wallace\n",
      "shorts_title:  \n",
      "shorts_description:  None\n",
      "shorts_published:  nan\n",
      "shorts_thumbnalil:  https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube\n",
      "view:  3,897\n",
      "likes:  72.0\n",
      "comments:  3.0\n",
      "shorts_comments_time:  nan\n",
      "ReligionForBreakfast https://www.youtube.com/watch?v=WZn6dF9C1NQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  ReligionForBreakfast\n",
      "shorts_title:  \n",
      "shorts_description:  None\n",
      "shorts_published:  nan\n",
      "shorts_thumbnalil:  https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube\n",
      "view:  82,627\n",
      "likes:  4700.0\n",
      "comments:  206.0\n",
      "shorts_comments_time:  nan\n",
      "Medicosis Perfectionalis https://www.youtube.com/watch?v=wFVlzZUWFcw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  Medicosis Perfectionalis\n",
      "shorts_title:  \n",
      "shorts_description:  None\n",
      "shorts_published:  nan\n",
      "shorts_thumbnalil:  https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube\n",
      "view:  2,977\n",
      "likes:  284.0\n",
      "comments:  5.0\n",
      "shorts_comments_time:  nan\n",
      "理科太太 Li Ke Tai Tai https://www.youtube.com/watch?v=E1789fuBkkU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  理科太太 Li Ke Tai Tai\n",
      "shorts_title:  貓咪個性這麼差，原來都是基因決定的！\n",
      "shorts_description:  None\n",
      "shorts_published:  2024-01-17 22\n",
      "shorts_thumbnalil:  https://rr3---sn-vgqsrnsr.googlevideo.com/videoplayback?expire=1729795493\\u0026ei=RUEaZ4bwA9ijlu8P0YPk0Q8\\u0026ip=109.121.40.7\\u0026id=o-AN4g-UD0h2UxQRyKNINNY7tTownovj-xCztRKcylTZOv\\u0026itag=18\\u0026source=youtube\\u0026requiressl=yes\\u0026xpc=EgVo2aDSNQ%3D%3D\\u0026met=1729773893%2C\\u0026mh=NB\\u0026mm=31%2C29\\u0026mn=sn-vgqsrnsr%2Csn-vgqsknze\\u0026ms=au%2Crdu\\u0026mv=u\\u0026mvi=3\\u0026pl=24\\u0026rms=au%2Cau\\u0026bui=AXLXGFTQuTCmAdRYUykqKCt8M5xY0FBSB18gB3-ulcEq6Yy1fOdbocNhKWR833ZxQLuAzvH9TqbqUf0g\\u0026spc=54MbxebnlHrjXAAW578iPCXkhvWIjQdcbyLTAisLS52OcZ7wfTCXzGdbUs350hE\\u0026vprv=1\\u0026svpuc=1\\u0026mime=video%2Fmp4\\u0026ns=PHlJtvMFgu_H_WM72L_Kw8QQ\\u0026rqh=1\\u0026gir=yes\\u0026clen=2152144\\u0026ratebypass=yes\\u0026dur=28.885\\u0026lmt=1705556810718508\\u0026mt=1729773546\\u0026fvip=1\\u0026fexp=51312688%2C51326932\\u0026c=WEB\\u0026sefc=1\\u0026txp=6300224\\u0026n=0xw_ff1OipM-4u4_u\\u0026sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt\\u0026sig=AJfQdSswRQIhAOV5QDzjUKS3BO1ymXH8eK4ehK4K2IsirXsl5K76FWP-AiAgOByar6yGsIHSpSVpPskQWfIvUMW6ZZq2VqxO_UPRPQ%3D%3D\\u0026lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms\\u0026lsig=ACJ0pHgwRAIgREknLlJsOjecYsKcb4kox8OG5nLE2htXOmUDguo8iNMCIGZJvanvrG2Yyt4eyIObO6oa_7fkb4cxYET2TTfNLXr3\n",
      "view:  15,447\n",
      "likes:  327.0\n",
      "comments:  12.0\n",
      "shorts_comments_time:  nan\n",
      "Brian Tracy https://www.youtube.com/watch?v=C6HaBSkA6xU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  Brian Tracy\n",
      "shorts_title:  Shift Your Mindset\n",
      "shorts_description:  Imagine the possibilities if failure weren’t a factor—how bold would your dreams be? Often, we hold back due to fear, but envisioning a life free from this constraint can reveal passions we’ve sidelined. 💭⁠\\n⁠\\nThis mindset inspires us to think big, whether it’s starting a business, pursuing a creative project, or making a significant life change. It helps us identify what truly matters and motivates us to take actionable steps toward our dreams.⁠\\n⁠\\nSo, what dreams are calling you, and what steps can you take today to make them a reality?⁠\\n\\nCheck out this 14-Step Goal Setting Guide to help set, pursue, and achieve your goals: https://bit.ly/4bbccaa\\n⁠\\n🎥: @hustlewithlana ⁠on Instagram\\n\\n#briantracy #success #motivation #goals #inspiration #stayinspired #successtips #motivated #successful \\n\\n___________________\\n\\nLearn more: \\n\\nSubscribe to my channel for free offers, tips and more!\\nYouTube: http://ow.ly/ScHSb\\nFacebook:   / briantracypage  \\nTwitter:   / briantracy  \\nGoogle+: +BrianTracyOfficialPage\\nPinterest:   / briantracy  \\nInstagram: @TheBrianTracy\\nBlog: http://bit.ly/1rc4hlg\n",
      "shorts_published:  2024-10-23 09\n",
      "shorts_thumbnalil:  https://i.ytimg.com/vi/C6HaBSkA6xU/hq2.jpg?sqp=-oaymwE8CKgBEF5IWvKriqkDLwgBFQAAAAAYACUAAMhCPQCAokN4AfABAfgBzgWAAoAKigIMCAAQARhlIFgoXDAP\\u0026rs=AOn4CLD5suD3-yNVsJCDfutb2O7tmwbTcQ\n",
      "view:  4,477\n",
      "likes:  562.0\n",
      "comments:  8.0\n",
      "shorts_comments_time:  nan\n",
      "Now You See It https://www.youtube.com/watch?v=g6lcT4EhNzM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T14Gen1\\Documents\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.scraperapi.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  Now You See It\n",
      "shorts_title:  The Best Steven Spielberg Interview Question Ever #shorts #film #movies #stevenspielberg\n",
      "shorts_description:  Movies: The Fablemans (2022) and Close Encounters of the Third Kind (1977)\\nFrom James Lipton - Inside Actor's Studio Episode #5.9\\nFull interview: https://www.dailymotion.com/video/xjqe5\\nOriginal interview source:    • Best Interview Question Ever - Steven...  \\n\\n#shorts #film #movies #stevenspielberg\n",
      "shorts_published:  2023-01-07 09\n",
      "shorts_thumbnalil:  https://rr1---sn-f58xn2xxq-aj5l.googlevideo.com/videoplayback?expire=1729795501\\u0026ei=TUEaZ_CCL8zYxN8P7uub-QM\\u0026ip=103.80.10.244\\u0026id=o-AMxyITgrENRuzdK3vFcXUvlcAWFyxr8xCIiHcWy2y-o8\\u0026itag=18\\u0026source=youtube\\u0026requiressl=yes\\u0026xpc=EgVo2aDSNQ%3D%3D\\u0026met=1729773901%2C\\u0026mh=R1\\u0026mm=31%2C29\\u0026mn=sn-f58xn2xxq-aj5l%2Csn-hgn7rnll\\u0026ms=au%2Crdu\\u0026mv=m\\u0026mvi=1\\u0026pl=23\\u0026rms=au%2Cau\\u0026initcwndbps=726250\\u0026bui=AXLXGFS7xAEJOiLKutq64K3bZQWf9UoJTNjcJsvSA_3AWPKOlhtPzrWDrhqvqbB9U2TDGUsG0b0CnCxl\\u0026spc=54MbxXWt4SFAFdKtsxlIFAxFkK9COVXbcyKLoYddn9HiiW5PpQ3j-5gxSaNAeag\\u0026vprv=1\\u0026svpuc=1\\u0026mime=video%2Fmp4\\u0026ns=2R4tKpU6XPQyfyV0rSeyfuUQ\\u0026rqh=1\\u0026cnr=14\\u0026ratebypass=yes\\u0026dur=34.295\\u0026lmt=1697215605722644\\u0026mt=1729773425\\u0026fvip=2\\u0026fexp=51312688%2C51326932\\u0026c=WEB\\u0026sefc=1\\u0026txp=6300224\\u0026n=JGQvov2CO1KLUy2na\\u0026sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Ccnr%2Cratebypass%2Cdur%2Clmt\\u0026sig=AJfQdSswRQIhAJs69RFTZMgV8gBzbCgwAaoK1k45-PWdcUx3v6nTCu1kAiBXeas8FQOmnV5TPilUsVIfDXSqlM0rxHqzwJM7NxqErQ%3D%3D\\u0026lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps\\u0026lsig=ACJ0pHgwRQIhAJOhIdJMwnL2Rct_ylZx9ZN0IIiv2-dllbpyBTikSMzrAiAGXor-DVi41qts9NtbxSzKCVhsbMEO7jVw1eQZMClc2w%3D%3D\n",
      "view:  47,959\n",
      "likes:  2400.0\n",
      "comments:  32.0\n",
      "shorts_comments_time:  nan\n",
      "[('Marc Brunet', 'https://www.youtube.com/watch?v=Qc6NO19u3MM', '', '👨\\u200d🎨 Serious about your art? Check out my ART School program here! ➡️ cgart.school (or link in bio)', 'https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube', '121,372', 17000.0, 94.0, nan, nan, datetime.datetime(2024, 10, 24, 21, 44, 30, 453033)), ('Jen_ny69', 'https://www.youtube.com/watch?v=ixq_pOK7jk0', '', 'Watch full video on \\u202a@adayinthelifeofa69\\u202c', 'https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube', '6,270', 328.0, 13.0, nan, nan, datetime.datetime(2024, 10, 24, 21, 44, 30, 453033)), ('DawateIslami', 'https://www.youtube.com/watch?v=JhocFEigq3k', '', \"Kabhi Ye Bhi Try Karen | #dawateislami #whatsappstatus #telethon #islamiccharity #bayanstatus \\\\n\\\\nJoin the Cause! Your Generosity Can Make a Difference – Donate Today at Our Telethon!\\\\nUAN # 021 111 113 473\\\\nWhatsApp # 03 111 111 226\\\\nDonate Now:\\\\nhttps://www.dawateislami.net/onlinedo...\\\\n#Telethon3Nov\\\\n#DawateislamiTelethon\\\\n\\\\nCOPYRIGHTS RESERVED BY Dawat-e-Islami\\\\n\\\\nFollow us on Social Media: \\\\n\\\\n► Join Us On Facebook:\\\\n\\xa0\\xa0/\\xa0dawateislami.net\\xa0\\xa0\\\\n\\\\n► Subscribe Dawat-e-Islami's Official YouTube Channel:\\\\n\\xa0\\xa0\\xa0/\\xa0@dawateislami\\xa0\\xa0\\\\n\\\\n► Follow us on Twitter:\\\\nhttps://x.com/MADANIinfo\\\\n\\\\n► Follow on Instagram:\\\\n\\xa0\\xa0/\\xa0dawateislam\\xa0\\xa0\", 'https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube', '926', 229.0, 3.0, nan, nan, datetime.datetime(2024, 10, 24, 21, 44, 30, 453033)), ('Go Natural English with Gabby Wallace', 'https://www.youtube.com/watch?v=v9dcf7OF1Wg', '', None, 'https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube', '3,897', 72.0, 3.0, nan, nan, datetime.datetime(2024, 10, 24, 21, 44, 30, 453033)), ('ReligionForBreakfast', 'https://www.youtube.com/watch?v=WZn6dF9C1NQ', '', None, 'https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube', '82,627', 4700.0, 206.0, nan, nan, datetime.datetime(2024, 10, 24, 21, 44, 30, 453033)), ('Medicosis Perfectionalis', 'https://www.youtube.com/watch?v=wFVlzZUWFcw', '', None, 'https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube', '2,977', 284.0, 5.0, nan, nan, datetime.datetime(2024, 10, 24, 21, 44, 30, 453033)), ('理科太太 Li Ke Tai Tai', 'https://www.youtube.com/watch?v=E1789fuBkkU', '貓咪個性這麼差，原來都是基因決定的！', None, 'https://rr3---sn-vgqsrnsr.googlevideo.com/videoplayback?expire=1729795493\\\\u0026ei=RUEaZ4bwA9ijlu8P0YPk0Q8\\\\u0026ip=109.121.40.7\\\\u0026id=o-AN4g-UD0h2UxQRyKNINNY7tTownovj-xCztRKcylTZOv\\\\u0026itag=18\\\\u0026source=youtube\\\\u0026requiressl=yes\\\\u0026xpc=EgVo2aDSNQ%3D%3D\\\\u0026met=1729773893%2C\\\\u0026mh=NB\\\\u0026mm=31%2C29\\\\u0026mn=sn-vgqsrnsr%2Csn-vgqsknze\\\\u0026ms=au%2Crdu\\\\u0026mv=u\\\\u0026mvi=3\\\\u0026pl=24\\\\u0026rms=au%2Cau\\\\u0026bui=AXLXGFTQuTCmAdRYUykqKCt8M5xY0FBSB18gB3-ulcEq6Yy1fOdbocNhKWR833ZxQLuAzvH9TqbqUf0g\\\\u0026spc=54MbxebnlHrjXAAW578iPCXkhvWIjQdcbyLTAisLS52OcZ7wfTCXzGdbUs350hE\\\\u0026vprv=1\\\\u0026svpuc=1\\\\u0026mime=video%2Fmp4\\\\u0026ns=PHlJtvMFgu_H_WM72L_Kw8QQ\\\\u0026rqh=1\\\\u0026gir=yes\\\\u0026clen=2152144\\\\u0026ratebypass=yes\\\\u0026dur=28.885\\\\u0026lmt=1705556810718508\\\\u0026mt=1729773546\\\\u0026fvip=1\\\\u0026fexp=51312688%2C51326932\\\\u0026c=WEB\\\\u0026sefc=1\\\\u0026txp=6300224\\\\u0026n=0xw_ff1OipM-4u4_u\\\\u0026sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cratebypass%2Cdur%2Clmt\\\\u0026sig=AJfQdSswRQIhAOV5QDzjUKS3BO1ymXH8eK4ehK4K2IsirXsl5K76FWP-AiAgOByar6yGsIHSpSVpPskQWfIvUMW6ZZq2VqxO_UPRPQ%3D%3D\\\\u0026lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms\\\\u0026lsig=ACJ0pHgwRAIgREknLlJsOjecYsKcb4kox8OG5nLE2htXOmUDguo8iNMCIGZJvanvrG2Yyt4eyIObO6oa_7fkb4cxYET2TTfNLXr3', '15,447', 327.0, 12.0, nan, '2024-01-17 22', datetime.datetime(2024, 10, 24, 21, 44, 30, 453033)), ('Brian Tracy', 'https://www.youtube.com/watch?v=C6HaBSkA6xU', 'Shift Your Mindset', 'Imagine the possibilities if failure weren’t a factor—how bold would your dreams be? Often, we hold back due to fear, but envisioning a life free from this constraint can reveal passions we’ve sidelined. 💭\\u2060\\\\n\\u2060\\\\nThis mindset inspires us to think big, whether it’s starting a business, pursuing a creative project, or making a significant life change. It helps us identify what truly matters and motivates us to take actionable steps toward our dreams.\\u2060\\\\n\\u2060\\\\nSo, what dreams are calling you, and what steps can you take today to make them a reality?\\u2060\\\\n\\\\nCheck out this 14-Step Goal Setting Guide to help set, pursue, and achieve your goals: https://bit.ly/4bbccaa\\\\n\\u2060\\\\n🎥: @hustlewithlana \\u2060on Instagram\\\\n\\\\n#briantracy #success #motivation #goals #inspiration #stayinspired #successtips #motivated #successful \\\\n\\\\n___________________\\\\n\\\\nLearn more: \\\\n\\\\nSubscribe to my channel for free offers, tips and more!\\\\nYouTube: http://ow.ly/ScHSb\\\\nFacebook: \\xa0\\xa0/\\xa0briantracypage\\xa0\\xa0\\\\nTwitter: \\xa0\\xa0/\\xa0briantracy\\xa0\\xa0\\\\nGoogle+: +BrianTracyOfficialPage\\\\nPinterest: \\xa0\\xa0/\\xa0briantracy\\xa0\\xa0\\\\nInstagram: @TheBrianTracy\\\\nBlog: http://bit.ly/1rc4hlg', 'https://i.ytimg.com/vi/C6HaBSkA6xU/hq2.jpg?sqp=-oaymwE8CKgBEF5IWvKriqkDLwgBFQAAAAAYACUAAMhCPQCAokN4AfABAfgBzgWAAoAKigIMCAAQARhlIFgoXDAP\\\\u0026rs=AOn4CLD5suD3-yNVsJCDfutb2O7tmwbTcQ', '4,477', 562.0, 8.0, nan, '2024-10-23 09', datetime.datetime(2024, 10, 24, 21, 44, 30, 453033)), ('Now You See It', 'https://www.youtube.com/watch?v=g6lcT4EhNzM', 'The Best Steven Spielberg Interview Question Ever #shorts #film #movies #stevenspielberg', \"Movies: The Fablemans (2022) and Close Encounters of the Third Kind (1977)\\\\nFrom James Lipton - Inside Actor's Studio Episode #5.9\\\\nFull interview: https://www.dailymotion.com/video/xjqe5\\\\nOriginal interview source: \\xa0\\xa0\\xa0•\\xa0Best\\xa0Interview\\xa0Question\\xa0Ever\\xa0-\\xa0Steven...\\xa0\\xa0\\\\n\\\\n#shorts #film #movies #stevenspielberg\", 'https://rr1---sn-f58xn2xxq-aj5l.googlevideo.com/videoplayback?expire=1729795501\\\\u0026ei=TUEaZ_CCL8zYxN8P7uub-QM\\\\u0026ip=103.80.10.244\\\\u0026id=o-AMxyITgrENRuzdK3vFcXUvlcAWFyxr8xCIiHcWy2y-o8\\\\u0026itag=18\\\\u0026source=youtube\\\\u0026requiressl=yes\\\\u0026xpc=EgVo2aDSNQ%3D%3D\\\\u0026met=1729773901%2C\\\\u0026mh=R1\\\\u0026mm=31%2C29\\\\u0026mn=sn-f58xn2xxq-aj5l%2Csn-hgn7rnll\\\\u0026ms=au%2Crdu\\\\u0026mv=m\\\\u0026mvi=1\\\\u0026pl=23\\\\u0026rms=au%2Cau\\\\u0026initcwndbps=726250\\\\u0026bui=AXLXGFS7xAEJOiLKutq64K3bZQWf9UoJTNjcJsvSA_3AWPKOlhtPzrWDrhqvqbB9U2TDGUsG0b0CnCxl\\\\u0026spc=54MbxXWt4SFAFdKtsxlIFAxFkK9COVXbcyKLoYddn9HiiW5PpQ3j-5gxSaNAeag\\\\u0026vprv=1\\\\u0026svpuc=1\\\\u0026mime=video%2Fmp4\\\\u0026ns=2R4tKpU6XPQyfyV0rSeyfuUQ\\\\u0026rqh=1\\\\u0026cnr=14\\\\u0026ratebypass=yes\\\\u0026dur=34.295\\\\u0026lmt=1697215605722644\\\\u0026mt=1729773425\\\\u0026fvip=2\\\\u0026fexp=51312688%2C51326932\\\\u0026c=WEB\\\\u0026sefc=1\\\\u0026txp=6300224\\\\u0026n=JGQvov2CO1KLUy2na\\\\u0026sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Ccnr%2Cratebypass%2Cdur%2Clmt\\\\u0026sig=AJfQdSswRQIhAJs69RFTZMgV8gBzbCgwAaoK1k45-PWdcUx3v6nTCu1kAiBXeas8FQOmnV5TPilUsVIfDXSqlM0rxHqzwJM7NxqErQ%3D%3D\\\\u0026lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps\\\\u0026lsig=ACJ0pHgwRQIhAJOhIdJMwnL2Rct_ylZx9ZN0IIiv2-dllbpyBTikSMzrAiAGXor-DVi41qts9NtbxSzKCVhsbMEO7jVw1eQZMClc2w%3D%3D', '47,959', 2400.0, 32.0, nan, '2023-01-07 09', datetime.datetime(2024, 10, 24, 21, 44, 30, 453033))]\n"
     ]
    }
   ],
   "source": [
    "# url 여러개 진행\n",
    "import requests\n",
    "API_KEY = '3397e8a6a37e89b03b08750a27575df8'\n",
    "today = datetime.today()\n",
    "def add_new_shorts_data(api_key, urls):\n",
    "    data_list = []\n",
    "    check_date = today\n",
    "    # Separate channel names and shorts URLs\n",
    "    channel_names = [item[0] for item in urls]\n",
    "    shorts_urls = [item[1] for item in urls]\n",
    "    \n",
    "    for channel_name, url in zip(channel_names, shorts_urls):\n",
    "        print(channel_name, url)\n",
    "        shorts_url = url\n",
    "        # Prepare payload and headers for the request\n",
    "        payload = {\n",
    "            'api_key': api_key,\n",
    "            'url': url\n",
    "            # ,'render': 'true'\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            'x-sapi-render': 'true',\n",
    "            'x-sapi-instruction_set': '[{\"type\":\"scroll\",\"direction\":\"y\",\"value\":\"bottom\"}, {\"type\": \"wait\", \"value\": 3}]'\n",
    "        }\n",
    "\n",
    "        # Make the GET request\n",
    "        r = requests.get('https://api.scraperapi.com/', params=payload,  verify=False)#headers=headers,\n",
    "        # Extract the necessary data\n",
    "        shorts_title, shorts_description, shorts_published, shorts_thumbnail, shorts_view, shorts_likes, shorts_comments_num, shorts_comments_time = basic_shorts_info(r.text)\n",
    "        \n",
    "        # Print the extracted information for debugging\n",
    "        print(\"title: \", channel_name)\n",
    "        print(\"shorts_title: \", shorts_title)\n",
    "        print(\"shorts_description: \", shorts_description)\n",
    "        print(\"shorts_published: \", shorts_published)\n",
    "        print(\"shorts_thumbnalil: \", shorts_thumbnail)\n",
    "        print(\"view: \", shorts_view)\n",
    "        print(\"likes: \", shorts_likes)\n",
    "        print(\"comments: \", shorts_comments_num)\n",
    "        print(\"shorts_comments_time: \", shorts_comments_time)\n",
    "\n",
    "        # Append as a tuple to the data_list\n",
    "        data_list.append((\n",
    "            channel_name,\n",
    "            shorts_url, \n",
    "            shorts_title,  \n",
    "            shorts_description, \n",
    "            shorts_thumbnail, \n",
    "            shorts_view, \n",
    "            shorts_likes, \n",
    "            shorts_comments_num, \n",
    "            shorts_comments_time,\n",
    "            shorts_published, \n",
    "            check_date\n",
    "\n",
    "        ))\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "data_list = add_new_shorts_data(API_KEY, new_shorts_urls[0])\n",
    "print(data_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8ad24f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T14Gen1\\AppData\\Local\\Temp\\ipykernel_32672\\1389024915.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  updated_loaded_db = pd.concat([loaded_db, new_data_df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>shorts_url</th>\n",
       "      <th>shorts_title</th>\n",
       "      <th>shorts_description</th>\n",
       "      <th>shorts_thumbnail</th>\n",
       "      <th>shorts_view</th>\n",
       "      <th>shorts_likes</th>\n",
       "      <th>shorts_comments_num</th>\n",
       "      <th>shorts_comments_time</th>\n",
       "      <th>shorts_published_date</th>\n",
       "      <th>check_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marc Brunet</td>\n",
       "      <td>https://www.youtube.com/watch?v=Qc6NO19u3MM</td>\n",
       "      <td></td>\n",
       "      <td>👨‍🎨 Serious about your art? Check out my ART S...</td>\n",
       "      <td>https://support.google.com/youtube/answer/3037...</td>\n",
       "      <td>121,372</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-24 21:44:30.453033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jen_ny69</td>\n",
       "      <td>https://www.youtube.com/watch?v=ixq_pOK7jk0</td>\n",
       "      <td></td>\n",
       "      <td>Watch full video on ‪@adayinthelifeofa69‬</td>\n",
       "      <td>https://support.google.com/youtube/answer/3037...</td>\n",
       "      <td>6,270</td>\n",
       "      <td>328.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-24 21:44:30.453033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DawateIslami</td>\n",
       "      <td>https://www.youtube.com/watch?v=JhocFEigq3k</td>\n",
       "      <td></td>\n",
       "      <td>Kabhi Ye Bhi Try Karen | #dawateislami #whatsa...</td>\n",
       "      <td>https://support.google.com/youtube/answer/3037...</td>\n",
       "      <td>926</td>\n",
       "      <td>229.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-24 21:44:30.453033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go Natural English with Gabby Wallace</td>\n",
       "      <td>https://www.youtube.com/watch?v=v9dcf7OF1Wg</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>https://support.google.com/youtube/answer/3037...</td>\n",
       "      <td>3,897</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-24 21:44:30.453033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReligionForBreakfast</td>\n",
       "      <td>https://www.youtube.com/watch?v=WZn6dF9C1NQ</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>https://support.google.com/youtube/answer/3037...</td>\n",
       "      <td>82,627</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-24 21:44:30.453033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Medicosis Perfectionalis</td>\n",
       "      <td>https://www.youtube.com/watch?v=wFVlzZUWFcw</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>https://support.google.com/youtube/answer/3037...</td>\n",
       "      <td>2,977</td>\n",
       "      <td>284.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-24 21:44:30.453033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>理科太太 Li Ke Tai Tai</td>\n",
       "      <td>https://www.youtube.com/watch?v=E1789fuBkkU</td>\n",
       "      <td>貓咪個性這麼差，原來都是基因決定的！</td>\n",
       "      <td>None</td>\n",
       "      <td>https://rr3---sn-vgqsrnsr.googlevideo.com/vide...</td>\n",
       "      <td>15,447</td>\n",
       "      <td>327.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-17 22</td>\n",
       "      <td>2024-10-24 21:44:30.453033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brian Tracy</td>\n",
       "      <td>https://www.youtube.com/watch?v=C6HaBSkA6xU</td>\n",
       "      <td>Shift Your Mindset</td>\n",
       "      <td>Imagine the possibilities if failure weren’t a...</td>\n",
       "      <td>https://i.ytimg.com/vi/C6HaBSkA6xU/hq2.jpg?sqp...</td>\n",
       "      <td>4,477</td>\n",
       "      <td>562.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-10-23 09</td>\n",
       "      <td>2024-10-24 21:44:30.453033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Now You See It</td>\n",
       "      <td>https://www.youtube.com/watch?v=g6lcT4EhNzM</td>\n",
       "      <td>The Best Steven Spielberg Interview Question E...</td>\n",
       "      <td>Movies: The Fablemans (2022) and Close Encount...</td>\n",
       "      <td>https://rr1---sn-f58xn2xxq-aj5l.googlevideo.co...</td>\n",
       "      <td>47,959</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-07 09</td>\n",
       "      <td>2024-10-24 21:44:30.453033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            channel_name  \\\n",
       "0                            Marc Brunet   \n",
       "1                               Jen_ny69   \n",
       "2                           DawateIslami   \n",
       "3  Go Natural English with Gabby Wallace   \n",
       "4                   ReligionForBreakfast   \n",
       "5               Medicosis Perfectionalis   \n",
       "6                     理科太太 Li Ke Tai Tai   \n",
       "7                            Brian Tracy   \n",
       "8                         Now You See It   \n",
       "\n",
       "                                    shorts_url  \\\n",
       "0  https://www.youtube.com/watch?v=Qc6NO19u3MM   \n",
       "1  https://www.youtube.com/watch?v=ixq_pOK7jk0   \n",
       "2  https://www.youtube.com/watch?v=JhocFEigq3k   \n",
       "3  https://www.youtube.com/watch?v=v9dcf7OF1Wg   \n",
       "4  https://www.youtube.com/watch?v=WZn6dF9C1NQ   \n",
       "5  https://www.youtube.com/watch?v=wFVlzZUWFcw   \n",
       "6  https://www.youtube.com/watch?v=E1789fuBkkU   \n",
       "7  https://www.youtube.com/watch?v=C6HaBSkA6xU   \n",
       "8  https://www.youtube.com/watch?v=g6lcT4EhNzM   \n",
       "\n",
       "                                        shorts_title  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                 貓咪個性這麼差，原來都是基因決定的！   \n",
       "7                                 Shift Your Mindset   \n",
       "8  The Best Steven Spielberg Interview Question E...   \n",
       "\n",
       "                                  shorts_description  \\\n",
       "0  👨‍🎨 Serious about your art? Check out my ART S...   \n",
       "1          Watch full video on ‪@adayinthelifeofa69‬   \n",
       "2  Kabhi Ye Bhi Try Karen | #dawateislami #whatsa...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "5                                               None   \n",
       "6                                               None   \n",
       "7  Imagine the possibilities if failure weren’t a...   \n",
       "8  Movies: The Fablemans (2022) and Close Encount...   \n",
       "\n",
       "                                    shorts_thumbnail shorts_view  \\\n",
       "0  https://support.google.com/youtube/answer/3037...     121,372   \n",
       "1  https://support.google.com/youtube/answer/3037...       6,270   \n",
       "2  https://support.google.com/youtube/answer/3037...         926   \n",
       "3  https://support.google.com/youtube/answer/3037...       3,897   \n",
       "4  https://support.google.com/youtube/answer/3037...      82,627   \n",
       "5  https://support.google.com/youtube/answer/3037...       2,977   \n",
       "6  https://rr3---sn-vgqsrnsr.googlevideo.com/vide...      15,447   \n",
       "7  https://i.ytimg.com/vi/C6HaBSkA6xU/hq2.jpg?sqp...       4,477   \n",
       "8  https://rr1---sn-f58xn2xxq-aj5l.googlevideo.co...      47,959   \n",
       "\n",
       "   shorts_likes  shorts_comments_num  shorts_comments_time  \\\n",
       "0       17000.0                 94.0                   NaN   \n",
       "1         328.0                 13.0                   NaN   \n",
       "2         229.0                  3.0                   NaN   \n",
       "3          72.0                  3.0                   NaN   \n",
       "4        4700.0                206.0                   NaN   \n",
       "5         284.0                  5.0                   NaN   \n",
       "6         327.0                 12.0                   NaN   \n",
       "7         562.0                  8.0                   NaN   \n",
       "8        2400.0                 32.0                   NaN   \n",
       "\n",
       "  shorts_published_date                 check_date  \n",
       "0                   NaN 2024-10-24 21:44:30.453033  \n",
       "1                   NaN 2024-10-24 21:44:30.453033  \n",
       "2                   NaN 2024-10-24 21:44:30.453033  \n",
       "3                   NaN 2024-10-24 21:44:30.453033  \n",
       "4                   NaN 2024-10-24 21:44:30.453033  \n",
       "5                   NaN 2024-10-24 21:44:30.453033  \n",
       "6         2024-01-17 22 2024-10-24 21:44:30.453033  \n",
       "7         2024-10-23 09 2024-10-24 21:44:30.453033  \n",
       "8         2023-01-07 09 2024-10-24 21:44:30.453033  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추가된 데이터 dataframe으로 loaed_db에 추가\n",
    "def add_new_data_to_loaded_db(data_list, loaded_db):\n",
    "    # Define the columns for the DataFrame\n",
    "    columns = [\n",
    "        'channel_name', 'shorts_url', 'shorts_title', 'shorts_description', \n",
    "        'shorts_thumbnail', 'shorts_view', 'shorts_likes', \n",
    "        'shorts_comments_num', 'shorts_comments_time', \n",
    "        'shorts_published_date', 'check_date'\n",
    "    ]\n",
    "    \n",
    "    # Map the data_list to the correct columns and create a new DataFrame\n",
    "    new_data_df = pd.DataFrame(data_list, columns=columns)\n",
    "    \n",
    "    # Append the new data to the loaded_db DataFrame\n",
    "    updated_loaded_db = pd.concat([loaded_db, new_data_df], ignore_index=True)\n",
    "    \n",
    "    return updated_loaded_db\n",
    "\n",
    "loaded_df = add_new_data_to_loaded_db(data_list, loaded_df)\n",
    "loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e7ff3e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_df.columns)\n",
    "len(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53827760",
   "metadata": {},
   "source": [
    "#### loaded_df 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d323ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거\n",
    "loaded_df = loaded_df.drop_duplicates()\n",
    "loaded_df.to_excel(\"loaded_db.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
